

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>dire_rapids.dire_pytorch &mdash; dire-rapids 0.1.0 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../../_static/css/theme.css?v=e59714d7" />

  
      <script src="../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../_static/documentation_options.js?v=01f34227"></script>
      <script src="../../_static/doctools.js?v=9a2dae69"></script>
      <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search"  style="background: white" >

          
          
          <a href="../../index.html" class="icon icon-home">
            dire-rapids
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../api/modules.html">dire_rapids</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu"  style="background: white" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">dire-rapids</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../index.html">Module code</a></li>
      <li class="breadcrumb-item active">dire_rapids.dire_pytorch</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for dire_rapids.dire_pytorch</h1><div class="highlight"><pre>
<span></span><span class="c1"># dire_pytorch.py</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">PyTorch/PyKeOps backend for DiRe dimensionality reduction.</span>

<span class="sd">This implementation features:</span>
<span class="sd">- Memory-efficient chunked k-NN computation for large datasets (&gt;100K points)</span>
<span class="sd">- Attraction forces applied only between k-NN neighbors  </span>
<span class="sd">- Repulsion forces computed from random samples</span>
<span class="sd">- Automatic GPU memory management with adaptive chunk sizing</span>
<span class="sd">- Designed for high-performance processing on CUDA GPUs</span>

<span class="sd">Performance characteristics:</span>
<span class="sd">- Best for datasets &gt;50K points on CUDA GPUs</span>
<span class="sd">- Memory-aware processing up to millions of points</span>
<span class="sd">- Chunked computation prevents GPU out-of-memory errors</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">gc</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">sys</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">plotly.express</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">px</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">loguru</span><span class="w"> </span><span class="kn">import</span> <span class="n">logger</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">scipy.optimize</span><span class="w"> </span><span class="kn">import</span> <span class="n">curve_fit</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.base</span><span class="w"> </span><span class="kn">import</span> <span class="n">TransformerMixin</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.decomposition</span><span class="w"> </span><span class="kn">import</span> <span class="n">PCA</span>

<span class="c1"># PyKeOps for efficient force computations</span>
<span class="k">try</span><span class="p">:</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">pykeops.torch</span><span class="w"> </span><span class="kn">import</span> <span class="n">LazyTensor</span>

    <span class="n">PYKEOPS_AVAILABLE</span> <span class="o">=</span> <span class="kc">True</span>
<span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
    <span class="n">PYKEOPS_AVAILABLE</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;PyKeOps not available. Install with: pip install pykeops&quot;</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_compile_metric</span><span class="p">(</span><span class="n">spec</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Turn a metric spec into a callable metric(x, y) that returns a distance-like</span>
<span class="sd">    matrix with broadcasting:</span>
<span class="sd">      - Torch path:  x: (A, 1, D), y: (1, B, D)  -&gt; (A, B) torch.Tensor</span>
<span class="sd">      - KeOps path:  x: LazyTensor(A,1,D), y: LazyTensor(1,B,D) -&gt; LazyTensor(A,B)</span>

<span class="sd">    If spec is None or &#39;euclidean&#39;/&#39;l2&#39;, return None (fast-path Euclidean stays in backend).</span>
<span class="sd">    If spec is str, it&#39;s eval&#39;ed with {&#39;x&#39;: x, &#39;y&#39;: y} and no builtins.</span>
<span class="sd">    If spec is callable, it&#39;s returned unchanged.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">spec</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">spec</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
        <span class="n">expr</span> <span class="o">=</span> <span class="n">spec</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">expr</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;euclidean&quot;</span><span class="p">,</span> <span class="s2">&quot;l2&quot;</span><span class="p">):</span>
            <span class="k">return</span> <span class="kc">None</span>  <span class="c1"># use built-in fast Euclidean</span>
        <span class="k">def</span><span class="w"> </span><span class="nf">_expr_metric</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">_expr</span><span class="o">=</span><span class="n">spec</span><span class="p">):</span>
            <span class="c1"># Use ONLY tensor methods like .sum(-1), .sqrt(), .abs(), etc.</span>
            <span class="c1"># Works for both torch.Tensor and KeOps LazyTensor.</span>
            <span class="k">return</span> <span class="nb">eval</span><span class="p">(</span><span class="n">_expr</span><span class="p">,</span> <span class="p">{</span><span class="s2">&quot;__builtins__&quot;</span><span class="p">:</span> <span class="p">{}},</span> <span class="p">{</span><span class="s2">&quot;x&quot;</span><span class="p">:</span> <span class="n">x</span><span class="p">,</span> <span class="s2">&quot;y&quot;</span><span class="p">:</span> <span class="n">y</span><span class="p">})</span>
        <span class="k">return</span> <span class="n">_expr_metric</span>
    <span class="k">if</span> <span class="nb">callable</span><span class="p">(</span><span class="n">spec</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">spec</span>
    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;metric must be None, a string expression, or a callable&quot;</span><span class="p">)</span>


<div class="viewcode-block" id="DiRePyTorch">
<a class="viewcode-back" href="../../api/modules.html#dire_rapids.dire_pytorch.DiRePyTorch">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">DiRePyTorch</span><span class="p">(</span><span class="n">TransformerMixin</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Memory-efficient PyTorch/PyKeOps implementation of DiRe dimensionality reduction.</span>
<span class="sd">    </span>
<span class="sd">    This class provides a high-performance implementation of the DiRe algorithm using PyTorch</span>
<span class="sd">    as the computational backend. It features adaptive memory management for large datasets</span>
<span class="sd">    and automatic GPU optimization.</span>
<span class="sd">    </span>
<span class="sd">    Features</span>
<span class="sd">    --------</span>
<span class="sd">    - Chunked k-NN computation prevents GPU out-of-memory errors</span>
<span class="sd">    - Memory-aware force computation with automatic chunk sizing</span>
<span class="sd">    - Attraction forces between k-NN neighbors only</span>
<span class="sd">    - Repulsion forces from random sampling for efficiency</span>
<span class="sd">    - Automatic FP16 optimization for memory and speed</span>
<span class="sd">    - Optional PyKeOps integration for low-dimensional data</span>
<span class="sd">    </span>
<span class="sd">    Best suited for</span>
<span class="sd">    ---------------</span>
<span class="sd">    - Large datasets (&gt;50K points) on CUDA GPUs</span>
<span class="sd">    - Production environments requiring reliable memory usage</span>
<span class="sd">    - High-performance dimensionality reduction workflows</span>
<span class="sd">    </span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    n_components : int, default=2</span>
<span class="sd">        Number of dimensions in the target embedding space.</span>
<span class="sd">    n_neighbors : int, default=16</span>
<span class="sd">        Number of nearest neighbors to use for attraction forces.</span>
<span class="sd">    init : {&#39;pca&#39;, &#39;random&#39;}, default=&#39;pca&#39;</span>
<span class="sd">        Method for initializing the embedding. &#39;pca&#39; uses PCA initialization,</span>
<span class="sd">        &#39;random&#39; uses random projection.</span>
<span class="sd">    max_iter_layout : int, default=128</span>
<span class="sd">        Maximum number of optimization iterations.</span>
<span class="sd">    min_dist : float, default=1e-2</span>
<span class="sd">        Minimum distance between points in the embedding.</span>
<span class="sd">    spread : float, default=1.0</span>
<span class="sd">        Controls how tightly points are packed in the embedding.</span>
<span class="sd">    cutoff : float, default=42.0</span>
<span class="sd">        Distance cutoff for repulsion forces.</span>
<span class="sd">    n_sample_dirs : int, default=8</span>
<span class="sd">        Number of sampling directions (used by derived classes).</span>
<span class="sd">    sample_size : int, default=16</span>
<span class="sd">        Size of samples for force computation (used by derived classes).</span>
<span class="sd">    neg_ratio : int, default=8</span>
<span class="sd">        Ratio of negative samples to positive samples for repulsion.</span>
<span class="sd">    verbose : bool, default=True</span>
<span class="sd">        Whether to print progress information.</span>
<span class="sd">    random_state : int or None, default=None</span>
<span class="sd">        Random seed for reproducible results.</span>
<span class="sd">    use_exact_repulsion : bool, default=False</span>
<span class="sd">        If True, use exact all-pairs repulsion (memory intensive, for testing only).</span>
<span class="sd">    metric : str, callable, or None, default=None</span>
<span class="sd">        Custom distance metric for k-NN computation only (layout forces remain Euclidean):</span>

<span class="sd">        - None or &#39;euclidean&#39;/&#39;l2&#39;: Use fast built-in Euclidean distance</span>
<span class="sd">        - str: String expression evaluated with x and y tensors (e.g., &#39;(x - y).abs().sum(-1)&#39; for L1)</span>
<span class="sd">        - callable: Custom function taking (x, y) tensors and returning distance matrix</span>

<span class="sd">        Examples: &#39;(x - y).abs().sum(-1)&#39; (L1), &#39;1 - (x*y).sum(-1)/(x.norm()*y.norm() + 1e-8)&#39; (cosine).</span>
<span class="sd">        </span>
<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    device : torch.device</span>
<span class="sd">        The PyTorch device being used (CPU or CUDA).</span>
<span class="sd">    logger : loguru.Logger</span>
<span class="sd">        Instance-specific logger for this reducer.</span>
<span class="sd">        </span>
<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    Basic usage::</span>
<span class="sd">    </span>
<span class="sd">        from dire_rapids import DiRePyTorch</span>
<span class="sd">        import numpy as np</span>
<span class="sd">        </span>
<span class="sd">        # Create sample data</span>
<span class="sd">        X = np.random.randn(10000, 100)</span>
<span class="sd">        </span>
<span class="sd">        # Create and fit reducer</span>
<span class="sd">        reducer = DiRePyTorch(n_neighbors=32, verbose=True)</span>
<span class="sd">        embedding = reducer.fit_transform(X)</span>
<span class="sd">        </span>
<span class="sd">        # Visualize results</span>
<span class="sd">        fig = reducer.visualize()</span>
<span class="sd">        fig.show()</span>
<span class="sd">    </span>
<span class="sd">    With custom parameters::</span>

<span class="sd">        reducer = DiRePyTorch(</span>
<span class="sd">            n_components=3,</span>
<span class="sd">            n_neighbors=50,</span>
<span class="sd">            max_iter_layout=200,</span>
<span class="sd">            min_dist=0.1,</span>
<span class="sd">            random_state=42</span>
<span class="sd">        )</span>
<span class="sd">        embedding = reducer.fit_transform(X)</span>

<span class="sd">    With custom distance metric::</span>

<span class="sd">        # Using L1 (Manhattan) distance for k-NN</span>
<span class="sd">        reducer = DiRePyTorch(</span>
<span class="sd">            metric=&#39;(x - y).abs().sum(-1)&#39;,</span>
<span class="sd">            n_neighbors=32</span>
<span class="sd">        )</span>
<span class="sd">        embedding = reducer.fit_transform(X)</span>

<span class="sd">        # Using custom callable metric</span>
<span class="sd">        def cosine_distance(x, y):</span>
<span class="sd">            return 1 - (x * y).sum(-1) / (x.norm(dim=-1, keepdim=True) * y.norm(dim=-1, keepdim=True) + 1e-8)</span>

<span class="sd">        reducer = DiRePyTorch(metric=cosine_distance)</span>
<span class="sd">        embedding = reducer.fit_transform(X)</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="DiRePyTorch.__init__">
<a class="viewcode-back" href="../../api/modules.html#dire_rapids.dire_pytorch.DiRePyTorch.__init__">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span>
            <span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
            <span class="n">n_neighbors</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
            <span class="n">init</span><span class="o">=</span><span class="s2">&quot;pca&quot;</span><span class="p">,</span>
            <span class="n">max_iter_layout</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
            <span class="n">min_dist</span><span class="o">=</span><span class="mf">1e-2</span><span class="p">,</span>
            <span class="n">spread</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
            <span class="n">cutoff</span><span class="o">=</span><span class="mf">42.0</span><span class="p">,</span>
            <span class="n">n_sample_dirs</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
            <span class="n">sample_size</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
            <span class="n">neg_ratio</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
            <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
            <span class="n">use_exact_repulsion</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>  <span class="c1"># If True, use all-pairs repulsion (for testing)</span>
            <span class="n">metric</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initialize DiRePyTorch reducer with specified parameters.</span>
<span class="sd">        </span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        n_components : int, default=2</span>
<span class="sd">            Number of dimensions in the target embedding space.</span>
<span class="sd">        n_neighbors : int, default=16</span>
<span class="sd">            Number of nearest neighbors to use for attraction forces.</span>
<span class="sd">        init : {&#39;pca&#39;, &#39;random&#39;}, default=&#39;pca&#39;</span>
<span class="sd">            Method for initializing the embedding.</span>
<span class="sd">        max_iter_layout : int, default=128</span>
<span class="sd">            Maximum number of optimization iterations.</span>
<span class="sd">        min_dist : float, default=1e-2</span>
<span class="sd">            Minimum distance between points in the embedding.</span>
<span class="sd">        spread : float, default=1.0</span>
<span class="sd">            Controls how tightly points are packed in the embedding.</span>
<span class="sd">        cutoff : float, default=42.0</span>
<span class="sd">            Distance cutoff for repulsion forces.</span>
<span class="sd">        n_sample_dirs : int, default=8</span>
<span class="sd">            Number of sampling directions (reserved for future use).</span>
<span class="sd">        sample_size : int, default=16</span>
<span class="sd">            Size of samples for force computation (reserved for future use).</span>
<span class="sd">        neg_ratio : int, default=8</span>
<span class="sd">            Ratio of negative samples to positive samples for repulsion.</span>
<span class="sd">        verbose : bool, default=True</span>
<span class="sd">            Whether to print progress information.</span>
<span class="sd">        random_state : int or None, default=None</span>
<span class="sd">            Random seed for reproducible results.</span>
<span class="sd">        use_exact_repulsion : bool, default=False</span>
<span class="sd">            If True, use exact all-pairs repulsion (memory intensive, testing only).</span>
<span class="sd">        metric : str, callable, or None, default=None</span>
<span class="sd">            Custom distance metric for k-NN computation. See class docstring for details.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">n_components</span> <span class="o">=</span> <span class="n">n_components</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_neighbors</span> <span class="o">=</span> <span class="n">n_neighbors</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">init</span> <span class="o">=</span> <span class="n">init</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_iter_layout</span> <span class="o">=</span> <span class="n">max_iter_layout</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">min_dist</span> <span class="o">=</span> <span class="n">min_dist</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">spread</span> <span class="o">=</span> <span class="n">spread</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cutoff</span> <span class="o">=</span> <span class="n">cutoff</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_sample_dirs</span> <span class="o">=</span> <span class="n">n_sample_dirs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sample_size</span> <span class="o">=</span> <span class="n">sample_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">neg_ratio</span> <span class="o">=</span> <span class="n">neg_ratio</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="n">verbose</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random_state</span> <span class="o">=</span> <span class="n">random_state</span> <span class="k">if</span> <span class="n">random_state</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span> <span class="o">**</span> <span class="mi">32</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">use_exact_repulsion</span> <span class="o">=</span> <span class="n">use_exact_repulsion</span>

        <span class="c1"># Custom metric for k-NN only (layout forces remain Euclidean):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">metric_spec</span> <span class="o">=</span> <span class="n">metric</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_metric_fn</span> <span class="o">=</span> <span class="n">_compile_metric</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">metric_spec</span><span class="p">)</span>

        <span class="c1"># Setup instance-specific logger</span>
        <span class="c1"># Create a completely new logger instance for this DiRe object</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">logger</span> <span class="o">=</span> <span class="n">logger</span><span class="o">.</span><span class="n">bind</span><span class="p">(</span><span class="n">dire_instance</span><span class="o">=</span><span class="nb">id</span><span class="p">(</span><span class="bp">self</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">remove</span><span class="p">()</span>  <span class="c1"># Remove all existing handlers</span>
        
        <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
            <span class="c1"># Add handler that outputs to stderr with formatting</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">add</span><span class="p">(</span>
                <span class="n">sys</span><span class="o">.</span><span class="n">stderr</span><span class="p">,</span>
                <span class="n">level</span><span class="o">=</span><span class="s2">&quot;INFO&quot;</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Add null handler that discards all messages</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="k">lambda</span> <span class="n">msg</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span> <span class="n">level</span><span class="o">=</span><span class="s2">&quot;TRACE&quot;</span><span class="p">)</span>

        <span class="c1"># Internal state</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_data</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_layout</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_n_samples</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_a</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_b</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_knn_indices</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_knn_distances</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="c1"># Device management</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cuda&#39;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s1">&#39;cpu&#39;</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="s1">&#39;cuda&#39;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Using CUDA device: </span><span class="si">{</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">get_device_name</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;CUDA not available, using CPU&quot;</span><span class="p">)</span></div>


    <span class="k">def</span><span class="w"> </span><span class="nf">_find_ab_params</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Find optimal a and b parameters for the distribution kernel.</span>
<span class="sd">        </span>
<span class="sd">        This private method fits a curve to determine the optimal parameters for the</span>
<span class="sd">        probability kernel used in force calculations. The parameters control the</span>
<span class="sd">        shape of the attraction/repulsion curve.</span>
<span class="sd">        </span>
<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        Private method, should not be called directly. Used by fit_transform().</span>
<span class="sd">        The kernel function is: 1 / (1 + a * x^(2*b))</span>
<span class="sd">        </span>
<span class="sd">        Side Effects</span>
<span class="sd">        ------------</span>
<span class="sd">        Sets self._a and self._b attributes with the fitted parameters.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">def</span><span class="w"> </span><span class="nf">curve</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
            <span class="k">return</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">+</span> <span class="n">a</span> <span class="o">*</span> <span class="n">x</span> <span class="o">**</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">b</span><span class="p">))</span>

        <span class="n">xv</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">spread</span><span class="p">,</span> <span class="mi">300</span><span class="p">)</span>
        <span class="n">yv</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">xv</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
        <span class="n">yv</span><span class="p">[</span><span class="n">xv</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_dist</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.0</span>
        <span class="n">yv</span><span class="p">[</span><span class="n">xv</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_dist</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="p">(</span><span class="n">xv</span><span class="p">[</span><span class="n">xv</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_dist</span><span class="p">]</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_dist</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">spread</span><span class="p">)</span>

        <span class="n">params</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">curve_fit</span><span class="p">(</span><span class="n">curve</span><span class="p">,</span> <span class="n">xv</span><span class="p">,</span> <span class="n">yv</span><span class="p">)[:</span><span class="mi">2</span><span class="p">]</span>  <span class="c1"># Extract only params and covariance</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_a</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_b</span> <span class="o">=</span> <span class="n">params</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Found kernel params: a=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_a</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, b=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_b</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_compute_knn</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">chunk_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">use_fp16</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>  <span class="c1"># pylint: disable=too-many-branches</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute k-nearest neighbors with memory-efficient chunking.</span>
<span class="sd">        </span>
<span class="sd">        This private method computes the k-nearest neighbors graph using either PyTorch</span>
<span class="sd">        or PyKeOps backends. It intelligently selects the optimal backend based on</span>
<span class="sd">        data dimensionality and automatically manages memory through chunking.</span>
<span class="sd">        </span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : numpy.ndarray</span>
<span class="sd">            Input data of shape (n_samples, n_features).</span>
<span class="sd">        chunk_size : int, optional</span>
<span class="sd">            Size of chunks for processing. If None, automatically determined based</span>
<span class="sd">            on available memory.</span>
<span class="sd">        use_fp16 : bool, optional</span>
<span class="sd">            Use FP16 precision for computation. If None, automatically determined</span>
<span class="sd">            based on data size and GPU capabilities. FP16 provides 2x memory savings</span>
<span class="sd">            and 2-14x speedup on modern GPUs.</span>
<span class="sd">            </span>
<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        Private method, should not be called directly. Used by fit_transform().</span>
<span class="sd">        </span>
<span class="sd">        Backend Selection:</span>
<span class="sd">        - PyTorch: Used for high-dimensional data (&gt;= 200D) or when PyKeOps unavailable</span>
<span class="sd">        - PyKeOps: Used for low-dimensional data (&lt; 200D) on GPU for better performance</span>
<span class="sd">        </span>
<span class="sd">        Side Effects</span>
<span class="sd">        ------------</span>
<span class="sd">        Sets self._knn_indices and self._knn_distances with computed k-NN graph.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">n_samples</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">n_dims</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Computing </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">n_neighbors</span><span class="si">}</span><span class="s2">-NN graph for </span><span class="si">{</span><span class="n">n_samples</span><span class="si">}</span><span class="s2"> points in </span><span class="si">{</span><span class="n">n_dims</span><span class="si">}</span><span class="s2">D...&quot;</span><span class="p">)</span>

        <span class="c1"># Auto-detect FP16 usage based on data size and GPU</span>
        <span class="k">if</span> <span class="n">use_fp16</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="s1">&#39;cuda&#39;</span><span class="p">:</span>
            <span class="c1"># Use FP16 for high-dimensional data or large datasets</span>
            <span class="n">use_fp16</span> <span class="o">=</span> <span class="n">n_dims</span> <span class="o">&gt;=</span> <span class="mi">500</span> <span class="ow">or</span> <span class="n">n_samples</span> <span class="o">&gt;=</span> <span class="mi">100000</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="s1">&#39;cpu&#39;</span><span class="p">:</span>
            <span class="n">use_fp16</span> <span class="o">=</span> <span class="kc">False</span>  <span class="c1"># CPU doesn&#39;t benefit from FP16</span>
        
        <span class="c1"># Choose precision</span>
        <span class="k">if</span> <span class="n">use_fp16</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="s1">&#39;cuda&#39;</span><span class="p">:</span>
            <span class="n">dtype</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">float16</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Using FP16 for k-NN (2x memory, faster on H100/A100)&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">dtype</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">float32</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Using FP32 for k-NN&quot;</span><span class="p">)</span>
        
        <span class="n">X_torch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        
        <span class="c1"># CRITICAL: PyKeOps is slower than PyTorch for high dimensions!</span>
        <span class="c1"># Use PyTorch for high-D, PyKeOps for low-D</span>
        <span class="n">use_pykeops</span> <span class="o">=</span> <span class="n">PYKEOPS_AVAILABLE</span> <span class="ow">and</span> <span class="n">n_dims</span> <span class="o">&lt;</span> <span class="mi">200</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="s1">&#39;cuda&#39;</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">use_fp16</span>
        
        <span class="k">if</span> <span class="n">n_dims</span> <span class="o">&gt;=</span> <span class="mi">200</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Using PyTorch for k-NN (high dimension: </span><span class="si">{</span><span class="n">n_dims</span><span class="si">}</span><span class="s2">D)&quot;</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">use_pykeops</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Using PyKeOps for k-NN (low dimension, GPU available)&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Using PyTorch for k-NN&quot;</span><span class="p">)</span>
        
        <span class="c1"># Set default chunk size if not provided</span>
        <span class="k">if</span> <span class="n">chunk_size</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">chunk_size</span> <span class="o">=</span> <span class="mi">50000</span>
            
        <span class="c1"># Adaptive chunk sizing based on available GPU memory</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="s1">&#39;cuda&#39;</span><span class="p">:</span>
            <span class="n">gpu_mem_free</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">mem_get_info</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
            <span class="c1"># Estimate memory for k-NN: chunk_size * n_samples * bytes_per_element</span>
            <span class="n">bytes_per_element</span> <span class="o">=</span> <span class="mi">2</span> <span class="k">if</span> <span class="n">use_fp16</span> <span class="k">else</span> <span class="mi">4</span>  <span class="c1"># FP16 uses 2 bytes, FP32 uses 4</span>
            <span class="n">memory_per_chunk</span> <span class="o">=</span> <span class="n">chunk_size</span> <span class="o">*</span> <span class="n">n_samples</span> <span class="o">*</span> <span class="n">bytes_per_element</span>
            
            <span class="c1"># Only auto-adjust if using default chunk size</span>
            <span class="k">if</span> <span class="n">chunk_size</span> <span class="o">==</span> <span class="mi">50000</span><span class="p">:</span>
                <span class="c1"># Use 30% of available memory for k-NN computation (40% for FP16 since it&#39;s more efficient)</span>
                <span class="n">memory_fraction</span> <span class="o">=</span> <span class="mf">0.4</span> <span class="k">if</span> <span class="n">use_fp16</span> <span class="k">else</span> <span class="mf">0.3</span>
                <span class="n">max_memory</span> <span class="o">=</span> <span class="n">gpu_mem_free</span> <span class="o">*</span> <span class="n">memory_fraction</span>
                <span class="k">if</span> <span class="n">memory_per_chunk</span> <span class="o">&gt;</span> <span class="n">max_memory</span><span class="p">:</span>
                    <span class="n">chunk_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">max_memory</span> <span class="o">/</span> <span class="p">(</span><span class="n">n_samples</span> <span class="o">*</span> <span class="n">bytes_per_element</span><span class="p">))</span>
                    <span class="n">chunk_size</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="n">chunk_size</span><span class="p">)</span>  <span class="c1"># Minimum chunk size</span>
                
                <span class="c1"># With FP16, we can use larger chunks!</span>
                <span class="k">if</span> <span class="n">use_fp16</span><span class="p">:</span>
                    <span class="n">chunk_size</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">chunk_size</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">100000</span><span class="p">)</span>  <span class="c1"># Double chunk size for FP16</span>
            
            <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Using chunk size: </span><span class="si">{</span><span class="n">chunk_size</span><span class="si">}</span><span class="s2"> (GPU memory: </span><span class="si">{</span><span class="n">gpu_mem_free</span><span class="o">/</span><span class="mi">1024</span><span class="o">**</span><span class="mi">3</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2">GB, dtype: </span><span class="si">{</span><span class="n">dtype</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>
        
        <span class="c1"># Initialize arrays for results</span>
        <span class="n">all_knn_indices</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">all_knn_distances</span> <span class="o">=</span> <span class="p">[]</span>
        
        <span class="c1"># Process in chunks to avoid memory issues</span>
        <span class="k">for</span> <span class="n">start_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">,</span> <span class="n">chunk_size</span><span class="p">):</span>
            <span class="n">end_idx</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">start_idx</span> <span class="o">+</span> <span class="n">chunk_size</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">)</span>
            
            <span class="k">if</span> <span class="n">n_samples</span> <span class="o">&gt;</span> <span class="mi">50000</span><span class="p">:</span>  <span class="c1"># Only log for large datasets</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Processing chunk </span><span class="si">{</span><span class="n">start_idx</span><span class="o">//</span><span class="n">chunk_size</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="p">(</span><span class="n">n_samples</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">chunk_size</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="o">//</span><span class="n">chunk_size</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            
            <span class="c1"># Get chunk data</span>
            <span class="n">X_chunk</span> <span class="o">=</span> <span class="n">X_torch</span><span class="p">[</span><span class="n">start_idx</span><span class="p">:</span><span class="n">end_idx</span><span class="p">]</span>  <span class="c1"># (chunk_size, D)</span>
            
            <span class="k">if</span> <span class="n">use_pykeops</span><span class="p">:</span>
                <span class="c1"># Use PyKeOps for LOW dimensional data</span>
                <span class="c1"># Ensure contiguity for PyKeOps</span>
                <span class="n">X_i</span> <span class="o">=</span> <span class="n">LazyTensor</span><span class="p">(</span><span class="n">X_chunk</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">contiguous</span><span class="p">())</span>  <span class="c1"># (chunk_size, 1, D)</span>
                <span class="n">X_j</span> <span class="o">=</span> <span class="n">LazyTensor</span><span class="p">(</span><span class="n">X_torch</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]</span><span class="o">.</span><span class="n">contiguous</span><span class="p">())</span>   <span class="c1"># (1, N, D)</span>
                
                <span class="c1"># Compute squared distances</span>
                <span class="n">D_ij</span> <span class="o">=</span> <span class="p">((</span><span class="n">X_i</span> <span class="o">-</span> <span class="n">X_j</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># (chunk_size, N) LazyTensor</span>
                
                <span class="c1"># Find k+1 nearest neighbors (including self)</span>
                <span class="n">knn_dists</span><span class="p">,</span> <span class="n">knn_indices</span> <span class="o">=</span> <span class="n">D_ij</span><span class="o">.</span><span class="n">Kmin_argKmin</span><span class="p">(</span><span class="n">K</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_neighbors</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
                
                <span class="c1"># Remove self and convert to actual distances</span>
                <span class="n">chunk_indices</span> <span class="o">=</span> <span class="n">knn_indices</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:]</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
                <span class="n">chunk_distances</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">knn_dists</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:])</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># Use PyTorch for HIGH dimensional data (MUCH faster!)</span>
                <span class="n">distances</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cdist</span><span class="p">(</span><span class="n">X_chunk</span><span class="p">,</span> <span class="n">X_torch</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
                <span class="n">knn_dists</span><span class="p">,</span> <span class="n">knn_indices</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">topk</span><span class="p">(</span><span class="n">distances</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_neighbors</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> 
                                                   <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">largest</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
                
                <span class="c1"># Remove self</span>
                <span class="n">chunk_indices</span> <span class="o">=</span> <span class="n">knn_indices</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:]</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>  
                <span class="n">chunk_distances</span> <span class="o">=</span> <span class="n">knn_dists</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:]</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
            
            <span class="n">all_knn_indices</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">chunk_indices</span><span class="p">)</span>
            <span class="n">all_knn_distances</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">chunk_distances</span><span class="p">)</span>
            
            <span class="c1"># Clear GPU memory periodically</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="s1">&#39;cuda&#39;</span> <span class="ow">and</span> <span class="n">start_idx</span> <span class="o">%</span> <span class="p">(</span><span class="n">chunk_size</span> <span class="o">*</span> <span class="mi">10</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>
        
        <span class="c1"># Concatenate results</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_knn_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">(</span><span class="n">all_knn_indices</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_knn_distances</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">(</span><span class="n">all_knn_distances</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;k-NN graph computed: shape </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_knn_indices</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_initialize_embedding</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initialize the low-dimensional embedding.</span>
<span class="sd">        </span>
<span class="sd">        This private method creates the initial embedding using either PCA or random</span>
<span class="sd">        projection, then normalizes the result.</span>
<span class="sd">        </span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : numpy.ndarray</span>
<span class="sd">            Input high-dimensional data of shape (n_samples, n_features).</span>
<span class="sd">            </span>
<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        torch.Tensor</span>
<span class="sd">            Initial embedding of shape (n_samples, n_components) on the target device.</span>
<span class="sd">            </span>
<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        Private method, should not be called directly. Used by fit_transform().</span>
<span class="sd">        </span>
<span class="sd">        The embedding is normalized to have zero mean and unit standard deviation</span>
<span class="sd">        along each dimension.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">init</span> <span class="o">==</span> <span class="s1">&#39;pca&#39;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Initializing with PCA&quot;</span><span class="p">)</span>
            <span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_components</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">random_state</span><span class="p">)</span>
            <span class="n">embedding</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">init</span> <span class="o">==</span> <span class="s1">&#39;random&#39;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Initializing with random projection&quot;</span><span class="p">)</span>
            <span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">random_state</span><span class="p">)</span>  <span class="c1"># pylint: disable=no-member</span>
            <span class="n">projection</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_components</span><span class="p">)</span>
            <span class="n">projection</span> <span class="o">/=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">projection</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">embedding</span> <span class="o">=</span> <span class="n">X</span> <span class="o">@</span> <span class="n">projection</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unknown init method: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">init</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Normalize</span>
        <span class="n">embedding</span> <span class="o">-=</span> <span class="n">embedding</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">embedding</span> <span class="o">/=</span> <span class="n">embedding</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">embedding</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_compute_forces</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">positions</span><span class="p">,</span> <span class="n">iteration</span><span class="p">,</span> <span class="n">max_iterations</span><span class="p">,</span> <span class="n">chunk_size</span><span class="o">=</span><span class="mi">5000</span><span class="p">):</span>  <span class="c1"># pylint: disable=too-many-branches,too-many-locals</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute attraction and repulsion forces for layout optimization.</span>
<span class="sd">        </span>
<span class="sd">        This private method computes forces between points in the embedding space</span>
<span class="sd">        using a memory-efficient chunked approach. Attraction forces are computed</span>
<span class="sd">        only between k-nearest neighbors, while repulsion forces use random sampling.</span>
<span class="sd">        </span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        positions : torch.Tensor</span>
<span class="sd">            Current positions of points in embedding space, shape (n_samples, n_components).</span>
<span class="sd">        iteration : int</span>
<span class="sd">            Current iteration number (0-indexed).</span>
<span class="sd">        max_iterations : int</span>
<span class="sd">            Total number of iterations planned.</span>
<span class="sd">        chunk_size : int, default=5000</span>
<span class="sd">            Maximum chunk size for memory-efficient processing.</span>
<span class="sd">            </span>
<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        torch.Tensor</span>
<span class="sd">            Computed forces of shape (n_samples, n_components).</span>
<span class="sd">            </span>
<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        Private method, should not be called directly. Used by _optimize_layout().</span>
<span class="sd">        </span>
<span class="sd">        Force Computation:</span>
<span class="sd">        - **Attraction forces**: Applied only between k-nearest neighbors using</span>
<span class="sd">          the kernel function 1 / (1 + a * (1/d)^(2*b))</span>
<span class="sd">        - **Repulsion forces**: Applied between randomly sampled pairs using</span>
<span class="sd">          the kernel function -1 / (1 + a * d^(2*b)) with exponential cutoff</span>
<span class="sd">        - **Cooling**: Forces are scaled by (1 - iteration/max_iterations)</span>
<span class="sd">        - **Clipping**: Forces are clipped to [-cutoff, cutoff] range</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># PyKeOps is optional - we can use pure PyTorch</span>
        <span class="c1"># if not PYKEOPS_AVAILABLE:</span>
        <span class="c1">#     raise RuntimeError(&quot;PyKeOps required for efficient force computation&quot;)</span>

        <span class="n">n_samples</span> <span class="o">=</span> <span class="n">positions</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">forces</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">positions</span><span class="p">)</span>

        <span class="c1"># Linear cooling schedule</span>
        <span class="n">alpha</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">iteration</span> <span class="o">/</span> <span class="n">max_iterations</span>

        <span class="c1"># Parameters</span>
        <span class="n">a_val</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_a</span><span class="p">)</span>
        <span class="n">b_val</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_b</span><span class="p">)</span>
        <span class="n">b_exp</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">b_val</span><span class="p">)</span>
        
        <span class="c1"># Adjust chunk size based on available memory</span>
        <span class="c1"># Estimate memory usage: chunk_size * (k + n_neg) * D * 4 bytes</span>
        <span class="n">n_neg_samples</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">neg_ratio</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_neighbors</span><span class="p">),</span> <span class="n">n_samples</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">n_dims</span> <span class="o">=</span> <span class="n">positions</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        
        <span class="c1"># Memory estimate per point (in bytes):</span>
        <span class="c1"># k*D*4 for attraction + n_neg*D*4 for repulsion</span>
        <span class="n">bytes_per_float</span> <span class="o">=</span> <span class="mi">4</span>
        <span class="n">memory_per_point</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_neighbors</span> <span class="o">+</span> <span class="n">n_neg_samples</span><span class="p">)</span> <span class="o">*</span> <span class="n">n_dims</span> <span class="o">*</span> <span class="n">bytes_per_float</span> <span class="o">*</span> <span class="mi">2</span>  <span class="c1"># x2 for safety</span>
        
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="s1">&#39;cuda&#39;</span><span class="p">:</span>
            <span class="c1"># Get available GPU memory and use 20% for force computation (more conservative)</span>
            <span class="n">gpu_mem_free</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">mem_get_info</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">max_chunk_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">gpu_mem_free</span> <span class="o">*</span> <span class="mf">0.2</span> <span class="o">/</span> <span class="n">memory_per_point</span><span class="p">)</span>
            <span class="n">chunk_size</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">chunk_size</span><span class="p">,</span> <span class="n">max_chunk_size</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">)</span>
            <span class="c1"># For very large datasets, be extra conservative</span>
            <span class="k">if</span> <span class="n">n_samples</span> <span class="o">&gt;</span> <span class="mi">500000</span><span class="p">:</span>
                <span class="n">chunk_size</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">chunk_size</span><span class="p">,</span> <span class="mi">2000</span><span class="p">)</span>
            <span class="c1"># Ensure reasonable chunk size</span>
            <span class="n">chunk_size</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="nb">min</span><span class="p">(</span><span class="n">chunk_size</span><span class="p">,</span> <span class="mi">5000</span><span class="p">))</span>  <span class="c1"># Between 100 and 5000</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Using chunk size: </span><span class="si">{</span><span class="n">chunk_size</span><span class="si">}</span><span class="s2"> (available memory: </span><span class="si">{</span><span class="n">gpu_mem_free</span><span class="o">/</span><span class="mf">1e9</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2"> GB)&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">chunk_size</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">)</span>  <span class="c1"># Smaller chunks for CPU</span>

        <span class="c1"># Process in chunks to manage memory</span>
        <span class="n">knn_indices_torch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_knn_indices</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        
        <span class="k">for</span> <span class="n">start_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">,</span> <span class="n">chunk_size</span><span class="p">):</span>
            <span class="n">end_idx</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">start_idx</span> <span class="o">+</span> <span class="n">chunk_size</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">)</span>
            <span class="n">chunk_indices</span> <span class="o">=</span> <span class="nb">slice</span><span class="p">(</span><span class="n">start_idx</span><span class="p">,</span> <span class="n">end_idx</span><span class="p">)</span>
            <span class="n">chunk_size_actual</span> <span class="o">=</span> <span class="n">end_idx</span> <span class="o">-</span> <span class="n">start_idx</span>
            
            <span class="c1"># ============ ATTRACTION FORCES (k-NN only) ============</span>
            <span class="c1"># Get chunk data</span>
            <span class="n">chunk_positions</span> <span class="o">=</span> <span class="n">positions</span><span class="p">[</span><span class="n">chunk_indices</span><span class="p">]</span>  <span class="c1"># (chunk, D)</span>
            <span class="n">chunk_knn_indices</span> <span class="o">=</span> <span class="n">knn_indices_torch</span><span class="p">[</span><span class="n">chunk_indices</span><span class="p">]</span>  <span class="c1"># (chunk, k)</span>
            
            <span class="c1"># Check if we have enough memory for vectorized computation</span>
            <span class="n">attraction_memory</span> <span class="o">=</span> <span class="n">chunk_size_actual</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_neighbors</span> <span class="o">*</span> <span class="n">n_dims</span> <span class="o">*</span> <span class="n">bytes_per_float</span>
            
            <span class="k">try</span><span class="p">:</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="s1">&#39;cuda&#39;</span><span class="p">:</span>
                    <span class="n">gpu_mem_free</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">mem_get_info</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
                    <span class="k">if</span> <span class="n">attraction_memory</span> <span class="o">&gt;</span> <span class="n">gpu_mem_free</span> <span class="o">*</span> <span class="mf">0.4</span><span class="p">:</span>
                        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Not enough memory for vectorized attraction&quot;</span><span class="p">)</span>
                
                <span class="c1"># Try vectorized version (faster)</span>
                <span class="n">neighbor_positions</span> <span class="o">=</span> <span class="n">positions</span><span class="p">[</span><span class="n">chunk_knn_indices</span><span class="p">]</span>  <span class="c1"># (chunk, k, D)</span>
                <span class="n">current_positions</span> <span class="o">=</span> <span class="n">chunk_positions</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># (chunk, 1, D)</span>
                
                <span class="c1"># Compute differences and distances</span>
                <span class="n">diff</span> <span class="o">=</span> <span class="n">neighbor_positions</span> <span class="o">-</span> <span class="n">current_positions</span>  <span class="c1"># (chunk, k, D)</span>
                <span class="n">dist</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">diff</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="o">+</span> <span class="mf">1e-10</span>  <span class="c1"># (chunk, k, 1)</span>
                
                <span class="c1"># Attraction kernel</span>
                <span class="n">att_coeff</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">+</span> <span class="n">a_val</span> <span class="o">*</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">/</span> <span class="n">dist</span><span class="p">)</span> <span class="o">**</span> <span class="n">b_exp</span><span class="p">)</span>  <span class="c1"># (chunk, k, 1)</span>
                
                <span class="c1"># Compute attraction forces and sum over neighbors</span>
                <span class="n">att_forces</span> <span class="o">=</span> <span class="p">(</span><span class="n">att_coeff</span> <span class="o">*</span> <span class="n">diff</span> <span class="o">/</span> <span class="n">dist</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># (chunk, D)</span>
                <span class="n">forces</span><span class="p">[</span><span class="n">chunk_indices</span><span class="p">]</span> <span class="o">+=</span> <span class="n">att_forces</span>
                
            <span class="k">except</span> <span class="p">(</span><span class="ne">RuntimeError</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">OutOfMemoryError</span><span class="p">):</span>
                <span class="c1"># Fall back to point-by-point if memory is tight</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="s1">&#39;cuda&#39;</span><span class="p">:</span>
                    <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;Falling back to point-by-point attraction due to memory constraints&quot;</span><span class="p">)</span>
                
                <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">start_idx</span><span class="p">,</span> <span class="n">end_idx</span><span class="p">):</span>
                    <span class="n">neighbor_ids</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_knn_indices</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
                    <span class="n">pos_i</span> <span class="o">=</span> <span class="n">positions</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span>
                    <span class="n">pos_neighbors</span> <span class="o">=</span> <span class="n">positions</span><span class="p">[</span><span class="n">neighbor_ids</span><span class="p">]</span>
                    
                    <span class="n">diff</span> <span class="o">=</span> <span class="n">pos_neighbors</span> <span class="o">-</span> <span class="n">pos_i</span>
                    <span class="n">dist</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">diff</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="o">+</span> <span class="mf">1e-10</span>
                    <span class="n">att_coeff</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">+</span> <span class="n">a_val</span> <span class="o">*</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">/</span> <span class="n">dist</span><span class="p">)</span> <span class="o">**</span> <span class="n">b_exp</span><span class="p">)</span>
                    <span class="n">forces</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+=</span> <span class="p">(</span><span class="n">att_coeff</span> <span class="o">*</span> <span class="n">diff</span> <span class="o">/</span> <span class="n">dist</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

            <span class="c1"># ============ REPULSION FORCES (Random Sampling) ============</span>
            <span class="k">if</span> <span class="n">n_neg_samples</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="c1"># Check memory for repulsion</span>
                <span class="n">repulsion_memory</span> <span class="o">=</span> <span class="n">chunk_size_actual</span> <span class="o">*</span> <span class="n">n_neg_samples</span> <span class="o">*</span> <span class="n">n_dims</span> <span class="o">*</span> <span class="n">bytes_per_float</span>
                
                <span class="k">try</span><span class="p">:</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="s1">&#39;cuda&#39;</span><span class="p">:</span>
                        <span class="n">gpu_mem_free</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">mem_get_info</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
                        <span class="k">if</span> <span class="n">repulsion_memory</span> <span class="o">&gt;</span> <span class="n">gpu_mem_free</span> <span class="o">*</span> <span class="mf">0.4</span><span class="p">:</span>
                            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Not enough memory for vectorized repulsion&quot;</span><span class="p">)</span>
                    
                    <span class="c1"># Try vectorized version</span>
                    <span class="c1"># Generate random samples for this chunk</span>
                    <span class="n">neg_indices</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">,</span> <span class="p">(</span><span class="n">chunk_size_actual</span><span class="p">,</span> <span class="n">n_neg_samples</span> <span class="o">+</span> <span class="mi">5</span><span class="p">),</span> 
                                              <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
                    
                    <span class="c1"># Create mask to exclude points from the current chunk</span>
                    <span class="n">chunk_range</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">start_idx</span><span class="p">,</span> <span class="n">end_idx</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
                    <span class="n">self_mask</span> <span class="o">=</span> <span class="n">neg_indices</span> <span class="o">==</span> <span class="n">chunk_range</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
                    
                    <span class="c1"># Replace self indices with valid random ones</span>
                    <span class="n">replacement_indices</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">,</span> <span class="p">(</span><span class="n">chunk_size_actual</span><span class="p">,</span> <span class="n">n_neg_samples</span> <span class="o">+</span> <span class="mi">5</span><span class="p">),</span> 
                                                      <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
                    <span class="n">neg_indices</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">self_mask</span><span class="p">,</span> <span class="n">replacement_indices</span><span class="p">,</span> <span class="n">neg_indices</span><span class="p">)</span>
                    
                    <span class="c1"># Take first n_neg_samples</span>
                    <span class="n">neg_indices</span> <span class="o">=</span> <span class="n">neg_indices</span><span class="p">[:,</span> <span class="p">:</span><span class="n">n_neg_samples</span><span class="p">]</span>
                    
                    <span class="c1"># Get negative sample positions</span>
                    <span class="n">neg_positions</span> <span class="o">=</span> <span class="n">positions</span><span class="p">[</span><span class="n">neg_indices</span><span class="p">]</span>  <span class="c1"># (chunk, n_neg, D)</span>
                    <span class="n">current_positions</span> <span class="o">=</span> <span class="n">chunk_positions</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># (chunk, 1, D)</span>
                    
                    <span class="c1"># Compute differences and distances</span>
                    <span class="n">diff</span> <span class="o">=</span> <span class="n">neg_positions</span> <span class="o">-</span> <span class="n">current_positions</span>  <span class="c1"># (chunk, n_neg, D)</span>
                    <span class="n">dist</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">diff</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="o">+</span> <span class="mf">1e-10</span>  <span class="c1"># (chunk, n_neg, 1)</span>
                    
                    <span class="c1"># Repulsion kernel</span>
                    <span class="n">rep_coeff</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.0</span> <span class="o">/</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">+</span> <span class="n">a_val</span> <span class="o">*</span> <span class="p">(</span><span class="n">dist</span> <span class="o">**</span> <span class="n">b_exp</span><span class="p">))</span>  <span class="c1"># (chunk, n_neg, 1)</span>
                    
                    <span class="c1"># Apply distance cutoff</span>
                    <span class="n">cutoff_scale</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">dist</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">cutoff</span><span class="p">)</span>
                    <span class="n">rep_coeff</span> <span class="o">=</span> <span class="n">rep_coeff</span> <span class="o">*</span> <span class="n">cutoff_scale</span>
                    
                    <span class="c1"># Compute repulsion forces and sum over negative samples</span>
                    <span class="n">rep_forces</span> <span class="o">=</span> <span class="p">(</span><span class="n">rep_coeff</span> <span class="o">*</span> <span class="n">diff</span> <span class="o">/</span> <span class="n">dist</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># (chunk, D)</span>
                    <span class="n">forces</span><span class="p">[</span><span class="n">chunk_indices</span><span class="p">]</span> <span class="o">+=</span> <span class="n">rep_forces</span>
                    
                <span class="k">except</span> <span class="p">(</span><span class="ne">RuntimeError</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">OutOfMemoryError</span><span class="p">):</span>
                    <span class="c1"># Fall back to point-by-point</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="s1">&#39;cuda&#39;</span><span class="p">:</span>
                        <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;Falling back to point-by-point repulsion due to memory constraints&quot;</span><span class="p">)</span>
                    
                    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">start_idx</span><span class="p">,</span> <span class="n">end_idx</span><span class="p">):</span>
                        <span class="c1"># Random sample for repulsion</span>
                        <span class="n">neg_samples</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="nb">min</span><span class="p">(</span><span class="n">n_neg_samples</span><span class="p">,</span> <span class="n">n_samples</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
                        <span class="n">neg_samples</span> <span class="o">=</span> <span class="n">neg_samples</span><span class="p">[</span><span class="n">neg_samples</span> <span class="o">!=</span> <span class="n">i</span><span class="p">][:</span><span class="n">n_neg_samples</span><span class="p">]</span>  <span class="c1"># Exclude self</span>
                        
                        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">neg_samples</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                            <span class="n">pos_i</span> <span class="o">=</span> <span class="n">positions</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span>
                            <span class="n">pos_neg</span> <span class="o">=</span> <span class="n">positions</span><span class="p">[</span><span class="n">neg_samples</span><span class="p">]</span>
                            
                            <span class="c1"># Compute differences and distances</span>
                            <span class="n">diff</span> <span class="o">=</span> <span class="n">pos_neg</span> <span class="o">-</span> <span class="n">pos_i</span>
                            <span class="n">dist</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">diff</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="o">+</span> <span class="mf">1e-10</span>
                            
                            <span class="c1"># Repulsion kernel</span>
                            <span class="n">rep_coeff</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.0</span> <span class="o">/</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">+</span> <span class="n">a_val</span> <span class="o">*</span> <span class="p">(</span><span class="n">dist</span> <span class="o">**</span> <span class="n">b_exp</span><span class="p">))</span>
                            
                            <span class="c1"># Apply distance cutoff</span>
                            <span class="n">cutoff_scale</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">dist</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">cutoff</span><span class="p">)</span>
                            <span class="n">rep_coeff</span> <span class="o">=</span> <span class="n">rep_coeff</span> <span class="o">*</span> <span class="n">cutoff_scale</span>
                            
                            <span class="c1"># Apply force</span>
                            <span class="n">forces</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+=</span> <span class="p">(</span><span class="n">rep_coeff</span> <span class="o">*</span> <span class="n">diff</span> <span class="o">/</span> <span class="n">dist</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

        <span class="c1"># Apply cooling and clipping</span>
        <span class="n">forces</span> <span class="o">=</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">forces</span>
        <span class="n">forces</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">forces</span><span class="p">,</span> <span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">cutoff</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">cutoff</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">forces</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_optimize_layout</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">initial_positions</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Optimize the embedding layout using iterative force computation.</span>
<span class="sd">        </span>
<span class="sd">        This private method performs the main optimization loop, iteratively</span>
<span class="sd">        computing and applying forces to refine the embedding layout.</span>
<span class="sd">        </span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        initial_positions : torch.Tensor</span>
<span class="sd">            Initial embedding positions of shape (n_samples, n_components).</span>
<span class="sd">            </span>
<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        torch.Tensor</span>
<span class="sd">            Optimized final positions of shape (n_samples, n_components),</span>
<span class="sd">            normalized to zero mean and unit standard deviation.</span>
<span class="sd">            </span>
<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        Private method, should not be called directly. Used by fit_transform().</span>
<span class="sd">        </span>
<span class="sd">        The optimization uses a simple force-directed layout algorithm with</span>
<span class="sd">        linear cooling schedule.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">positions</span> <span class="o">=</span> <span class="n">initial_positions</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Optimizing layout for </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_n_samples</span><span class="si">}</span><span class="s2"> points...&quot;</span><span class="p">)</span>

        <span class="c1"># Optimization loop</span>
        <span class="k">for</span> <span class="n">iteration</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">max_iter_layout</span><span class="p">):</span>
            <span class="c1"># Compute forces correctly</span>
            <span class="n">forces</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_forces</span><span class="p">(</span><span class="n">positions</span><span class="p">,</span> <span class="n">iteration</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_iter_layout</span><span class="p">)</span>

            <span class="c1"># Update positions</span>
            <span class="n">positions</span> <span class="o">+=</span> <span class="n">forces</span>

            <span class="c1"># Log progress every 20th iteration</span>
            <span class="k">if</span> <span class="n">iteration</span> <span class="o">%</span> <span class="mi">20</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Iteration </span><span class="si">{</span><span class="n">iteration</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">max_iter_layout</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Final normalization</span>
        <span class="n">positions</span> <span class="o">-=</span> <span class="n">positions</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">positions</span> <span class="o">/=</span> <span class="n">positions</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">positions</span>

<div class="viewcode-block" id="DiRePyTorch.fit_transform">
<a class="viewcode-back" href="../../api/modules.html#dire_rapids.dire_pytorch.DiRePyTorch.fit_transform">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">fit_transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>  <span class="c1"># pylint: disable=unused-argument,arguments-differ</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Fit the DiRe model and transform data to low-dimensional embedding.</span>
<span class="sd">        </span>
<span class="sd">        This method performs the complete dimensionality reduction pipeline:</span>
<span class="sd">        1. Computes k-nearest neighbors graph</span>
<span class="sd">        2. Fits kernel parameters</span>
<span class="sd">        3. Initializes embedding with PCA or random projection</span>
<span class="sd">        4. Optimizes layout using force-directed algorithm</span>
<span class="sd">        </span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array-like of shape (n_samples, n_features)</span>
<span class="sd">            High-dimensional input data to transform.</span>
<span class="sd">        y : array-like of shape (n_samples,), optional</span>
<span class="sd">            Ignored. Present for scikit-learn API compatibility.</span>
<span class="sd">            </span>
<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        numpy.ndarray of shape (n_samples, n_components)</span>
<span class="sd">            Low-dimensional embedding of the input data.</span>
<span class="sd">            </span>
<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        Transform high-dimensional data::</span>
<span class="sd">        </span>
<span class="sd">            import numpy as np</span>
<span class="sd">            from dire_rapids import DiRePyTorch</span>
<span class="sd">            </span>
<span class="sd">            X = np.random.randn(1000, 100)</span>
<span class="sd">            reducer = DiRePyTorch(n_neighbors=16)</span>
<span class="sd">            embedding = reducer.fit_transform(X)</span>
<span class="sd">            print(embedding.shape)  # (1000, 2)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Store data</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_n_samples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Processing </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_n_samples</span><span class="si">}</span><span class="s2"> samples with </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2"> features&quot;</span><span class="p">)</span>

        <span class="c1"># Find distribution kernel parameters</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_find_ab_params</span><span class="p">()</span>

        <span class="c1"># Compute k-NN graph</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_compute_knn</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_data</span><span class="p">)</span>

        <span class="c1"># Initialize embedding</span>
        <span class="n">initial_embedding</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_initialize_embedding</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_data</span><span class="p">)</span>

        <span class="c1"># Optimize layout</span>
        <span class="n">final_embedding</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_optimize_layout</span><span class="p">(</span><span class="n">initial_embedding</span><span class="p">)</span>

        <span class="c1"># Convert back to numpy and store</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_layout</span> <span class="o">=</span> <span class="n">final_embedding</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

        <span class="c1"># Clear GPU memory</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="s1">&#39;cuda&#39;</span><span class="p">:</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>
        <span class="n">gc</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_layout</span></div>


<div class="viewcode-block" id="DiRePyTorch.fit">
<a class="viewcode-back" href="../../api/modules.html#dire_rapids.dire_pytorch.DiRePyTorch.fit">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>  <span class="c1"># pylint: disable=unused-argument,arguments-differ</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Fit the DiRe model to data without transforming.</span>
<span class="sd">        </span>
<span class="sd">        This method fits the model by computing the k-NN graph, kernel parameters,</span>
<span class="sd">        and optimized embedding, but primarily serves for scikit-learn compatibility.</span>
<span class="sd">        For practical use, fit_transform() is recommended.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : numpy.ndarray of shape (n_samples, n_features)</span>
<span class="sd">            High-dimensional data to fit the model to.</span>
<span class="sd">        y : array-like of shape (n_samples,), optional</span>
<span class="sd">            Ignored. Present for scikit-learn API compatibility.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        self : DiRePyTorch</span>
<span class="sd">            The fitted DiRe instance.</span>
<span class="sd">            </span>
<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        This method calls fit_transform() internally. The embedding result</span>
<span class="sd">        is stored in self._layout and can be accessed after fitting.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span></div>


<div class="viewcode-block" id="DiRePyTorch.visualize">
<a class="viewcode-back" href="../../api/modules.html#dire_rapids.dire_pytorch.DiRePyTorch.visualize">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">visualize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">point_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">max_points</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Create an interactive visualization of the embedding.</span>

<span class="sd">        Uses WebGL rendering (Scattergl) for performance and automatically</span>
<span class="sd">        subsamples to max_points if dataset is larger.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        labels : array-like of shape (n_samples,), optional</span>
<span class="sd">            Labels for coloring points in the visualization.</span>
<span class="sd">        point_size : int, default=2</span>
<span class="sd">            Size of points in the scatter plot.</span>
<span class="sd">        title : str, optional</span>
<span class="sd">            Title for the plot. If None, a default title is generated.</span>
<span class="sd">        max_points : int, default=10000</span>
<span class="sd">            Maximum number of points to display. Subsamples if larger.</span>
<span class="sd">        **kwargs : dict</span>
<span class="sd">            Additional keyword arguments passed to plotly.express plotting functions.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        plotly.graph_objects.Figure or None</span>
<span class="sd">            Interactive Plotly figure, or None if no embedding is available.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        Basic visualization::</span>

<span class="sd">            fig = reducer.visualize()</span>
<span class="sd">            fig.show()</span>

<span class="sd">        With labels and custom styling::</span>

<span class="sd">            fig = reducer.visualize(</span>
<span class="sd">                labels=y,</span>
<span class="sd">                point_size=3,</span>
<span class="sd">                title=&quot;My Embedding&quot;,</span>
<span class="sd">                max_points=20000,</span>
<span class="sd">                width=800,</span>
<span class="sd">                height=600</span>
<span class="sd">            )</span>
<span class="sd">            fig.show()</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        Requires a fitted model with available embedding (self._layout).</span>
<span class="sd">        Only supports 2D and 3D visualizations.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_layout</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;No layout available for visualization&quot;</span><span class="p">)</span>
            <span class="k">return</span> <span class="kc">None</span>

        <span class="k">if</span> <span class="n">title</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">title</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;PyTorch </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">n_components</span><span class="si">}</span><span class="s2">D Embedding&quot;</span>

        <span class="c1"># Subsample if needed</span>
        <span class="n">n_points</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_layout</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">n_points</span> <span class="o">&gt;</span> <span class="n">max_points</span><span class="p">:</span>
            <span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
            <span class="n">subsample_idx</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">n_points</span><span class="p">,</span> <span class="n">max_points</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="n">layout_vis</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_layout</span><span class="p">[</span><span class="n">subsample_idx</span><span class="p">]</span>
            <span class="n">labels_vis</span> <span class="o">=</span> <span class="n">labels</span><span class="p">[</span><span class="n">subsample_idx</span><span class="p">]</span> <span class="k">if</span> <span class="n">labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">layout_vis</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_layout</span>
            <span class="n">labels_vis</span> <span class="o">=</span> <span class="n">labels</span>

        <span class="c1"># Create dataframe</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_components</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
            <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">layout_vis</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="s1">&#39;y&#39;</span><span class="p">])</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_components</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
            <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">layout_vis</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="s1">&#39;z&#39;</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Cannot visualize </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">n_components</span><span class="si">}</span><span class="s2">D embedding&quot;</span><span class="p">)</span>
            <span class="k">return</span> <span class="kc">None</span>

        <span class="c1"># Add labels if provided</span>
        <span class="k">if</span> <span class="n">labels_vis</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">df</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">labels_vis</span>

        <span class="c1"># Create plot</span>
        <span class="n">vis_params</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s1">&#39;color&#39;</span><span class="p">:</span> <span class="s1">&#39;label&#39;</span> <span class="k">if</span> <span class="n">labels_vis</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
            <span class="s1">&#39;title&#39;</span><span class="p">:</span> <span class="n">title</span><span class="p">,</span>
        <span class="p">}</span>
        <span class="n">vis_params</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_components</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
            <span class="n">fig</span> <span class="o">=</span> <span class="n">px</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="o">**</span><span class="n">vis_params</span><span class="p">)</span>
            <span class="c1"># Convert to WebGL for performance</span>
            <span class="k">for</span> <span class="n">trace</span> <span class="ow">in</span> <span class="n">fig</span><span class="o">.</span><span class="n">data</span><span class="p">:</span>
                <span class="n">trace</span><span class="o">.</span><span class="n">type</span> <span class="o">=</span> <span class="s1">&#39;scattergl&#39;</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">fig</span> <span class="o">=</span> <span class="n">px</span><span class="o">.</span><span class="n">scatter_3d</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="n">z</span><span class="o">=</span><span class="s1">&#39;z&#39;</span><span class="p">,</span> <span class="o">**</span><span class="n">vis_params</span><span class="p">)</span>

        <span class="n">fig</span><span class="o">.</span><span class="n">update_traces</span><span class="p">(</span><span class="n">marker</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;size&#39;</span><span class="p">:</span> <span class="n">point_size</span><span class="p">,</span> <span class="s1">&#39;opacity&#39;</span><span class="p">:</span> <span class="mf">0.7</span><span class="p">})</span>

        <span class="k">return</span> <span class="n">fig</span></div>
</div>



<div class="viewcode-block" id="create_dire">
<a class="viewcode-back" href="../../api/modules.html#dire_rapids.dire_pytorch.create_dire">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">create_dire</span><span class="p">(</span><span class="n">backend</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span> <span class="n">memory_efficient</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create DiRe instance with automatic backend selection.</span>

<span class="sd">    This factory function automatically selects the optimal DiRe implementation</span>
<span class="sd">    based on available hardware and software, or allows manual backend selection.</span>
<span class="sd">    It provides a convenient interface for creating DiRe instances without</span>
<span class="sd">    importing specific backend classes.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    backend : {&#39;auto&#39;, &#39;cuvs&#39;, &#39;pytorch&#39;, &#39;pytorch_gpu&#39;, &#39;pytorch_cpu&#39;}, default=&#39;auto&#39;</span>
<span class="sd">        Backend selection strategy:</span>

<span class="sd">        - &#39;auto&#39;: Automatically select best available backend based on hardware</span>
<span class="sd">        - &#39;cuvs&#39;: Force RAPIDS cuVS backend (requires RAPIDS installation)</span>
<span class="sd">        - &#39;pytorch&#39;: Force PyTorch backend with automatic device selection</span>
<span class="sd">        - &#39;pytorch_gpu&#39;: Force PyTorch backend on GPU (requires CUDA)</span>
<span class="sd">        - &#39;pytorch_cpu&#39;: Force PyTorch backend on CPU only</span>

<span class="sd">    memory_efficient : bool, default=False</span>
<span class="sd">        If True, use memory-efficient PyTorch implementation which provides:</span>

<span class="sd">        - Reduced memory usage for large datasets</span>
<span class="sd">        - FP16 support for additional memory savings</span>
<span class="sd">        - Enhanced chunking strategies</span>
<span class="sd">        - More aggressive memory cleanup</span>

<span class="sd">    **kwargs : dict</span>
<span class="sd">        Additional keyword arguments passed to the DiRe constructor.</span>
<span class="sd">        See individual backend documentation for available parameters.</span>
<span class="sd">        Common parameters include: n_components, n_neighbors, metric,</span>
<span class="sd">        max_iter_layout, min_dist, spread, verbose, random_state.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    DiRe instance</span>
<span class="sd">        An instance of the selected DiRe backend (DiRePyTorch, DiRePyTorchMemoryEfficient,</span>
<span class="sd">        or DiReCuVS) configured with the specified parameters.</span>

<span class="sd">    Raises</span>
<span class="sd">    ------</span>
<span class="sd">    RuntimeError</span>
<span class="sd">        If a specific backend is requested but requirements are not met</span>
<span class="sd">        (e.g., requesting cuVS without RAPIDS, or GPU without CUDA).</span>
<span class="sd">    ValueError</span>
<span class="sd">        If an unknown backend name is specified.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    Auto-select optimal backend::\n</span>
<span class="sd">        from dire_rapids import create_dire</span>

<span class="sd">        # Will use cuVS if available, otherwise PyTorch with GPU if available</span>
<span class="sd">        reducer = create_dire(n_neighbors=32, verbose=True)</span>
<span class="sd">        embedding = reducer.fit_transform(X)</span>

<span class="sd">    Force memory-efficient mode for large datasets::\n</span>
<span class="sd">        reducer = create_dire(</span>
<span class="sd">            memory_efficient=True,</span>
<span class="sd">            n_neighbors=50,</span>
<span class="sd">            max_iter_layout=200</span>
<span class="sd">        )</span>

<span class="sd">    Force specific backend::\n</span>
<span class="sd">        # CPU-only processing</span>
<span class="sd">        reducer = create_dire(backend=&#39;pytorch_cpu&#39;)</span>

<span class="sd">        # GPU processing with cuVS acceleration</span>
<span class="sd">        reducer = create_dire(backend=&#39;cuvs&#39;, use_cuvs=True)</span>

<span class="sd">        # With custom distance metric</span>
<span class="sd">        reducer = create_dire(</span>
<span class="sd">            metric=&#39;(x - y).abs().sum(-1)&#39;,  # L1 distance</span>
<span class="sd">            n_neighbors=32,</span>
<span class="sd">            verbose=True</span>
<span class="sd">        )</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    Backend Selection Priority (when backend=&#39;auto&#39;):</span>
<span class="sd">    1. RAPIDS cuVS (if available and CUDA GPU present)</span>
<span class="sd">    2. PyTorch with CUDA (if CUDA GPU available)</span>
<span class="sd">    3. PyTorch with CPU (fallback)</span>

<span class="sd">    The function automatically handles import errors and missing dependencies,</span>
<span class="sd">    falling back to available alternatives when possible.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Handle verbose parameter early to disable logging if needed</span>
    <span class="n">verbose</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;verbose&#39;</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>

    <span class="c1"># Import here to avoid circular imports</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">.dire_cuvs</span><span class="w"> </span><span class="kn">import</span> <span class="n">DiReCuVS</span>
        <span class="n">CUVS_AVAILABLE</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
        <span class="n">CUVS_AVAILABLE</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="kn">from</span><span class="w"> </span><span class="nn">.dire_pytorch_memory_efficient</span><span class="w"> </span><span class="kn">import</span> <span class="n">DiRePyTorchMemoryEfficient</span>

    <span class="k">if</span> <span class="n">backend</span> <span class="o">==</span> <span class="s1">&#39;auto&#39;</span><span class="p">:</span>
        <span class="c1"># Auto-select best backend based on availability</span>
        <span class="k">if</span> <span class="n">CUVS_AVAILABLE</span> <span class="ow">and</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Auto-selected RAPIDS cuVS backend (GPU acceleration)&quot;</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">DiReCuVS</span><span class="p">(</span><span class="n">use_cuvs</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">memory_efficient</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Auto-selected memory-efficient PyTorch backend (GPU)&quot;</span><span class="p">)</span>
                <span class="k">return</span> <span class="n">DiRePyTorchMemoryEfficient</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Auto-selected PyTorch backend (GPU)&quot;</span><span class="p">)</span>
                <span class="k">return</span> <span class="n">DiRePyTorch</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="c1"># CPU fallback</span>
        <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Auto-selected PyTorch backend (CPU)&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">memory_efficient</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;Memory-efficient mode has limited benefits on CPU&quot;</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">DiRePyTorchMemoryEfficient</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">DiRePyTorch</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="k">elif</span> <span class="n">backend</span> <span class="o">==</span> <span class="s1">&#39;cuvs&#39;</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">CUVS_AVAILABLE</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="s2">&quot;cuVS backend requested but RAPIDS not installed. &quot;</span>
                <span class="s2">&quot;Follow the installation instructions at https://docs.rapids.ai/install/&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;cuVS backend requires CUDA GPU&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Using RAPIDS cuVS backend&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">DiReCuVS</span><span class="p">(</span><span class="n">use_cuvs</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="k">elif</span> <span class="n">backend</span> <span class="o">==</span> <span class="s1">&#39;pytorch&#39;</span><span class="p">:</span>
        <span class="c1"># Use PyTorch with auto device selection</span>
        <span class="k">if</span> <span class="n">memory_efficient</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Using memory-efficient PyTorch backend&quot;</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">DiRePyTorchMemoryEfficient</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Using PyTorch backend&quot;</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">DiRePyTorch</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="k">elif</span> <span class="n">backend</span> <span class="o">==</span> <span class="s1">&#39;pytorch_gpu&#39;</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;GPU requested but CUDA not available&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">memory_efficient</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Using memory-efficient PyTorch backend (GPU)&quot;</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">DiRePyTorchMemoryEfficient</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Using PyTorch backend (GPU)&quot;</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">DiRePyTorch</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="k">elif</span> <span class="n">backend</span> <span class="o">==</span> <span class="s1">&#39;pytorch_cpu&#39;</span><span class="p">:</span>
        <span class="c1"># Force CPU even if GPU is available</span>
        <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Using PyTorch backend (forced CPU)&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">memory_efficient</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;Memory-efficient mode has limited benefits on CPU&quot;</span><span class="p">)</span>
            <span class="c1"># Create instance and force CPU</span>
            <span class="n">reducer</span> <span class="o">=</span> <span class="n">DiRePyTorchMemoryEfficient</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">reducer</span> <span class="o">=</span> <span class="n">DiRePyTorch</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="n">reducer</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">reducer</span>

    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Unknown backend: </span><span class="si">{</span><span class="n">backend</span><span class="si">}</span><span class="s2">. &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;Choose from: &#39;auto&#39;, &#39;cuvs&#39;, &#39;pytorch&#39;, &#39;pytorch_gpu&#39;, &#39;pytorch_cpu&#39;&quot;</span>
        <span class="p">)</span></div>



<span class="c1"># ============================================================================</span>
<span class="c1"># ReducerRunner Framework - Benchmarking and Dataset Loading Utilities</span>
<span class="c1"># ============================================================================</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">inspect</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">re</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">time</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">gzip</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">shutil</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">urllib.request</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">dataclasses</span><span class="w"> </span><span class="kn">import</span> <span class="n">dataclass</span><span class="p">,</span> <span class="n">field</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pathlib</span><span class="w"> </span><span class="kn">import</span> <span class="n">Path</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Any</span><span class="p">,</span> <span class="n">Callable</span><span class="p">,</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">Union</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn</span><span class="w"> </span><span class="kn">import</span> <span class="n">datasets</span> <span class="k">as</span> <span class="n">skds</span>

<span class="k">try</span><span class="p">:</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">scipy</span><span class="w"> </span><span class="kn">import</span> <span class="n">sparse</span> <span class="k">as</span> <span class="n">sp</span>
<span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
    <span class="n">sp</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># sklearn normally pulls scipy in; keep soft guard</span>

<span class="n">TransformFn</span> <span class="o">=</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]],</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]]]</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_identity_transform</span><span class="p">(</span><span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]):</span>
    <span class="k">return</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span>


<span class="c1"># --------- minimal display helpers (so .visualize renders in Colab) ---------</span>

<span class="k">def</span><span class="w"> </span><span class="nf">_safe_init_plotly_renderer</span><span class="p">():</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="kn">import</span><span class="w"> </span><span class="nn">plotly.io</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pio</span>
        <span class="k">if</span> <span class="n">pio</span><span class="o">.</span><span class="n">renderers</span><span class="o">.</span><span class="n">default</span> <span class="ow">in</span> <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;auto&quot;</span><span class="p">):</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="kn">import</span><span class="w"> </span><span class="nn">google.colab</span>  <span class="c1"># noqa: F401</span>
                <span class="n">pio</span><span class="o">.</span><span class="n">renderers</span><span class="o">.</span><span class="n">default</span> <span class="o">=</span> <span class="s2">&quot;colab&quot;</span>
            <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
                <span class="n">pio</span><span class="o">.</span><span class="n">renderers</span><span class="o">.</span><span class="n">default</span> <span class="o">=</span> <span class="s2">&quot;notebook_connected&quot;</span>
    <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
        <span class="k">pass</span>

<span class="k">def</span><span class="w"> </span><span class="nf">_display_obj</span><span class="p">(</span><span class="n">obj</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">obj</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">False</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
        <span class="n">shown</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">for</span> <span class="n">it</span> <span class="ow">in</span> <span class="n">obj</span><span class="p">:</span>
            <span class="n">shown</span> <span class="o">=</span> <span class="n">_display_obj</span><span class="p">(</span><span class="n">it</span><span class="p">)</span> <span class="ow">or</span> <span class="n">shown</span>
        <span class="k">return</span> <span class="n">shown</span>
    <span class="c1"># Plotly</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="kn">import</span><span class="w"> </span><span class="nn">plotly.graph_objects</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">go</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">go</span><span class="o">.</span><span class="n">Figure</span><span class="p">):</span>
            <span class="n">_safe_init_plotly_renderer</span><span class="p">()</span>
            <span class="n">obj</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
            <span class="k">return</span> <span class="kc">True</span>
    <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
        <span class="k">pass</span>
    <span class="c1"># Matplotlib</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">matplotlib.figure</span><span class="w"> </span><span class="kn">import</span> <span class="n">Figure</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">matplotlib.axes</span><span class="w"> </span><span class="kn">import</span> <span class="n">Axes</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="p">(</span><span class="n">Figure</span><span class="p">,</span> <span class="n">Axes</span><span class="p">)):</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
            <span class="k">return</span> <span class="kc">True</span>
    <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
        <span class="k">pass</span>
    <span class="c1"># HTML / str</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="p">(</span><span class="nb">str</span><span class="p">,</span> <span class="nb">bytes</span><span class="p">)):</span>
        <span class="n">s</span> <span class="o">=</span> <span class="n">obj</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s2">&quot;utf-8&quot;</span><span class="p">,</span> <span class="s2">&quot;ignore&quot;</span><span class="p">)</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="nb">bytes</span><span class="p">)</span> <span class="k">else</span> <span class="n">obj</span>
        <span class="k">if</span> <span class="s2">&quot;&lt;&quot;</span> <span class="ow">in</span> <span class="n">s</span> <span class="ow">and</span> <span class="s2">&quot;&gt;&quot;</span> <span class="ow">in</span> <span class="n">s</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="kn">from</span><span class="w"> </span><span class="nn">IPython.display</span><span class="w"> </span><span class="kn">import</span> <span class="n">display</span><span class="p">,</span> <span class="n">HTML</span>
                <span class="n">display</span><span class="p">(</span><span class="n">HTML</span><span class="p">(</span><span class="n">s</span><span class="p">))</span>
            <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>  <span class="c1"># Fallback to print if IPython not available</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>
        <span class="k">return</span> <span class="kc">True</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">IPython.display</span><span class="w"> </span><span class="kn">import</span> <span class="n">display</span>
            <span class="n">display</span><span class="p">(</span><span class="n">obj</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="n">obj</span><span class="p">)</span>  <span class="c1"># Fallback to print if IPython not available</span>
        <span class="k">return</span> <span class="kc">True</span>
    <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">False</span>


<span class="c1"># --------- sklearn resolution ---------</span>

<span class="n">_SKLEARN_ALIASES</span> <span class="o">=</span> <span class="p">{</span>
    <span class="c1"># loaders</span>
    <span class="s2">&quot;iris&quot;</span><span class="p">:</span> <span class="s2">&quot;load_iris&quot;</span><span class="p">,</span>
    <span class="s2">&quot;digits&quot;</span><span class="p">:</span> <span class="s2">&quot;load_digits&quot;</span><span class="p">,</span>
    <span class="s2">&quot;wine&quot;</span><span class="p">:</span> <span class="s2">&quot;load_wine&quot;</span><span class="p">,</span>
    <span class="s2">&quot;breast_cancer&quot;</span><span class="p">:</span> <span class="s2">&quot;load_breast_cancer&quot;</span><span class="p">,</span>
    <span class="s2">&quot;diabetes&quot;</span><span class="p">:</span> <span class="s2">&quot;load_diabetes&quot;</span><span class="p">,</span>
    <span class="s2">&quot;linnerud&quot;</span><span class="p">:</span> <span class="s2">&quot;load_linnerud&quot;</span><span class="p">,</span>
    <span class="c1"># generators</span>
    <span class="s2">&quot;blobs&quot;</span><span class="p">:</span> <span class="s2">&quot;make_blobs&quot;</span><span class="p">,</span>
    <span class="s2">&quot;classification&quot;</span><span class="p">:</span> <span class="s2">&quot;make_classification&quot;</span><span class="p">,</span>
    <span class="s2">&quot;multilabel_classification&quot;</span><span class="p">:</span> <span class="s2">&quot;make_multilabel_classification&quot;</span><span class="p">,</span>
    <span class="s2">&quot;moons&quot;</span><span class="p">:</span> <span class="s2">&quot;make_moons&quot;</span><span class="p">,</span>
    <span class="s2">&quot;circles&quot;</span><span class="p">:</span> <span class="s2">&quot;make_circles&quot;</span><span class="p">,</span>
    <span class="s2">&quot;s_curve&quot;</span><span class="p">:</span> <span class="s2">&quot;make_s_curve&quot;</span><span class="p">,</span>
    <span class="s2">&quot;swiss_roll&quot;</span><span class="p">:</span> <span class="s2">&quot;make_swiss_roll&quot;</span><span class="p">,</span>
    <span class="s2">&quot;gaussian_quantiles&quot;</span><span class="p">:</span> <span class="s2">&quot;make_gaussian_quantiles&quot;</span><span class="p">,</span>
    <span class="s2">&quot;low_rank_matrix&quot;</span><span class="p">:</span> <span class="s2">&quot;make_low_rank_matrix&quot;</span><span class="p">,</span>
    <span class="s2">&quot;spd_matrix&quot;</span><span class="p">:</span> <span class="s2">&quot;make_spd_matrix&quot;</span><span class="p">,</span>
    <span class="s2">&quot;sparse_spd_matrix&quot;</span><span class="p">:</span> <span class="s2">&quot;make_sparse_spd_matrix&quot;</span><span class="p">,</span>
<span class="p">}</span>

<span class="k">def</span><span class="w"> </span><span class="nf">_normalize_key</span><span class="p">(</span><span class="n">s</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;[^a-z0-9_]+&quot;</span><span class="p">,</span> <span class="s2">&quot;_&quot;</span><span class="p">,</span> <span class="n">s</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="o">.</span><span class="n">lower</span><span class="p">())</span>

<span class="k">def</span><span class="w"> </span><span class="nf">_resolve_sklearn_function</span><span class="p">(</span><span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
    <span class="n">n</span> <span class="o">=</span> <span class="n">_normalize_key</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">n</span><span class="o">.</span><span class="n">startswith</span><span class="p">((</span><span class="s2">&quot;load_&quot;</span><span class="p">,</span> <span class="s2">&quot;fetch_&quot;</span><span class="p">,</span> <span class="s2">&quot;make_&quot;</span><span class="p">)):</span>
        <span class="n">fn</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">skds</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">callable</span><span class="p">(</span><span class="n">fn</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">n</span><span class="p">,</span> <span class="n">fn</span>
    <span class="n">alias</span> <span class="o">=</span> <span class="n">_SKLEARN_ALIASES</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">alias</span> <span class="ow">and</span> <span class="nb">callable</span><span class="p">(</span><span class="nb">getattr</span><span class="p">(</span><span class="n">skds</span><span class="p">,</span> <span class="n">alias</span><span class="p">,</span> <span class="kc">None</span><span class="p">)):</span>
        <span class="k">return</span> <span class="n">alias</span><span class="p">,</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">skds</span><span class="p">,</span> <span class="n">alias</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">pref</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;load_&quot;</span><span class="p">,</span> <span class="s2">&quot;fetch_&quot;</span><span class="p">,</span> <span class="s2">&quot;make_&quot;</span><span class="p">):</span>
        <span class="n">cand</span> <span class="o">=</span> <span class="n">pref</span> <span class="o">+</span> <span class="n">n</span>
        <span class="n">fn</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">skds</span><span class="p">,</span> <span class="n">cand</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">callable</span><span class="p">(</span><span class="n">fn</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">cand</span><span class="p">,</span> <span class="n">fn</span>
    <span class="n">candidates</span> <span class="o">=</span> <span class="p">[</span>
        <span class="p">(</span><span class="n">attr</span><span class="p">,</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">skds</span><span class="p">,</span> <span class="n">attr</span><span class="p">))</span>
        <span class="k">for</span> <span class="n">attr</span> <span class="ow">in</span> <span class="nb">dir</span><span class="p">(</span><span class="n">skds</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">attr</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="n">n</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">callable</span><span class="p">(</span><span class="nb">getattr</span><span class="p">(</span><span class="n">skds</span><span class="p">,</span> <span class="n">attr</span><span class="p">))</span>
    <span class="p">]</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">candidates</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">candidates</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">candidates</span><span class="p">:</span>
        <span class="n">names</span> <span class="o">=</span> <span class="s2">&quot;, &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">a</span> <span class="k">for</span> <span class="n">a</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">candidates</span><span class="p">[:</span><span class="mi">6</span><span class="p">])</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Ambiguous sklearn dataset &#39;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">&#39;. Candidates: </span><span class="si">{</span><span class="n">names</span><span class="si">}</span><span class="s2"> ...&quot;</span><span class="p">)</span>
    <span class="n">all_names</span> <span class="o">=</span> <span class="s2">&quot;, &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">a</span> <span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="nb">dir</span><span class="p">(</span><span class="n">skds</span><span class="p">)</span> <span class="k">if</span> <span class="n">a</span><span class="o">.</span><span class="n">startswith</span><span class="p">((</span><span class="s2">&quot;load_&quot;</span><span class="p">,</span> <span class="s2">&quot;fetch_&quot;</span><span class="p">,</span> <span class="s2">&quot;make_&quot;</span><span class="p">)))</span>
    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unknown sklearn dataset &#39;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">&#39;. Available include: </span><span class="si">{</span><span class="n">all_names</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_to_Xy_from_obj</span><span class="p">(</span><span class="n">obj</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]]:</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="p">(</span><span class="nb">tuple</span><span class="p">,</span> <span class="nb">list</span><span class="p">))</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">obj</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">obj</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">obj</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">obj</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="k">else</span> <span class="kc">None</span>
        <span class="k">return</span> <span class="n">_coerce_Xy</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="s2">&quot;get&quot;</span><span class="p">):</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">obj</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;data&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="n">target</span> <span class="o">=</span> <span class="n">obj</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;target&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="n">images</span> <span class="o">=</span> <span class="n">obj</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;images&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">data</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">images</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">imgs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>
            <span class="n">data</span> <span class="o">=</span> <span class="n">imgs</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">imgs</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">_coerce_Xy</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="s2">&quot;shape&quot;</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">_coerce_Xy</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Unsupported sklearn return type; cannot coerce to (X, y).&quot;</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_coerce_Xy</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]]:</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="ow">and</span> <span class="n">X</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="nb">str</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;Loaded dataset contains text data; vectorize first.&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">sp</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">sp</span><span class="o">.</span><span class="n">issparse</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">y</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">X</span><span class="p">,</span> <span class="kc">None</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">y</span><span class="o">.</span><span class="n">dtype</span><span class="o">.</span><span class="n">kind</span> <span class="ow">in</span> <span class="p">{</span><span class="s2">&quot;U&quot;</span><span class="p">,</span> <span class="s2">&quot;S&quot;</span><span class="p">,</span> <span class="s2">&quot;O&quot;</span><span class="p">}:</span>
        <span class="n">uniq</span> <span class="o">=</span> <span class="p">{</span><span class="n">v</span><span class="p">:</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y</span><span class="p">))}</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">uniq</span><span class="p">[</span><span class="n">v</span><span class="p">]</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">y</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_load_sklearn_any</span><span class="p">(</span><span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]]:</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">fn</span> <span class="o">=</span> <span class="n">_resolve_sklearn_function</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">sig</span> <span class="o">=</span> <span class="n">inspect</span><span class="o">.</span><span class="n">signature</span><span class="p">(</span><span class="n">fn</span><span class="p">)</span>
        <span class="k">if</span> <span class="s2">&quot;return_X_y&quot;</span> <span class="ow">in</span> <span class="n">sig</span><span class="o">.</span><span class="n">parameters</span><span class="p">:</span>
            <span class="n">obj</span> <span class="o">=</span> <span class="n">fn</span><span class="p">(</span><span class="n">return_X_y</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
            <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">_to_Xy_from_obj</span><span class="p">(</span><span class="n">obj</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">obj</span> <span class="o">=</span> <span class="n">fn</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
            <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">_to_Xy_from_obj</span><span class="p">(</span><span class="n">obj</span><span class="p">)</span>
    <span class="k">except</span> <span class="ne">TypeError</span><span class="p">:</span>
        <span class="n">obj</span> <span class="o">=</span> <span class="n">fn</span><span class="p">()</span>
        <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">_to_Xy_from_obj</span><span class="p">(</span><span class="n">obj</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span>


<span class="c1"># --------- file loader ---------</span>

<span class="k">def</span><span class="w"> </span><span class="nf">_load_file</span><span class="p">(</span><span class="n">path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]]:</span>
    <span class="n">path</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
    <span class="n">ext</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">path</span><span class="p">)</span><span class="o">.</span><span class="n">suffix</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>

    <span class="k">if</span> <span class="n">ext</span> <span class="o">==</span> <span class="s2">&quot;.csv&quot;</span><span class="p">:</span>
        <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
        <span class="n">label_col</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;label_column&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">label_col</span> <span class="ow">and</span> <span class="n">label_col</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>
            <span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">label_col</span><span class="p">]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
            <span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="n">label_col</span><span class="p">])</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">y</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span>

    <span class="k">if</span> <span class="n">ext</span> <span class="o">==</span> <span class="s2">&quot;.parquet&quot;</span><span class="p">:</span>
        <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_parquet</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
        <span class="n">label_col</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;label_column&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">label_col</span> <span class="ow">and</span> <span class="n">label_col</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>
            <span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">label_col</span><span class="p">]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
            <span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="n">label_col</span><span class="p">])</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">y</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span>

    <span class="k">if</span> <span class="n">ext</span> <span class="o">==</span> <span class="s2">&quot;.npy&quot;</span><span class="p">:</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">mmap_mode</span><span class="o">=</span><span class="s2">&quot;r&quot;</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">labels_path</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;labels_path&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">labels_path</span><span class="p">:</span>
            <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">labels_path</span><span class="p">,</span> <span class="n">mmap_mode</span><span class="o">=</span><span class="s2">&quot;r&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">y</span>

    <span class="k">if</span> <span class="n">ext</span> <span class="o">==</span> <span class="s2">&quot;.npz&quot;</span><span class="p">:</span>
        <span class="n">f</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">mmap_mode</span><span class="o">=</span><span class="s2">&quot;r&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="s2">&quot;X&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">f</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;.npz must contain key &#39;X&#39; (and optionally &#39;y&#39;).&quot;</span><span class="p">)</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">f</span><span class="p">[</span><span class="s2">&quot;X&quot;</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">f</span><span class="p">[</span><span class="s2">&quot;y&quot;</span><span class="p">]</span> <span class="k">if</span> <span class="s2">&quot;y&quot;</span> <span class="ow">in</span> <span class="n">f</span> <span class="k">else</span> <span class="kc">None</span>
        <span class="k">return</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span>

    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unsupported file type &#39;</span><span class="si">{</span><span class="n">ext</span><span class="si">}</span><span class="s2">&#39;. Use .csv, .npy, .npz, or .parquet.&quot;</span><span class="p">)</span>


<span class="c1"># --------- DiRe geometric datasets ---------</span>

<div class="viewcode-block" id="rand_point_disk">
<a class="viewcode-back" href="../../api/dire_rapids.dire_pytorch.html#dire_rapids.dire_pytorch.rand_point_disk">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">rand_point_disk</span><span class="p">(</span><span class="n">n_features</span><span class="p">,</span> <span class="n">n_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Generate uniformly distributed points in n-dimensional unit disk.&quot;&quot;&quot;</span>
    <span class="n">prepts</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">n_features</span><span class="p">)</span>
    <span class="n">prenorms</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">prepts</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">rads</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">n_samples</span><span class="p">))</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">pts</span> <span class="o">=</span> <span class="n">prepts</span> <span class="o">*</span> <span class="n">rads</span> <span class="o">/</span> <span class="n">prenorms</span>
    <span class="k">return</span> <span class="n">pts</span></div>



<div class="viewcode-block" id="rand_point_sphere">
<a class="viewcode-back" href="../../api/dire_rapids.dire_pytorch.html#dire_rapids.dire_pytorch.rand_point_sphere">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">rand_point_sphere</span><span class="p">(</span><span class="n">n_features</span><span class="p">,</span> <span class="n">n_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Generate uniformly distributed points on n-dimensional unit sphere.&quot;&quot;&quot;</span>
    <span class="n">prepts</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">n_features</span><span class="p">)</span>
    <span class="n">prenorms</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">prepts</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">pts</span> <span class="o">=</span> <span class="n">prepts</span> <span class="o">/</span> <span class="n">prenorms</span>
    <span class="k">return</span> <span class="n">pts</span></div>



<div class="viewcode-block" id="elgen">
<a class="viewcode-back" href="../../api/dire_rapids.dire_pytorch.html#dire_rapids.dire_pytorch.elgen">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">elgen</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Ellipsoid generator - transforms sphere points to ellipsoid.&quot;&quot;&quot;</span>
<div class="viewcode-block" id="elgen.__init__">
<a class="viewcode-back" href="../../api/dire_rapids.dire_pytorch.html#dire_rapids.dire_pytorch.elgen.__init__">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">a</span><span class="p">):</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
        <span class="n">themat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="n">a</span> <span class="o">*</span> <span class="n">a</span><span class="p">))</span>
        <span class="n">L</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">cholesky</span><span class="p">(</span><span class="n">themat</span><span class="p">)</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">L</span> <span class="o">=</span> <span class="n">L</span></div>


    <span class="k">def</span><span class="w"> </span><span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ar</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">L</span> <span class="o">@</span> <span class="n">ar</span><span class="o">.</span><span class="n">T</span><span class="p">)</span><span class="o">.</span><span class="n">T</span></div>



<div class="viewcode-block" id="rand_point_ell">
<a class="viewcode-back" href="../../api/dire_rapids.dire_pytorch.html#dire_rapids.dire_pytorch.rand_point_ell">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">rand_point_ell</span><span class="p">(</span><span class="n">semi_axes</span><span class="p">,</span> <span class="n">n_features</span><span class="p">,</span> <span class="n">n_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Generate uniformly distributed points on n-dimensional ellipsoid with semi-axes.&quot;&quot;&quot;</span>
    <span class="n">spts</span> <span class="o">=</span> <span class="n">rand_point_sphere</span><span class="p">(</span><span class="n">n_features</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">)</span>
    <span class="n">eg</span> <span class="o">=</span> <span class="n">elgen</span><span class="p">(</span><span class="n">semi_axes</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">eg</span><span class="p">(</span><span class="n">spts</span><span class="p">)</span></div>



<span class="k">def</span><span class="w"> </span><span class="nf">_load_dire_dataset</span><span class="p">(</span><span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Load DiRe geometric datasets.</span>

<span class="sd">    Supported:</span>
<span class="sd">    - &#39;disk_uniform&#39;: Uniform in n-dimensional unit disk</span>
<span class="sd">    - &#39;sphere_uniform&#39;: Uniform on n-dimensional unit sphere</span>
<span class="sd">    - &#39;ellipsoid_uniform&#39;: Uniform on n-dimensional ellipsoid</span>

<span class="sd">    Options:</span>
<span class="sd">    - n_samples (default 1000)</span>
<span class="sd">    - n_features (default 10)</span>
<span class="sd">    - semi_axes (for ellipsoid, default [1, 2, ..., n])</span>
<span class="sd">    - random_state</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">key</span> <span class="o">=</span> <span class="n">_normalize_key</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>

    <span class="n">n_samples</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">&#39;n_samples&#39;</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>
    <span class="n">n_features</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">&#39;n_features&#39;</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
    <span class="n">random_state</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">&#39;random_state&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">random_state</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">random_state</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">key</span> <span class="o">==</span> <span class="s1">&#39;disk_uniform&#39;</span><span class="p">:</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">rand_point_disk</span><span class="p">(</span><span class="n">n_features</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">key</span> <span class="o">==</span> <span class="s1">&#39;sphere_uniform&#39;</span><span class="p">:</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">rand_point_sphere</span><span class="p">(</span><span class="n">n_features</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">key</span> <span class="o">==</span> <span class="s1">&#39;ellipsoid_uniform&#39;</span><span class="p">:</span>
        <span class="n">semi_axes</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">&#39;semi_axes&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">semi_axes</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">n_features</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">semi_axes</span><span class="p">)</span>  <span class="c1"># Infer n_features from semi_axes</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">semi_axes</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_features</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>  <span class="c1"># Default semi_axes</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">rand_point_ell</span><span class="p">(</span><span class="n">semi_axes</span><span class="p">,</span> <span class="n">n_features</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Unknown DiRe dataset &#39;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">&#39;. Options: &#39;disk_uniform&#39;, &#39;sphere_uniform&#39;, &#39;ellipsoid_uniform&#39;&quot;</span>
        <span class="p">)</span>

    <span class="k">return</span> <span class="n">X</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="kc">None</span>


<span class="c1"># --------- cytof scheme (Levine13/32) ---------</span>

<span class="n">_DEF_CACHE</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">expanduser</span><span class="p">(</span><span class="s2">&quot;~&quot;</span><span class="p">),</span> <span class="s2">&quot;.cache&quot;</span><span class="p">,</span> <span class="s2">&quot;reducer_runner&quot;</span><span class="p">,</span> <span class="s2">&quot;cytof&quot;</span><span class="p">)</span>
<span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">_DEF_CACHE</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">_download</span><span class="p">(</span><span class="n">url</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">dest</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">overwrite</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="k">if</span> <span class="p">(</span><span class="ow">not</span> <span class="n">overwrite</span><span class="p">)</span> <span class="ow">and</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">dest</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">dest</span>
    <span class="n">tmp</span> <span class="o">=</span> <span class="n">dest</span> <span class="o">+</span> <span class="s2">&quot;.part&quot;</span>
    <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="n">dest</span><span class="p">),</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">urllib</span><span class="o">.</span><span class="n">request</span><span class="o">.</span><span class="n">urlretrieve</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">tmp</span><span class="p">)</span>
    <span class="n">os</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">tmp</span><span class="p">,</span> <span class="n">dest</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">dest</span>

<span class="k">def</span><span class="w"> </span><span class="nf">_safe_gunzip</span><span class="p">(</span><span class="n">path</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">path</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s2">&quot;.gz&quot;</span><span class="p">):</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">path</span><span class="p">[:</span><span class="o">-</span><span class="mi">3</span><span class="p">]</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">out</span><span class="p">):</span>
            <span class="k">with</span> <span class="n">gzip</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="s2">&quot;rb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f_in</span><span class="p">,</span> <span class="nb">open</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="s2">&quot;wb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f_out</span><span class="p">:</span>
                <span class="n">shutil</span><span class="o">.</span><span class="n">copyfileobj</span><span class="p">(</span><span class="n">f_in</span><span class="p">,</span> <span class="n">f_out</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">out</span>
    <span class="k">return</span> <span class="n">path</span>

<span class="n">_CYTOF_REGISTRY</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;levine13&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">&quot;urls&quot;</span><span class="p">:</span> <span class="p">[</span>
            <span class="s2">&quot;https://raw.githubusercontent.com/lmweber/benchmark-data-Levine-13-dim/master/data/Levine_13dim.fcs&quot;</span><span class="p">,</span>
            <span class="s2">&quot;https://raw.githubusercontent.com/lmweber/benchmark-data-Levine-13-dim/master/data/Levine_13dim.txt&quot;</span><span class="p">,</span>
        <span class="p">],</span>
        <span class="s2">&quot;label_column&quot;</span><span class="p">:</span> <span class="s2">&quot;label&quot;</span><span class="p">,</span>
        <span class="s2">&quot;drop_columns&quot;</span><span class="p">:</span> <span class="p">(</span><span class="s2">&quot;label&quot;</span><span class="p">,</span> <span class="s2">&quot;individual&quot;</span><span class="p">),</span>
    <span class="p">},</span>
    <span class="s2">&quot;levine32&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">&quot;urls&quot;</span><span class="p">:</span> <span class="p">[</span>
            <span class="s2">&quot;https://raw.githubusercontent.com/lmweber/benchmark-data-Levine-32-dim/master/data/Levine_32dim.fcs&quot;</span><span class="p">,</span>
        <span class="p">],</span>
        <span class="s2">&quot;label_column&quot;</span><span class="p">:</span> <span class="s2">&quot;label&quot;</span><span class="p">,</span>
        <span class="s2">&quot;drop_columns&quot;</span><span class="p">:</span> <span class="p">(</span><span class="s2">&quot;label&quot;</span><span class="p">,</span> <span class="s2">&quot;individual&quot;</span><span class="p">),</span>
    <span class="p">},</span>
<span class="p">}</span>

<span class="k">def</span><span class="w"> </span><span class="nf">_load_cytof</span><span class="p">(</span><span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    CyTOF loader:</span>
<span class="sd">      - &#39;levine13&#39;</span>
<span class="sd">      - &#39;levine32&#39;</span>
<span class="sd">    via built-in URLs/caching</span>
<span class="sd">    Supports .txt/.tsv/.csv (pandas).</span>
<span class="sd">    Options:</span>
<span class="sd">      - url / file / cache_dir</span>
<span class="sd">      - label_column (for txt/csv/tsv)</span>
<span class="sd">      - drop_columns</span>
<span class="sd">      - arcsinh_cofactor (if raw)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">key</span> <span class="o">=</span> <span class="n">_normalize_key</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>
    <span class="n">spec</span> <span class="o">=</span> <span class="n">_CYTOF_REGISTRY</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">spec</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unknown cytof dataset &#39;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">&#39;. Options: </span><span class="si">{</span><span class="nb">tuple</span><span class="p">(</span><span class="n">_CYTOF_REGISTRY</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="n">cache_dir</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;cache_dir&quot;</span><span class="p">,</span> <span class="n">_DEF_CACHE</span><span class="p">)</span>
    <span class="n">url</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;url&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
    <span class="n">label_col</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;label_column&quot;</span><span class="p">,</span> <span class="n">spec</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;label_column&quot;</span><span class="p">,</span> <span class="s2">&quot;label&quot;</span><span class="p">))</span>
    <span class="n">drop_cols</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;drop_columns&quot;</span><span class="p">,</span> <span class="n">spec</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;drop_columns&quot;</span><span class="p">,</span> <span class="p">(</span><span class="n">label_col</span><span class="p">,))))</span>
    <span class="n">drop_unassigned</span> <span class="o">=</span> <span class="nb">bool</span><span class="p">(</span><span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;drop_unassigned&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">))</span>
    <span class="n">arcsinh_cofactor</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;arcsinh_cofactor&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
    <span class="n">local_path</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;file&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

    <span class="c1"># Resolve local or download</span>
    <span class="k">if</span> <span class="n">local_path</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">urls</span> <span class="o">=</span> <span class="p">[</span><span class="n">url</span><span class="p">]</span> <span class="k">if</span> <span class="n">url</span> <span class="k">else</span> <span class="n">spec</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;urls&quot;</span><span class="p">,</span> <span class="p">[])</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">urls</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;cytof:</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2"> requires &#39;url&#39; or local &#39;file&#39; path.&quot;</span><span class="p">)</span>
        <span class="n">last_err</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">for</span> <span class="n">u</span> <span class="ow">in</span> <span class="n">urls</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">fname</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">cache_dir</span><span class="p">,</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">basename</span><span class="p">(</span><span class="n">u</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;?&quot;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]))</span>
                <span class="n">local_path</span> <span class="o">=</span> <span class="n">_download</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">fname</span><span class="p">)</span>
                <span class="k">break</span>
            <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="n">last_err</span> <span class="o">=</span> <span class="n">e</span>
                <span class="n">local_path</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="n">local_path</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Failed to download cytof:</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">last_err</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="n">path</span> <span class="o">=</span> <span class="n">_safe_gunzip</span><span class="p">(</span><span class="n">local_path</span><span class="p">)</span>
    <span class="n">ext</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">path</span><span class="p">)</span><span class="o">.</span><span class="n">suffix</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>

    <span class="c1"># ---------- FCS via flowio ----------</span>
    <span class="k">if</span> <span class="n">ext</span> <span class="o">==</span> <span class="s2">&quot;.fcs&quot;</span><span class="p">:</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="kn">import</span><span class="w"> </span><span class="nn">flowio</span>
        <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ImportError</span><span class="p">(</span><span class="s2">&quot;flowio required for FCS files. Install with: pip install flowio&quot;</span><span class="p">)</span>

        <span class="n">fcs</span> <span class="o">=</span> <span class="n">flowio</span><span class="o">.</span><span class="n">FlowData</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">fcs</span><span class="o">.</span><span class="n">as_array</span><span class="p">()</span>  <span class="c1"># Get 2D numpy array with preprocessing</span>

        <span class="c1"># Get channel names from pnn_labels (parameter names)</span>
        <span class="n">channel_names</span> <span class="o">=</span> <span class="n">fcs</span><span class="o">.</span><span class="n">pnn_labels</span> <span class="k">if</span> <span class="n">fcs</span><span class="o">.</span><span class="n">pnn_labels</span> <span class="k">else</span> <span class="p">[</span><span class="sa">f</span><span class="s1">&#39;Ch</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">&#39;</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">fcs</span><span class="o">.</span><span class="n">channel_count</span><span class="p">)]</span>

        <span class="c1"># Create DataFrame from FCS data</span>
        <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">channel_names</span><span class="p">)</span>

        <span class="c1"># Drop rows with null labels if requested</span>
        <span class="k">if</span> <span class="n">drop_unassigned</span> <span class="ow">and</span> <span class="n">label_col</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>
            <span class="n">before</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
            <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="n">label_col</span><span class="p">]</span><span class="o">.</span><span class="n">notna</span><span class="p">()]</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
            <span class="n">after</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[cytof] dropped </span><span class="si">{</span><span class="n">before</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">after</span><span class="si">}</span><span class="s2"> rows with null labels&quot;</span><span class="p">)</span>

        <span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">label_col</span><span class="p">]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span> <span class="k">if</span> <span class="n">label_col</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span> <span class="k">else</span> <span class="kc">None</span>
        <span class="n">drop</span> <span class="o">=</span> <span class="p">[</span><span class="n">c</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">drop_cols</span> <span class="k">if</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">]</span>
        <span class="n">Xdf</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="n">drop</span><span class="p">,</span> <span class="n">errors</span><span class="o">=</span><span class="s2">&quot;ignore&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">select_dtypes</span><span class="p">(</span><span class="n">include</span><span class="o">=</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">number</span><span class="p">])</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">Xdf</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">copy</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

        <span class="k">if</span> <span class="p">(</span><span class="n">arcsinh_cofactor</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">and</span> <span class="n">arcsinh_cofactor</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arcsinh</span><span class="p">(</span><span class="n">X</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">arcsinh_cofactor</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

        <span class="c1"># map string labels to ints</span>
        <span class="k">if</span> <span class="n">y</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">y</span><span class="o">.</span><span class="n">dtype</span><span class="o">.</span><span class="n">kind</span> <span class="ow">in</span> <span class="p">{</span><span class="s2">&quot;U&quot;</span><span class="p">,</span> <span class="s2">&quot;S&quot;</span><span class="p">,</span> <span class="s2">&quot;O&quot;</span><span class="p">}:</span>
                <span class="n">uniq</span> <span class="o">=</span> <span class="p">{</span><span class="n">v</span><span class="p">:</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y</span><span class="p">))}</span>
                <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">uniq</span><span class="p">[</span><span class="n">v</span><span class="p">]</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">y</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">y</span><span class="o">.</span><span class="n">dtype</span><span class="o">.</span><span class="n">kind</span> <span class="o">==</span> <span class="s2">&quot;f&quot;</span><span class="p">:</span>  <span class="c1"># floating point labels</span>
                <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span>

    <span class="c1"># ---------- TXT/TSV/CSV via pandas ----------</span>
    <span class="k">if</span> <span class="n">ext</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;.txt&quot;</span><span class="p">,</span> <span class="s2">&quot;.tsv&quot;</span><span class="p">,</span> <span class="s2">&quot;.csv&quot;</span><span class="p">):</span>
        <span class="n">sep</span> <span class="o">=</span> <span class="s2">&quot;</span><span class="se">\t</span><span class="s2">&quot;</span> <span class="k">if</span> <span class="n">ext</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;.txt&quot;</span><span class="p">,</span> <span class="s2">&quot;.tsv&quot;</span><span class="p">)</span> <span class="k">else</span> <span class="s2">&quot;,&quot;</span>
        <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="n">sep</span><span class="p">)</span>

        <span class="c1"># Drop rows with null labels if requested</span>
        <span class="k">if</span> <span class="n">drop_unassigned</span> <span class="ow">and</span> <span class="n">label_col</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>
            <span class="n">before</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
            <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="n">label_col</span><span class="p">]</span><span class="o">.</span><span class="n">notna</span><span class="p">()]</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
            <span class="n">after</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[cytof] dropped </span><span class="si">{</span><span class="n">before</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">after</span><span class="si">}</span><span class="s2"> rows with null labels&quot;</span><span class="p">)</span>

        <span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">label_col</span><span class="p">]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span> <span class="k">if</span> <span class="n">label_col</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span> <span class="k">else</span> <span class="kc">None</span>
        <span class="n">drop</span> <span class="o">=</span> <span class="p">[</span><span class="n">c</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">drop_cols</span> <span class="k">if</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">]</span>
        <span class="n">Xdf</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="n">drop</span><span class="p">,</span> <span class="n">errors</span><span class="o">=</span><span class="s2">&quot;ignore&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">select_dtypes</span><span class="p">(</span><span class="n">include</span><span class="o">=</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">number</span><span class="p">])</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">Xdf</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">copy</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

        <span class="k">if</span> <span class="p">(</span><span class="n">arcsinh_cofactor</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">and</span> <span class="n">arcsinh_cofactor</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arcsinh</span><span class="p">(</span><span class="n">X</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">arcsinh_cofactor</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

        <span class="c1"># map string labels to ints</span>
        <span class="k">if</span> <span class="n">y</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">y</span><span class="o">.</span><span class="n">dtype</span><span class="o">.</span><span class="n">kind</span> <span class="ow">in</span> <span class="p">{</span><span class="s2">&quot;U&quot;</span><span class="p">,</span> <span class="s2">&quot;S&quot;</span><span class="p">,</span> <span class="s2">&quot;O&quot;</span><span class="p">}:</span>
                <span class="n">uniq</span> <span class="o">=</span> <span class="p">{</span><span class="n">v</span><span class="p">:</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y</span><span class="p">))}</span>
                <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">uniq</span><span class="p">[</span><span class="n">v</span><span class="p">]</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">y</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">y</span><span class="o">.</span><span class="n">dtype</span><span class="o">.</span><span class="n">kind</span> <span class="o">==</span> <span class="s2">&quot;f&quot;</span><span class="p">:</span>  <span class="c1"># floating point labels</span>
                <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span>

    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unsupported cytof file: </span><span class="si">{</span><span class="n">path</span><span class="si">}</span><span class="s2"> (use .fcs, .txt/.tsv, or .csv)&quot;</span><span class="p">)</span>



<span class="c1"># --------- ReducerConfig ---------</span>

<div class="viewcode-block" id="ReducerConfig">
<a class="viewcode-back" href="../../api/dire_rapids.dire_pytorch.html#dire_rapids.dire_pytorch.ReducerConfig">[docs]</a>
<span class="nd">@dataclass</span>
<span class="k">class</span><span class="w"> </span><span class="nc">ReducerConfig</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Configuration for a dimensionality reduction algorithm.</span>

<span class="sd">    All fields are mutable and can be changed after creation:</span>
<span class="sd">        config.visualize = True</span>
<span class="sd">        config.categorical_labels = False</span>
<span class="sd">        config.max_points = 20000</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">name</span><span class="p">:</span> <span class="nb">str</span>
    <span class="n">reducer_class</span><span class="p">:</span> <span class="nb">type</span>
    <span class="n">reducer_kwargs</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span>
    <span class="n">visualize</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">categorical_labels</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>  <span class="c1"># False for regression-style labels (swiss_roll, etc.)</span>
    <span class="n">max_points</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10000</span>  <span class="c1"># Max points for visualization (subsamples if larger)</span></div>



<span class="c1"># --------- selector parsing ---------</span>

<span class="k">def</span><span class="w"> </span><span class="nf">_parse_selector</span><span class="p">(</span><span class="n">selector</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]:</span>
    <span class="n">s</span> <span class="o">=</span> <span class="n">selector</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
    <span class="n">p</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">exists</span><span class="p">()</span> <span class="ow">or</span> <span class="n">re</span><span class="o">.</span><span class="n">search</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;\.(csv|np[yz]|parquet)$&quot;</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">re</span><span class="o">.</span><span class="n">I</span><span class="p">):</span>
        <span class="k">return</span> <span class="s2">&quot;file&quot;</span><span class="p">,</span> <span class="n">s</span>
    <span class="n">m</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">match</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;^(?P&lt;scheme&gt;[A-Za-z0-9_]+)[:\.](?P&lt;name&gt;.+)$&quot;</span><span class="p">,</span> <span class="n">s</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">m</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">m</span><span class="o">.</span><span class="n">group</span><span class="p">(</span><span class="s2">&quot;scheme&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">lower</span><span class="p">(),</span> <span class="n">m</span><span class="o">.</span><span class="n">group</span><span class="p">(</span><span class="s2">&quot;name&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
    <span class="k">return</span> <span class="s2">&quot;sklearn&quot;</span><span class="p">,</span> <span class="n">s</span>


<span class="c1"># --------- Runner ---------</span>

<div class="viewcode-block" id="ReducerRunner">
<a class="viewcode-back" href="../../api/dire_rapids.dire_pytorch.html#dire_rapids.dire_pytorch.ReducerRunner">[docs]</a>
<span class="nd">@dataclass</span>
<span class="k">class</span><span class="w"> </span><span class="nc">ReducerRunner</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    General-purpose runner for dimensionality reduction algorithms.</span>

<span class="sd">    Supports:</span>
<span class="sd">    - DiRe (create_dire, DiRePyTorch, DiRePyTorchMemoryEfficient, DiReCuVS)</span>
<span class="sd">    - cuML (UMAP, TSNE)</span>
<span class="sd">    - scikit-learn (any TransformerMixin-compatible class)</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    config : ReducerConfig</span>
<span class="sd">        Configuration object containing reducer_class, reducer_kwargs, name, and visualize flag.</span>
<span class="sd">    default_transform : callable</span>
<span class="sd">        Default transform to apply to data before reduction</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">config</span><span class="p">:</span> <span class="n">ReducerConfig</span>
    <span class="n">default_transform</span><span class="p">:</span> <span class="n">TransformFn</span> <span class="o">=</span> <span class="n">_identity_transform</span>

<div class="viewcode-block" id="ReducerRunner.__post_init__">
<a class="viewcode-back" href="../../api/dire_rapids.dire_pytorch.html#dire_rapids.dire_pytorch.ReducerRunner.__post_init__">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">__post_init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Validate that config is provided.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Must provide &#39;config&#39; (ReducerConfig)&quot;</span><span class="p">)</span></div>


    <span class="k">def</span><span class="w"> </span><span class="nf">_get_reducer_info</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">type</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span> <span class="nb">bool</span><span class="p">,</span> <span class="nb">bool</span><span class="p">,</span> <span class="nb">int</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Extract reducer info from config.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">name</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">reducer_class</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">reducer_kwargs</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">visualize</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">categorical_labels</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">max_points</span>
        <span class="p">)</span>

<div class="viewcode-block" id="ReducerRunner.run">
<a class="viewcode-back" href="../../api/dire_rapids.dire_pytorch.html#dire_rapids.dire_pytorch.ReducerRunner.run">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">run</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">dataset</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">dataset_kwargs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">transform</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">TransformFn</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Run dimensionality reduction on specified dataset.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        dataset : str</span>
<span class="sd">            Dataset selector (sklearn:name, openml:name, cytof:name, dire:name, file:path)</span>
<span class="sd">        dataset_kwargs : dict, optional</span>
<span class="sd">            Arguments for dataset loader</span>
<span class="sd">        transform : callable, optional</span>
<span class="sd">            Custom transform function (X, y) -&gt; (X&#39;, y&#39;)</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        dict</span>
<span class="sd">            Results containing:</span>
<span class="sd">            - embedding: reduced data</span>
<span class="sd">            - labels: data labels</span>
<span class="sd">            - reducer: fitted reducer instance</span>
<span class="sd">            - fit_time_sec: time taken for fit_transform</span>
<span class="sd">            - dataset_info: dataset metadata</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Get reducer configuration</span>
        <span class="n">reducer_name</span><span class="p">,</span> <span class="n">reducer_class</span><span class="p">,</span> <span class="n">reducer_kwargs</span><span class="p">,</span> <span class="n">should_visualize</span><span class="p">,</span> <span class="n">categorical_labels</span><span class="p">,</span> <span class="n">max_points</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_reducer_info</span><span class="p">()</span>

        <span class="n">scheme</span><span class="p">,</span> <span class="n">name</span> <span class="o">=</span> <span class="n">_parse_selector</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
        <span class="n">dataset_kwargs</span> <span class="o">=</span> <span class="n">dataset_kwargs</span> <span class="ow">or</span> <span class="p">{}</span>

        <span class="k">if</span> <span class="n">scheme</span> <span class="o">==</span> <span class="s2">&quot;sklearn&quot;</span><span class="p">:</span>
            <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">_load_sklearn_any</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="o">**</span><span class="n">dataset_kwargs</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">scheme</span> <span class="o">==</span> <span class="s2">&quot;file&quot;</span><span class="p">:</span>
            <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">_load_file</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="o">**</span><span class="n">dataset_kwargs</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">scheme</span> <span class="o">==</span> <span class="s2">&quot;openml&quot;</span><span class="p">:</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">fetch_openml</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">data_id</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">name</span><span class="p">))</span>
                <span class="n">ds</span> <span class="o">=</span> <span class="n">fetch_openml</span><span class="p">(</span><span class="n">data_id</span><span class="o">=</span><span class="n">data_id</span><span class="p">,</span> <span class="n">return_X_y</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="o">**</span><span class="n">dataset_kwargs</span><span class="p">)</span>
            <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
                <span class="n">ds</span> <span class="o">=</span> <span class="n">fetch_openml</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">return_X_y</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="o">**</span><span class="n">dataset_kwargs</span><span class="p">)</span>
            <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">_coerce_Xy</span><span class="p">(</span><span class="n">ds</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">ds</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
        <span class="k">elif</span> <span class="n">scheme</span> <span class="o">==</span> <span class="s2">&quot;cytof&quot;</span><span class="p">:</span>
            <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">_load_cytof</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="o">**</span><span class="n">dataset_kwargs</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">scheme</span> <span class="o">==</span> <span class="s2">&quot;dire&quot;</span><span class="p">:</span>
            <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">_load_dire_dataset</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="o">**</span><span class="n">dataset_kwargs</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unsupported scheme &#39;</span><span class="si">{</span><span class="n">scheme</span><span class="si">}</span><span class="s2">&#39;. Use &#39;sklearn&#39;, &#39;openml&#39;, &#39;cytof&#39;, &#39;dire&#39;, &#39;file&#39;.&quot;</span><span class="p">)</span>

        <span class="n">T</span> <span class="o">=</span> <span class="n">transform</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">default_transform</span>
        <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">T</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

        <span class="c1"># Instantiate reducer (handles both classes and factory functions)</span>
        <span class="k">if</span> <span class="nb">callable</span><span class="p">(</span><span class="n">reducer_class</span><span class="p">):</span>
            <span class="n">reducer</span> <span class="o">=</span> <span class="n">reducer_class</span><span class="p">(</span><span class="o">**</span><span class="n">reducer_kwargs</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;reducer_class must be callable, got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">reducer_class</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="n">t0</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">perf_counter</span><span class="p">()</span>
        <span class="n">embedding</span> <span class="o">=</span> <span class="n">reducer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">t1</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">perf_counter</span><span class="p">()</span>

        <span class="c1"># Handle visualization</span>
        <span class="k">if</span> <span class="n">should_visualize</span><span class="p">:</span>
            <span class="c1"># Only use ReducerRunner&#39;s plotly visualization (not the reducer&#39;s built-in visualize)</span>
            <span class="n">n_dims</span> <span class="o">=</span> <span class="n">embedding</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">embedding</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="k">else</span> <span class="mi">1</span>
            <span class="k">if</span> <span class="n">n_dims</span> <span class="ow">in</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">):</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_visualize_with_plotly</span><span class="p">(</span><span class="n">embedding</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">reducer_name</span><span class="p">,</span> <span class="n">n_dims</span><span class="p">,</span> <span class="n">categorical_labels</span><span class="p">,</span> <span class="n">max_points</span><span class="p">)</span>
                <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[WARNING] plotly visualization failed: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="k">return</span> <span class="p">{</span>
            <span class="s2">&quot;embedding&quot;</span><span class="p">:</span> <span class="n">embedding</span><span class="p">,</span>
            <span class="s2">&quot;labels&quot;</span><span class="p">:</span> <span class="n">y</span><span class="p">,</span>
            <span class="s2">&quot;reducer&quot;</span><span class="p">:</span> <span class="n">reducer</span><span class="p">,</span>
            <span class="s2">&quot;fit_time_sec&quot;</span><span class="p">:</span> <span class="nb">float</span><span class="p">(</span><span class="n">t1</span> <span class="o">-</span> <span class="n">t0</span><span class="p">),</span>
            <span class="s2">&quot;dataset_info&quot;</span><span class="p">:</span> <span class="p">{</span>
                <span class="s2">&quot;selector&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">,</span>
                <span class="s2">&quot;n_samples&quot;</span><span class="p">:</span> <span class="nb">int</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span>
                <span class="s2">&quot;n_features&quot;</span><span class="p">:</span> <span class="nb">int</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span>
            <span class="p">},</span>
        <span class="p">}</span></div>


    <span class="k">def</span><span class="w"> </span><span class="nf">_visualize_with_plotly</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">embedding</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
        <span class="n">labels</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span>
        <span class="n">title</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">n_dims</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">categorical_labels</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">max_points</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10000</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Create and display plotly visualization for 2D or 3D embeddings.</span>

<span class="sd">        Uses WebGL rendering (Scattergl) for performance. Automatically subsamples</span>
<span class="sd">        to max_points if dataset is larger.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="kn">import</span><span class="w"> </span><span class="nn">plotly.graph_objects</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">go</span>
        <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;[WARNING] plotly not installed. Install with: pip install plotly&quot;</span><span class="p">)</span>
            <span class="k">return</span>

        <span class="n">_safe_init_plotly_renderer</span><span class="p">()</span>

        <span class="n">n_points</span> <span class="o">=</span> <span class="n">embedding</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="c1"># Subsample if needed</span>
        <span class="k">if</span> <span class="n">n_points</span> <span class="o">&gt;</span> <span class="n">max_points</span><span class="p">:</span>
            <span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
            <span class="n">subsample_idx</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">n_points</span><span class="p">,</span> <span class="n">max_points</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="n">embedding_vis</span> <span class="o">=</span> <span class="n">embedding</span><span class="p">[</span><span class="n">subsample_idx</span><span class="p">]</span>
            <span class="n">labels_vis</span> <span class="o">=</span> <span class="n">labels</span><span class="p">[</span><span class="n">subsample_idx</span><span class="p">]</span> <span class="k">if</span> <span class="n">labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">embedding_vis</span> <span class="o">=</span> <span class="n">embedding</span>
            <span class="n">labels_vis</span> <span class="o">=</span> <span class="n">labels</span>

        <span class="k">if</span> <span class="n">n_dims</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
            <span class="c1"># Use Scattergl for WebGL acceleration</span>
            <span class="k">if</span> <span class="n">labels_vis</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="n">categorical_labels</span><span class="p">:</span>
                    <span class="n">fig</span> <span class="o">=</span> <span class="n">go</span><span class="o">.</span><span class="n">Figure</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">go</span><span class="o">.</span><span class="n">Scattergl</span><span class="p">(</span>
                        <span class="n">x</span><span class="o">=</span><span class="n">embedding_vis</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span>
                        <span class="n">y</span><span class="o">=</span><span class="n">embedding_vis</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span>
                        <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;markers&#39;</span><span class="p">,</span>
                        <span class="n">marker</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span>
                            <span class="n">size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
                            <span class="n">color</span><span class="o">=</span><span class="n">labels_vis</span><span class="p">,</span>
                            <span class="n">colorscale</span><span class="o">=</span><span class="s1">&#39;Viridis&#39;</span><span class="p">,</span>
                            <span class="n">colorbar</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s2">&quot;Label Value&quot;</span><span class="p">),</span>
                            <span class="n">showscale</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                            <span class="n">opacity</span><span class="o">=</span><span class="mf">0.8</span>
                        <span class="p">)</span>
                    <span class="p">))</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">unique_labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">labels_vis</span><span class="p">)</span>

                    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">unique_labels</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">20</span><span class="p">:</span>
                        <span class="n">label_to_idx</span> <span class="o">=</span> <span class="p">{</span><span class="n">lbl</span><span class="p">:</span> <span class="n">idx</span> <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">lbl</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">unique_labels</span><span class="p">)}</span>
                        <span class="n">colors</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">label_to_idx</span><span class="p">[</span><span class="n">lbl</span><span class="p">]</span> <span class="k">for</span> <span class="n">lbl</span> <span class="ow">in</span> <span class="n">labels_vis</span><span class="p">])</span>

                        <span class="n">fig</span> <span class="o">=</span> <span class="n">go</span><span class="o">.</span><span class="n">Figure</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">go</span><span class="o">.</span><span class="n">Scattergl</span><span class="p">(</span>
                            <span class="n">x</span><span class="o">=</span><span class="n">embedding_vis</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span>
                            <span class="n">y</span><span class="o">=</span><span class="n">embedding_vis</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span>
                            <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;markers&#39;</span><span class="p">,</span>
                            <span class="n">marker</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span>
                                <span class="n">size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
                                <span class="n">color</span><span class="o">=</span><span class="n">colors</span><span class="p">,</span>
                                <span class="n">colorscale</span><span class="o">=</span><span class="s1">&#39;Viridis&#39;</span><span class="p">,</span>
                                <span class="n">showscale</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                <span class="n">opacity</span><span class="o">=</span><span class="mf">0.8</span>
                            <span class="p">),</span>
                            <span class="n">text</span><span class="o">=</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;Label: </span><span class="si">{</span><span class="n">lbl</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">lbl</span> <span class="ow">in</span> <span class="n">labels_vis</span><span class="p">],</span>
                            <span class="n">hovertemplate</span><span class="o">=</span><span class="s1">&#39;%</span><span class="si">{text}</span><span class="s1">&lt;extra&gt;&lt;/extra&gt;&#39;</span>
                        <span class="p">))</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">fig</span> <span class="o">=</span> <span class="n">go</span><span class="o">.</span><span class="n">Figure</span><span class="p">()</span>
                        <span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">unique_labels</span><span class="p">:</span>
                            <span class="n">mask</span> <span class="o">=</span> <span class="n">labels_vis</span> <span class="o">==</span> <span class="n">label</span>
                            <span class="n">fig</span><span class="o">.</span><span class="n">add_trace</span><span class="p">(</span><span class="n">go</span><span class="o">.</span><span class="n">Scattergl</span><span class="p">(</span>
                                <span class="n">x</span><span class="o">=</span><span class="n">embedding_vis</span><span class="p">[</span><span class="n">mask</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
                                <span class="n">y</span><span class="o">=</span><span class="n">embedding_vis</span><span class="p">[</span><span class="n">mask</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
                                <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;markers&#39;</span><span class="p">,</span>
                                <span class="n">name</span><span class="o">=</span><span class="nb">str</span><span class="p">(</span><span class="n">label</span><span class="p">),</span>
                                <span class="n">marker</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">opacity</span><span class="o">=</span><span class="mf">0.8</span><span class="p">)</span>
                            <span class="p">))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">fig</span> <span class="o">=</span> <span class="n">go</span><span class="o">.</span><span class="n">Figure</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">go</span><span class="o">.</span><span class="n">Scattergl</span><span class="p">(</span>
                    <span class="n">x</span><span class="o">=</span><span class="n">embedding_vis</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span>
                    <span class="n">y</span><span class="o">=</span><span class="n">embedding_vis</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span>
                    <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;markers&#39;</span><span class="p">,</span>
                    <span class="n">marker</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">opacity</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
                <span class="p">))</span>

            <span class="n">fig</span><span class="o">.</span><span class="n">update_layout</span><span class="p">(</span>
                <span class="n">title</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">title</span><span class="si">}</span><span class="s2"> - 2D Embedding&quot;</span><span class="p">,</span>
                <span class="n">xaxis_title</span><span class="o">=</span><span class="s2">&quot;Dimension 1&quot;</span><span class="p">,</span>
                <span class="n">yaxis_title</span><span class="o">=</span><span class="s2">&quot;Dimension 2&quot;</span><span class="p">,</span>
                <span class="n">width</span><span class="o">=</span><span class="mi">800</span><span class="p">,</span>
                <span class="n">height</span><span class="o">=</span><span class="mi">600</span><span class="p">,</span>
                <span class="n">hovermode</span><span class="o">=</span><span class="s1">&#39;closest&#39;</span>
            <span class="p">)</span>

        <span class="k">elif</span> <span class="n">n_dims</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">labels_vis</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="n">categorical_labels</span><span class="p">:</span>
                    <span class="n">fig</span> <span class="o">=</span> <span class="n">go</span><span class="o">.</span><span class="n">Figure</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">go</span><span class="o">.</span><span class="n">Scatter3d</span><span class="p">(</span>
                        <span class="n">x</span><span class="o">=</span><span class="n">embedding_vis</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span>
                        <span class="n">y</span><span class="o">=</span><span class="n">embedding_vis</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span>
                        <span class="n">z</span><span class="o">=</span><span class="n">embedding_vis</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">],</span>
                        <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;markers&#39;</span><span class="p">,</span>
                        <span class="n">marker</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span>
                            <span class="n">size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                            <span class="n">color</span><span class="o">=</span><span class="n">labels_vis</span><span class="p">,</span>
                            <span class="n">colorscale</span><span class="o">=</span><span class="s1">&#39;Viridis&#39;</span><span class="p">,</span>
                            <span class="n">colorbar</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s2">&quot;Label Value&quot;</span><span class="p">),</span>
                            <span class="n">showscale</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                            <span class="n">opacity</span><span class="o">=</span><span class="mf">0.8</span>
                        <span class="p">)</span>
                    <span class="p">))</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">unique_labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">labels_vis</span><span class="p">)</span>

                    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">unique_labels</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">20</span><span class="p">:</span>
                        <span class="n">label_to_idx</span> <span class="o">=</span> <span class="p">{</span><span class="n">lbl</span><span class="p">:</span> <span class="n">idx</span> <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">lbl</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">unique_labels</span><span class="p">)}</span>
                        <span class="n">colors</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">label_to_idx</span><span class="p">[</span><span class="n">lbl</span><span class="p">]</span> <span class="k">for</span> <span class="n">lbl</span> <span class="ow">in</span> <span class="n">labels_vis</span><span class="p">])</span>

                        <span class="n">fig</span> <span class="o">=</span> <span class="n">go</span><span class="o">.</span><span class="n">Figure</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">go</span><span class="o">.</span><span class="n">Scatter3d</span><span class="p">(</span>
                            <span class="n">x</span><span class="o">=</span><span class="n">embedding_vis</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span>
                            <span class="n">y</span><span class="o">=</span><span class="n">embedding_vis</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span>
                            <span class="n">z</span><span class="o">=</span><span class="n">embedding_vis</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">],</span>
                            <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;markers&#39;</span><span class="p">,</span>
                            <span class="n">marker</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span>
                                <span class="n">size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                                <span class="n">color</span><span class="o">=</span><span class="n">colors</span><span class="p">,</span>
                                <span class="n">colorscale</span><span class="o">=</span><span class="s1">&#39;Viridis&#39;</span><span class="p">,</span>
                                <span class="n">showscale</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                <span class="n">opacity</span><span class="o">=</span><span class="mf">0.8</span>
                            <span class="p">),</span>
                            <span class="n">text</span><span class="o">=</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;Label: </span><span class="si">{</span><span class="n">lbl</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">lbl</span> <span class="ow">in</span> <span class="n">labels_vis</span><span class="p">],</span>
                            <span class="n">hovertemplate</span><span class="o">=</span><span class="s1">&#39;%</span><span class="si">{text}</span><span class="s1">&lt;extra&gt;&lt;/extra&gt;&#39;</span>
                        <span class="p">))</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">fig</span> <span class="o">=</span> <span class="n">go</span><span class="o">.</span><span class="n">Figure</span><span class="p">()</span>
                        <span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">unique_labels</span><span class="p">:</span>
                            <span class="n">mask</span> <span class="o">=</span> <span class="n">labels_vis</span> <span class="o">==</span> <span class="n">label</span>
                            <span class="n">fig</span><span class="o">.</span><span class="n">add_trace</span><span class="p">(</span><span class="n">go</span><span class="o">.</span><span class="n">Scatter3d</span><span class="p">(</span>
                                <span class="n">x</span><span class="o">=</span><span class="n">embedding_vis</span><span class="p">[</span><span class="n">mask</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
                                <span class="n">y</span><span class="o">=</span><span class="n">embedding_vis</span><span class="p">[</span><span class="n">mask</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
                                <span class="n">z</span><span class="o">=</span><span class="n">embedding_vis</span><span class="p">[</span><span class="n">mask</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
                                <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;markers&#39;</span><span class="p">,</span>
                                <span class="n">name</span><span class="o">=</span><span class="nb">str</span><span class="p">(</span><span class="n">label</span><span class="p">),</span>
                                <span class="n">marker</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">opacity</span><span class="o">=</span><span class="mf">0.8</span><span class="p">)</span>
                            <span class="p">))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">fig</span> <span class="o">=</span> <span class="n">go</span><span class="o">.</span><span class="n">Figure</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">go</span><span class="o">.</span><span class="n">Scatter3d</span><span class="p">(</span>
                    <span class="n">x</span><span class="o">=</span><span class="n">embedding_vis</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span>
                    <span class="n">y</span><span class="o">=</span><span class="n">embedding_vis</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span>
                    <span class="n">z</span><span class="o">=</span><span class="n">embedding_vis</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">],</span>
                    <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;markers&#39;</span><span class="p">,</span>
                    <span class="n">marker</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">opacity</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
                <span class="p">))</span>

            <span class="n">fig</span><span class="o">.</span><span class="n">update_layout</span><span class="p">(</span>
                <span class="n">title</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">title</span><span class="si">}</span><span class="s2"> - 3D Embedding&quot;</span><span class="p">,</span>
                <span class="n">scene</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span>
                    <span class="n">xaxis_title</span><span class="o">=</span><span class="s2">&quot;Dimension 1&quot;</span><span class="p">,</span>
                    <span class="n">yaxis_title</span><span class="o">=</span><span class="s2">&quot;Dimension 2&quot;</span><span class="p">,</span>
                    <span class="n">zaxis_title</span><span class="o">=</span><span class="s2">&quot;Dimension 3&quot;</span>
                <span class="p">),</span>
                <span class="n">width</span><span class="o">=</span><span class="mi">900</span><span class="p">,</span>
                <span class="n">height</span><span class="o">=</span><span class="mi">700</span>
            <span class="p">)</span>

        <span class="n">fig</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<div class="viewcode-block" id="ReducerRunner.available_sklearn">
<a class="viewcode-back" href="../../api/dire_rapids.dire_pytorch.html#dire_rapids.dire_pytorch.ReducerRunner.available_sklearn">[docs]</a>
    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">available_sklearn</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="o">...</span><span class="p">]]:</span>
        <span class="n">loads</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">a</span> <span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="nb">dir</span><span class="p">(</span><span class="n">skds</span><span class="p">)</span> <span class="k">if</span> <span class="n">a</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;load_&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">callable</span><span class="p">(</span><span class="nb">getattr</span><span class="p">(</span><span class="n">skds</span><span class="p">,</span> <span class="n">a</span><span class="p">)))</span>
        <span class="n">fetches</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">a</span> <span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="nb">dir</span><span class="p">(</span><span class="n">skds</span><span class="p">)</span> <span class="k">if</span> <span class="n">a</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;fetch_&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">callable</span><span class="p">(</span><span class="nb">getattr</span><span class="p">(</span><span class="n">skds</span><span class="p">,</span> <span class="n">a</span><span class="p">)))</span>
        <span class="n">makes</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">a</span> <span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="nb">dir</span><span class="p">(</span><span class="n">skds</span><span class="p">)</span> <span class="k">if</span> <span class="n">a</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;make_&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">callable</span><span class="p">(</span><span class="nb">getattr</span><span class="p">(</span><span class="n">skds</span><span class="p">,</span> <span class="n">a</span><span class="p">)))</span>
        <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;load&quot;</span><span class="p">:</span> <span class="n">loads</span><span class="p">,</span> <span class="s2">&quot;fetch&quot;</span><span class="p">:</span> <span class="n">fetches</span><span class="p">,</span> <span class="s2">&quot;make&quot;</span><span class="p">:</span> <span class="n">makes</span><span class="p">}</span></div>


<div class="viewcode-block" id="ReducerRunner.available_cytof">
<a class="viewcode-back" href="../../api/dire_rapids.dire_pytorch.html#dire_rapids.dire_pytorch.ReducerRunner.available_cytof">[docs]</a>
    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">available_cytof</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="o">...</span><span class="p">]:</span>
        <span class="k">return</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">_CYTOF_REGISTRY</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span></div>
</div>

</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2024, Alexander Kolpakov (UATX), Igor Rivin (Temple University).</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>