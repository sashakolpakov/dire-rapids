

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>dire_rapids.dire_pytorch &mdash; dire-rapids 0.1.0 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../../_static/css/theme.css?v=e59714d7" />

  
      <script src="../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../_static/documentation_options.js?v=01f34227"></script>
      <script src="../../_static/doctools.js?v=9a2dae69"></script>
      <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search"  style="background: white" >

          
          
          <a href="../../index.html" class="icon icon-home">
            dire-rapids
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../api/modules.html">dire_rapids</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu"  style="background: white" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">dire-rapids</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../index.html">Module code</a></li>
      <li class="breadcrumb-item active">dire_rapids.dire_pytorch</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for dire_rapids.dire_pytorch</h1><div class="highlight"><pre>
<span></span><span class="c1"># dire_pytorch.py</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">PyTorch/PyKeOps backend for DiRe dimensionality reduction.</span>

<span class="sd">This implementation features:</span>
<span class="sd">- Memory-efficient chunked k-NN computation for large datasets (&gt;100K points)</span>
<span class="sd">- Attraction forces applied only between k-NN neighbors  </span>
<span class="sd">- Repulsion forces computed from random samples</span>
<span class="sd">- Automatic GPU memory management with adaptive chunk sizing</span>
<span class="sd">- Designed for high-performance processing on CUDA GPUs</span>

<span class="sd">Performance characteristics:</span>
<span class="sd">- Best for datasets &gt;50K points on CUDA GPUs</span>
<span class="sd">- Memory-aware processing up to millions of points</span>
<span class="sd">- Chunked computation prevents GPU out-of-memory errors</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">gc</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">sys</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">plotly.express</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">px</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">loguru</span><span class="w"> </span><span class="kn">import</span> <span class="n">logger</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">scipy.optimize</span><span class="w"> </span><span class="kn">import</span> <span class="n">curve_fit</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.base</span><span class="w"> </span><span class="kn">import</span> <span class="n">TransformerMixin</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.decomposition</span><span class="w"> </span><span class="kn">import</span> <span class="n">PCA</span>

<span class="c1"># PyKeOps for efficient force computations</span>
<span class="k">try</span><span class="p">:</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">pykeops.torch</span><span class="w"> </span><span class="kn">import</span> <span class="n">LazyTensor</span>

    <span class="n">PYKEOPS_AVAILABLE</span> <span class="o">=</span> <span class="kc">True</span>
<span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
    <span class="n">PYKEOPS_AVAILABLE</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;PyKeOps not available. Install with: pip install pykeops&quot;</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_compile_metric</span><span class="p">(</span><span class="n">spec</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Turn a metric spec into a callable metric(x, y) that returns a distance-like</span>
<span class="sd">    matrix with broadcasting:</span>
<span class="sd">      - Torch path:  x: (A, 1, D), y: (1, B, D)  -&gt; (A, B) torch.Tensor</span>
<span class="sd">      - KeOps path:  x: LazyTensor(A,1,D), y: LazyTensor(1,B,D) -&gt; LazyTensor(A,B)</span>

<span class="sd">    If spec is None or &#39;euclidean&#39;/&#39;l2&#39;, return None (fast-path Euclidean stays in backend).</span>
<span class="sd">    If spec is str, it&#39;s eval&#39;ed with {&#39;x&#39;: x, &#39;y&#39;: y} and no builtins.</span>
<span class="sd">    If spec is callable, it&#39;s returned unchanged.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">spec</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">spec</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
        <span class="n">expr</span> <span class="o">=</span> <span class="n">spec</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">expr</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;euclidean&quot;</span><span class="p">,</span> <span class="s2">&quot;l2&quot;</span><span class="p">):</span>
            <span class="k">return</span> <span class="kc">None</span>  <span class="c1"># use built-in fast Euclidean</span>
        <span class="k">def</span><span class="w"> </span><span class="nf">_expr_metric</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">_expr</span><span class="o">=</span><span class="n">spec</span><span class="p">):</span>
            <span class="c1"># Use ONLY tensor methods like .sum(-1), .sqrt(), .abs(), etc.</span>
            <span class="c1"># Works for both torch.Tensor and KeOps LazyTensor.</span>
            <span class="k">return</span> <span class="nb">eval</span><span class="p">(</span><span class="n">_expr</span><span class="p">,</span> <span class="p">{</span><span class="s2">&quot;__builtins__&quot;</span><span class="p">:</span> <span class="p">{}},</span> <span class="p">{</span><span class="s2">&quot;x&quot;</span><span class="p">:</span> <span class="n">x</span><span class="p">,</span> <span class="s2">&quot;y&quot;</span><span class="p">:</span> <span class="n">y</span><span class="p">})</span>
        <span class="k">return</span> <span class="n">_expr_metric</span>
    <span class="k">if</span> <span class="nb">callable</span><span class="p">(</span><span class="n">spec</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">spec</span>
    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;metric must be None, a string expression, or a callable&quot;</span><span class="p">)</span>


<div class="viewcode-block" id="DiRePyTorch">
<a class="viewcode-back" href="../../api/modules.html#dire_rapids.dire_pytorch.DiRePyTorch">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">DiRePyTorch</span><span class="p">(</span><span class="n">TransformerMixin</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Memory-efficient PyTorch/PyKeOps implementation of DiRe dimensionality reduction.</span>
<span class="sd">    </span>
<span class="sd">    This class provides a high-performance implementation of the DiRe algorithm using PyTorch</span>
<span class="sd">    as the computational backend. It features adaptive memory management for large datasets</span>
<span class="sd">    and automatic GPU optimization.</span>
<span class="sd">    </span>
<span class="sd">    Features</span>
<span class="sd">    --------</span>
<span class="sd">    - Chunked k-NN computation prevents GPU out-of-memory errors</span>
<span class="sd">    - Memory-aware force computation with automatic chunk sizing</span>
<span class="sd">    - Attraction forces between k-NN neighbors only</span>
<span class="sd">    - Repulsion forces from random sampling for efficiency</span>
<span class="sd">    - Automatic FP16 optimization for memory and speed</span>
<span class="sd">    - Optional PyKeOps integration for low-dimensional data</span>
<span class="sd">    </span>
<span class="sd">    Best suited for</span>
<span class="sd">    ---------------</span>
<span class="sd">    - Large datasets (&gt;50K points) on CUDA GPUs</span>
<span class="sd">    - Production environments requiring reliable memory usage</span>
<span class="sd">    - High-performance dimensionality reduction workflows</span>
<span class="sd">    </span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    n_components : int, default=2</span>
<span class="sd">        Number of dimensions in the target embedding space.</span>
<span class="sd">    n_neighbors : int, default=16</span>
<span class="sd">        Number of nearest neighbors to use for attraction forces.</span>
<span class="sd">    init : {&#39;pca&#39;, &#39;random&#39;}, default=&#39;pca&#39;</span>
<span class="sd">        Method for initializing the embedding. &#39;pca&#39; uses PCA initialization,</span>
<span class="sd">        &#39;random&#39; uses random projection.</span>
<span class="sd">    max_iter_layout : int, default=128</span>
<span class="sd">        Maximum number of optimization iterations.</span>
<span class="sd">    min_dist : float, default=1e-2</span>
<span class="sd">        Minimum distance between points in the embedding.</span>
<span class="sd">    spread : float, default=1.0</span>
<span class="sd">        Controls how tightly points are packed in the embedding.</span>
<span class="sd">    cutoff : float, default=42.0</span>
<span class="sd">        Distance cutoff for repulsion forces.</span>
<span class="sd">    n_sample_dirs : int, default=8</span>
<span class="sd">        Number of sampling directions (used by derived classes).</span>
<span class="sd">    sample_size : int, default=16</span>
<span class="sd">        Size of samples for force computation (used by derived classes).</span>
<span class="sd">    neg_ratio : int, default=8</span>
<span class="sd">        Ratio of negative samples to positive samples for repulsion.</span>
<span class="sd">    verbose : bool, default=True</span>
<span class="sd">        Whether to print progress information.</span>
<span class="sd">    random_state : int or None, default=None</span>
<span class="sd">        Random seed for reproducible results.</span>
<span class="sd">    use_exact_repulsion : bool, default=False</span>
<span class="sd">        If True, use exact all-pairs repulsion (memory intensive, for testing only).</span>
<span class="sd">    metric : str, callable, or None, default=None</span>
<span class="sd">        Custom distance metric for k-NN computation only (layout forces remain Euclidean):</span>

<span class="sd">        - None or &#39;euclidean&#39;/&#39;l2&#39;: Use fast built-in Euclidean distance</span>
<span class="sd">        - str: String expression evaluated with x and y tensors (e.g., &#39;(x - y).abs().sum(-1)&#39; for L1)</span>
<span class="sd">        - callable: Custom function taking (x, y) tensors and returning distance matrix</span>

<span class="sd">        Examples: &#39;(x - y).abs().sum(-1)&#39; (L1), &#39;1 - (x*y).sum(-1)/(x.norm()*y.norm() + 1e-8)&#39; (cosine).</span>
<span class="sd">        </span>
<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    device : torch.device</span>
<span class="sd">        The PyTorch device being used (CPU or CUDA).</span>
<span class="sd">    logger : loguru.Logger</span>
<span class="sd">        Instance-specific logger for this reducer.</span>
<span class="sd">        </span>
<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    Basic usage::</span>
<span class="sd">    </span>
<span class="sd">        from dire_rapids import DiRePyTorch</span>
<span class="sd">        import numpy as np</span>
<span class="sd">        </span>
<span class="sd">        # Create sample data</span>
<span class="sd">        X = np.random.randn(10000, 100)</span>
<span class="sd">        </span>
<span class="sd">        # Create and fit reducer</span>
<span class="sd">        reducer = DiRePyTorch(n_neighbors=32, verbose=True)</span>
<span class="sd">        embedding = reducer.fit_transform(X)</span>
<span class="sd">        </span>
<span class="sd">        # Visualize results</span>
<span class="sd">        fig = reducer.visualize()</span>
<span class="sd">        fig.show()</span>
<span class="sd">    </span>
<span class="sd">    With custom parameters::</span>

<span class="sd">        reducer = DiRePyTorch(</span>
<span class="sd">            n_components=3,</span>
<span class="sd">            n_neighbors=50,</span>
<span class="sd">            max_iter_layout=200,</span>
<span class="sd">            min_dist=0.1,</span>
<span class="sd">            random_state=42</span>
<span class="sd">        )</span>
<span class="sd">        embedding = reducer.fit_transform(X)</span>

<span class="sd">    With custom distance metric::</span>

<span class="sd">        # Using L1 (Manhattan) distance for k-NN</span>
<span class="sd">        reducer = DiRePyTorch(</span>
<span class="sd">            metric=&#39;(x - y).abs().sum(-1)&#39;,</span>
<span class="sd">            n_neighbors=32</span>
<span class="sd">        )</span>
<span class="sd">        embedding = reducer.fit_transform(X)</span>

<span class="sd">        # Using custom callable metric</span>
<span class="sd">        def cosine_distance(x, y):</span>
<span class="sd">            return 1 - (x * y).sum(-1) / (x.norm(dim=-1, keepdim=True) * y.norm(dim=-1, keepdim=True) + 1e-8)</span>

<span class="sd">        reducer = DiRePyTorch(metric=cosine_distance)</span>
<span class="sd">        embedding = reducer.fit_transform(X)</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="DiRePyTorch.__init__">
<a class="viewcode-back" href="../../api/modules.html#dire_rapids.dire_pytorch.DiRePyTorch.__init__">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span>
            <span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
            <span class="n">n_neighbors</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
            <span class="n">init</span><span class="o">=</span><span class="s2">&quot;pca&quot;</span><span class="p">,</span>
            <span class="n">max_iter_layout</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
            <span class="n">min_dist</span><span class="o">=</span><span class="mf">1e-2</span><span class="p">,</span>
            <span class="n">spread</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
            <span class="n">cutoff</span><span class="o">=</span><span class="mf">42.0</span><span class="p">,</span>
            <span class="n">n_sample_dirs</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
            <span class="n">sample_size</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
            <span class="n">neg_ratio</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
            <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
            <span class="n">use_exact_repulsion</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>  <span class="c1"># If True, use all-pairs repulsion (for testing)</span>
            <span class="n">metric</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initialize DiRePyTorch reducer with specified parameters.</span>
<span class="sd">        </span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        n_components : int, default=2</span>
<span class="sd">            Number of dimensions in the target embedding space.</span>
<span class="sd">        n_neighbors : int, default=16</span>
<span class="sd">            Number of nearest neighbors to use for attraction forces.</span>
<span class="sd">        init : {&#39;pca&#39;, &#39;random&#39;}, default=&#39;pca&#39;</span>
<span class="sd">            Method for initializing the embedding.</span>
<span class="sd">        max_iter_layout : int, default=128</span>
<span class="sd">            Maximum number of optimization iterations.</span>
<span class="sd">        min_dist : float, default=1e-2</span>
<span class="sd">            Minimum distance between points in the embedding.</span>
<span class="sd">        spread : float, default=1.0</span>
<span class="sd">            Controls how tightly points are packed in the embedding.</span>
<span class="sd">        cutoff : float, default=42.0</span>
<span class="sd">            Distance cutoff for repulsion forces.</span>
<span class="sd">        n_sample_dirs : int, default=8</span>
<span class="sd">            Number of sampling directions (reserved for future use).</span>
<span class="sd">        sample_size : int, default=16</span>
<span class="sd">            Size of samples for force computation (reserved for future use).</span>
<span class="sd">        neg_ratio : int, default=8</span>
<span class="sd">            Ratio of negative samples to positive samples for repulsion.</span>
<span class="sd">        verbose : bool, default=True</span>
<span class="sd">            Whether to print progress information.</span>
<span class="sd">        random_state : int or None, default=None</span>
<span class="sd">            Random seed for reproducible results.</span>
<span class="sd">        use_exact_repulsion : bool, default=False</span>
<span class="sd">            If True, use exact all-pairs repulsion (memory intensive, testing only).</span>
<span class="sd">        metric : str, callable, or None, default=None</span>
<span class="sd">            Custom distance metric for k-NN computation. See class docstring for details.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">n_components</span> <span class="o">=</span> <span class="n">n_components</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_neighbors</span> <span class="o">=</span> <span class="n">n_neighbors</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">init</span> <span class="o">=</span> <span class="n">init</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_iter_layout</span> <span class="o">=</span> <span class="n">max_iter_layout</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">min_dist</span> <span class="o">=</span> <span class="n">min_dist</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">spread</span> <span class="o">=</span> <span class="n">spread</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cutoff</span> <span class="o">=</span> <span class="n">cutoff</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_sample_dirs</span> <span class="o">=</span> <span class="n">n_sample_dirs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sample_size</span> <span class="o">=</span> <span class="n">sample_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">neg_ratio</span> <span class="o">=</span> <span class="n">neg_ratio</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="n">verbose</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random_state</span> <span class="o">=</span> <span class="n">random_state</span> <span class="k">if</span> <span class="n">random_state</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span> <span class="o">**</span> <span class="mi">32</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">use_exact_repulsion</span> <span class="o">=</span> <span class="n">use_exact_repulsion</span>

        <span class="c1"># Custom metric for k-NN only (layout forces remain Euclidean):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">metric_spec</span> <span class="o">=</span> <span class="n">metric</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_metric_fn</span> <span class="o">=</span> <span class="n">_compile_metric</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">metric_spec</span><span class="p">)</span>

        <span class="c1"># Setup instance-specific logger</span>
        <span class="c1"># Create a completely new logger instance for this DiRe object</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">logger</span> <span class="o">=</span> <span class="n">logger</span><span class="o">.</span><span class="n">bind</span><span class="p">(</span><span class="n">dire_instance</span><span class="o">=</span><span class="nb">id</span><span class="p">(</span><span class="bp">self</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">remove</span><span class="p">()</span>  <span class="c1"># Remove all existing handlers</span>
        
        <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
            <span class="c1"># Add handler that outputs to stderr with formatting</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">add</span><span class="p">(</span>
                <span class="n">sys</span><span class="o">.</span><span class="n">stderr</span><span class="p">,</span>
                <span class="n">level</span><span class="o">=</span><span class="s2">&quot;INFO&quot;</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Add null handler that discards all messages</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="k">lambda</span> <span class="n">msg</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span> <span class="n">level</span><span class="o">=</span><span class="s2">&quot;TRACE&quot;</span><span class="p">)</span>

        <span class="c1"># Internal state</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_data</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_layout</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_n_samples</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_a</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_b</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_knn_indices</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_knn_distances</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="c1"># Device management</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cuda&#39;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s1">&#39;cpu&#39;</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="s1">&#39;cuda&#39;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Using CUDA device: </span><span class="si">{</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">get_device_name</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;CUDA not available, using CPU&quot;</span><span class="p">)</span></div>


    <span class="k">def</span><span class="w"> </span><span class="nf">_find_ab_params</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Find optimal a and b parameters for the distribution kernel.</span>
<span class="sd">        </span>
<span class="sd">        This private method fits a curve to determine the optimal parameters for the</span>
<span class="sd">        probability kernel used in force calculations. The parameters control the</span>
<span class="sd">        shape of the attraction/repulsion curve.</span>
<span class="sd">        </span>
<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        Private method, should not be called directly. Used by fit_transform().</span>
<span class="sd">        The kernel function is: 1 / (1 + a * x^(2*b))</span>
<span class="sd">        </span>
<span class="sd">        Side Effects</span>
<span class="sd">        ------------</span>
<span class="sd">        Sets self._a and self._b attributes with the fitted parameters.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">def</span><span class="w"> </span><span class="nf">curve</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
            <span class="k">return</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">+</span> <span class="n">a</span> <span class="o">*</span> <span class="n">x</span> <span class="o">**</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">b</span><span class="p">))</span>

        <span class="n">xv</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">spread</span><span class="p">,</span> <span class="mi">300</span><span class="p">)</span>
        <span class="n">yv</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">xv</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
        <span class="n">yv</span><span class="p">[</span><span class="n">xv</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_dist</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.0</span>
        <span class="n">yv</span><span class="p">[</span><span class="n">xv</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_dist</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="p">(</span><span class="n">xv</span><span class="p">[</span><span class="n">xv</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_dist</span><span class="p">]</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_dist</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">spread</span><span class="p">)</span>

        <span class="n">params</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">curve_fit</span><span class="p">(</span><span class="n">curve</span><span class="p">,</span> <span class="n">xv</span><span class="p">,</span> <span class="n">yv</span><span class="p">)[:</span><span class="mi">2</span><span class="p">]</span>  <span class="c1"># Extract only params and covariance</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_a</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_b</span> <span class="o">=</span> <span class="n">params</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Found kernel params: a=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_a</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, b=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_b</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_compute_knn</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">chunk_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">use_fp16</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>  <span class="c1"># pylint: disable=too-many-branches</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute k-nearest neighbors with memory-efficient chunking.</span>
<span class="sd">        </span>
<span class="sd">        This private method computes the k-nearest neighbors graph using either PyTorch</span>
<span class="sd">        or PyKeOps backends. It intelligently selects the optimal backend based on</span>
<span class="sd">        data dimensionality and automatically manages memory through chunking.</span>
<span class="sd">        </span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : numpy.ndarray</span>
<span class="sd">            Input data of shape (n_samples, n_features).</span>
<span class="sd">        chunk_size : int, optional</span>
<span class="sd">            Size of chunks for processing. If None, automatically determined based</span>
<span class="sd">            on available memory.</span>
<span class="sd">        use_fp16 : bool, optional</span>
<span class="sd">            Use FP16 precision for computation. If None, automatically determined</span>
<span class="sd">            based on data size and GPU capabilities. FP16 provides 2x memory savings</span>
<span class="sd">            and 2-14x speedup on modern GPUs.</span>
<span class="sd">            </span>
<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        Private method, should not be called directly. Used by fit_transform().</span>
<span class="sd">        </span>
<span class="sd">        Backend Selection:</span>
<span class="sd">        - PyTorch: Used for high-dimensional data (&gt;= 200D) or when PyKeOps unavailable</span>
<span class="sd">        - PyKeOps: Used for low-dimensional data (&lt; 200D) on GPU for better performance</span>
<span class="sd">        </span>
<span class="sd">        Side Effects</span>
<span class="sd">        ------------</span>
<span class="sd">        Sets self._knn_indices and self._knn_distances with computed k-NN graph.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">n_samples</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">n_dims</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Computing </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">n_neighbors</span><span class="si">}</span><span class="s2">-NN graph for </span><span class="si">{</span><span class="n">n_samples</span><span class="si">}</span><span class="s2"> points in </span><span class="si">{</span><span class="n">n_dims</span><span class="si">}</span><span class="s2">D...&quot;</span><span class="p">)</span>

        <span class="c1"># Auto-detect FP16 usage based on data size and GPU</span>
        <span class="k">if</span> <span class="n">use_fp16</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="s1">&#39;cuda&#39;</span><span class="p">:</span>
            <span class="c1"># Use FP16 for high-dimensional data or large datasets</span>
            <span class="n">use_fp16</span> <span class="o">=</span> <span class="n">n_dims</span> <span class="o">&gt;=</span> <span class="mi">500</span> <span class="ow">or</span> <span class="n">n_samples</span> <span class="o">&gt;=</span> <span class="mi">100000</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="s1">&#39;cpu&#39;</span><span class="p">:</span>
            <span class="n">use_fp16</span> <span class="o">=</span> <span class="kc">False</span>  <span class="c1"># CPU doesn&#39;t benefit from FP16</span>
        
        <span class="c1"># Choose precision</span>
        <span class="k">if</span> <span class="n">use_fp16</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="s1">&#39;cuda&#39;</span><span class="p">:</span>
            <span class="n">dtype</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">float16</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Using FP16 for k-NN (2x memory, faster on H100/A100)&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">dtype</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">float32</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Using FP32 for k-NN&quot;</span><span class="p">)</span>
        
        <span class="n">X_torch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        
        <span class="c1"># CRITICAL: PyKeOps is slower than PyTorch for high dimensions!</span>
        <span class="c1"># Use PyTorch for high-D, PyKeOps for low-D</span>
        <span class="n">use_pykeops</span> <span class="o">=</span> <span class="n">PYKEOPS_AVAILABLE</span> <span class="ow">and</span> <span class="n">n_dims</span> <span class="o">&lt;</span> <span class="mi">200</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="s1">&#39;cuda&#39;</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">use_fp16</span>
        
        <span class="k">if</span> <span class="n">n_dims</span> <span class="o">&gt;=</span> <span class="mi">200</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Using PyTorch for k-NN (high dimension: </span><span class="si">{</span><span class="n">n_dims</span><span class="si">}</span><span class="s2">D)&quot;</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">use_pykeops</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Using PyKeOps for k-NN (low dimension, GPU available)&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Using PyTorch for k-NN&quot;</span><span class="p">)</span>
        
        <span class="c1"># Set default chunk size if not provided</span>
        <span class="k">if</span> <span class="n">chunk_size</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">chunk_size</span> <span class="o">=</span> <span class="mi">50000</span>
            
        <span class="c1"># Adaptive chunk sizing based on available GPU memory</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="s1">&#39;cuda&#39;</span><span class="p">:</span>
            <span class="n">gpu_mem_free</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">mem_get_info</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
            <span class="c1"># Estimate memory for k-NN: chunk_size * n_samples * bytes_per_element</span>
            <span class="n">bytes_per_element</span> <span class="o">=</span> <span class="mi">2</span> <span class="k">if</span> <span class="n">use_fp16</span> <span class="k">else</span> <span class="mi">4</span>  <span class="c1"># FP16 uses 2 bytes, FP32 uses 4</span>
            <span class="n">memory_per_chunk</span> <span class="o">=</span> <span class="n">chunk_size</span> <span class="o">*</span> <span class="n">n_samples</span> <span class="o">*</span> <span class="n">bytes_per_element</span>
            
            <span class="c1"># Only auto-adjust if using default chunk size</span>
            <span class="k">if</span> <span class="n">chunk_size</span> <span class="o">==</span> <span class="mi">50000</span><span class="p">:</span>
                <span class="c1"># Use 30% of available memory for k-NN computation (40% for FP16 since it&#39;s more efficient)</span>
                <span class="n">memory_fraction</span> <span class="o">=</span> <span class="mf">0.4</span> <span class="k">if</span> <span class="n">use_fp16</span> <span class="k">else</span> <span class="mf">0.3</span>
                <span class="n">max_memory</span> <span class="o">=</span> <span class="n">gpu_mem_free</span> <span class="o">*</span> <span class="n">memory_fraction</span>
                <span class="k">if</span> <span class="n">memory_per_chunk</span> <span class="o">&gt;</span> <span class="n">max_memory</span><span class="p">:</span>
                    <span class="n">chunk_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">max_memory</span> <span class="o">/</span> <span class="p">(</span><span class="n">n_samples</span> <span class="o">*</span> <span class="n">bytes_per_element</span><span class="p">))</span>
                    <span class="n">chunk_size</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="n">chunk_size</span><span class="p">)</span>  <span class="c1"># Minimum chunk size</span>
                
                <span class="c1"># With FP16, we can use larger chunks!</span>
                <span class="k">if</span> <span class="n">use_fp16</span><span class="p">:</span>
                    <span class="n">chunk_size</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">chunk_size</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">100000</span><span class="p">)</span>  <span class="c1"># Double chunk size for FP16</span>
            
            <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Using chunk size: </span><span class="si">{</span><span class="n">chunk_size</span><span class="si">}</span><span class="s2"> (GPU memory: </span><span class="si">{</span><span class="n">gpu_mem_free</span><span class="o">/</span><span class="mi">1024</span><span class="o">**</span><span class="mi">3</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2">GB, dtype: </span><span class="si">{</span><span class="n">dtype</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>
        
        <span class="c1"># Initialize arrays for results</span>
        <span class="n">all_knn_indices</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">all_knn_distances</span> <span class="o">=</span> <span class="p">[]</span>
        
        <span class="c1"># Process in chunks to avoid memory issues</span>
        <span class="k">for</span> <span class="n">start_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">,</span> <span class="n">chunk_size</span><span class="p">):</span>
            <span class="n">end_idx</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">start_idx</span> <span class="o">+</span> <span class="n">chunk_size</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">)</span>
            
            <span class="k">if</span> <span class="n">n_samples</span> <span class="o">&gt;</span> <span class="mi">50000</span><span class="p">:</span>  <span class="c1"># Only log for large datasets</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Processing chunk </span><span class="si">{</span><span class="n">start_idx</span><span class="o">//</span><span class="n">chunk_size</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="p">(</span><span class="n">n_samples</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">chunk_size</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="o">//</span><span class="n">chunk_size</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            
            <span class="c1"># Get chunk data</span>
            <span class="n">X_chunk</span> <span class="o">=</span> <span class="n">X_torch</span><span class="p">[</span><span class="n">start_idx</span><span class="p">:</span><span class="n">end_idx</span><span class="p">]</span>  <span class="c1"># (chunk_size, D)</span>
            
            <span class="k">if</span> <span class="n">use_pykeops</span><span class="p">:</span>
                <span class="c1"># Use PyKeOps for LOW dimensional data</span>
                <span class="c1"># Ensure contiguity for PyKeOps</span>
                <span class="n">X_i</span> <span class="o">=</span> <span class="n">LazyTensor</span><span class="p">(</span><span class="n">X_chunk</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">contiguous</span><span class="p">())</span>  <span class="c1"># (chunk_size, 1, D)</span>
                <span class="n">X_j</span> <span class="o">=</span> <span class="n">LazyTensor</span><span class="p">(</span><span class="n">X_torch</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]</span><span class="o">.</span><span class="n">contiguous</span><span class="p">())</span>   <span class="c1"># (1, N, D)</span>
                
                <span class="c1"># Compute squared distances</span>
                <span class="n">D_ij</span> <span class="o">=</span> <span class="p">((</span><span class="n">X_i</span> <span class="o">-</span> <span class="n">X_j</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># (chunk_size, N) LazyTensor</span>
                
                <span class="c1"># Find k+1 nearest neighbors (including self)</span>
                <span class="n">knn_dists</span><span class="p">,</span> <span class="n">knn_indices</span> <span class="o">=</span> <span class="n">D_ij</span><span class="o">.</span><span class="n">Kmin_argKmin</span><span class="p">(</span><span class="n">K</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_neighbors</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
                
                <span class="c1"># Remove self and convert to actual distances</span>
                <span class="n">chunk_indices</span> <span class="o">=</span> <span class="n">knn_indices</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:]</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
                <span class="n">chunk_distances</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">knn_dists</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:])</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># Use PyTorch for HIGH dimensional data (MUCH faster!)</span>
                <span class="n">distances</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cdist</span><span class="p">(</span><span class="n">X_chunk</span><span class="p">,</span> <span class="n">X_torch</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
                <span class="n">knn_dists</span><span class="p">,</span> <span class="n">knn_indices</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">topk</span><span class="p">(</span><span class="n">distances</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_neighbors</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> 
                                                   <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">largest</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
                
                <span class="c1"># Remove self</span>
                <span class="n">chunk_indices</span> <span class="o">=</span> <span class="n">knn_indices</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:]</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>  
                <span class="n">chunk_distances</span> <span class="o">=</span> <span class="n">knn_dists</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:]</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
            
            <span class="n">all_knn_indices</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">chunk_indices</span><span class="p">)</span>
            <span class="n">all_knn_distances</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">chunk_distances</span><span class="p">)</span>
            
            <span class="c1"># Clear GPU memory periodically</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="s1">&#39;cuda&#39;</span> <span class="ow">and</span> <span class="n">start_idx</span> <span class="o">%</span> <span class="p">(</span><span class="n">chunk_size</span> <span class="o">*</span> <span class="mi">10</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>
        
        <span class="c1"># Concatenate results</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_knn_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">(</span><span class="n">all_knn_indices</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_knn_distances</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">(</span><span class="n">all_knn_distances</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;k-NN graph computed: shape </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_knn_indices</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_initialize_embedding</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initialize the low-dimensional embedding.</span>
<span class="sd">        </span>
<span class="sd">        This private method creates the initial embedding using either PCA or random</span>
<span class="sd">        projection, then normalizes the result.</span>
<span class="sd">        </span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : numpy.ndarray</span>
<span class="sd">            Input high-dimensional data of shape (n_samples, n_features).</span>
<span class="sd">            </span>
<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        torch.Tensor</span>
<span class="sd">            Initial embedding of shape (n_samples, n_components) on the target device.</span>
<span class="sd">            </span>
<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        Private method, should not be called directly. Used by fit_transform().</span>
<span class="sd">        </span>
<span class="sd">        The embedding is normalized to have zero mean and unit standard deviation</span>
<span class="sd">        along each dimension.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">init</span> <span class="o">==</span> <span class="s1">&#39;pca&#39;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Initializing with PCA&quot;</span><span class="p">)</span>
            <span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_components</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">random_state</span><span class="p">)</span>
            <span class="n">embedding</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">init</span> <span class="o">==</span> <span class="s1">&#39;random&#39;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Initializing with random projection&quot;</span><span class="p">)</span>
            <span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">random_state</span><span class="p">)</span>  <span class="c1"># pylint: disable=no-member</span>
            <span class="n">projection</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_components</span><span class="p">)</span>
            <span class="n">projection</span> <span class="o">/=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">projection</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">embedding</span> <span class="o">=</span> <span class="n">X</span> <span class="o">@</span> <span class="n">projection</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unknown init method: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">init</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Normalize</span>
        <span class="n">embedding</span> <span class="o">-=</span> <span class="n">embedding</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">embedding</span> <span class="o">/=</span> <span class="n">embedding</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">embedding</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_compute_forces</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">positions</span><span class="p">,</span> <span class="n">iteration</span><span class="p">,</span> <span class="n">max_iterations</span><span class="p">,</span> <span class="n">chunk_size</span><span class="o">=</span><span class="mi">5000</span><span class="p">):</span>  <span class="c1"># pylint: disable=too-many-branches,too-many-locals</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute attraction and repulsion forces for layout optimization.</span>
<span class="sd">        </span>
<span class="sd">        This private method computes forces between points in the embedding space</span>
<span class="sd">        using a memory-efficient chunked approach. Attraction forces are computed</span>
<span class="sd">        only between k-nearest neighbors, while repulsion forces use random sampling.</span>
<span class="sd">        </span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        positions : torch.Tensor</span>
<span class="sd">            Current positions of points in embedding space, shape (n_samples, n_components).</span>
<span class="sd">        iteration : int</span>
<span class="sd">            Current iteration number (0-indexed).</span>
<span class="sd">        max_iterations : int</span>
<span class="sd">            Total number of iterations planned.</span>
<span class="sd">        chunk_size : int, default=5000</span>
<span class="sd">            Maximum chunk size for memory-efficient processing.</span>
<span class="sd">            </span>
<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        torch.Tensor</span>
<span class="sd">            Computed forces of shape (n_samples, n_components).</span>
<span class="sd">            </span>
<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        Private method, should not be called directly. Used by _optimize_layout().</span>
<span class="sd">        </span>
<span class="sd">        Force Computation:</span>
<span class="sd">        - **Attraction forces**: Applied only between k-nearest neighbors using</span>
<span class="sd">          the kernel function 1 / (1 + a * (1/d)^(2*b))</span>
<span class="sd">        - **Repulsion forces**: Applied between randomly sampled pairs using</span>
<span class="sd">          the kernel function -1 / (1 + a * d^(2*b)) with exponential cutoff</span>
<span class="sd">        - **Cooling**: Forces are scaled by (1 - iteration/max_iterations)</span>
<span class="sd">        - **Clipping**: Forces are clipped to [-cutoff, cutoff] range</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># PyKeOps is optional - we can use pure PyTorch</span>
        <span class="c1"># if not PYKEOPS_AVAILABLE:</span>
        <span class="c1">#     raise RuntimeError(&quot;PyKeOps required for efficient force computation&quot;)</span>

        <span class="n">n_samples</span> <span class="o">=</span> <span class="n">positions</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">forces</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">positions</span><span class="p">)</span>

        <span class="c1"># Linear cooling schedule</span>
        <span class="n">alpha</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">iteration</span> <span class="o">/</span> <span class="n">max_iterations</span>

        <span class="c1"># Parameters</span>
        <span class="n">a_val</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_a</span><span class="p">)</span>
        <span class="n">b_val</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_b</span><span class="p">)</span>
        <span class="n">b_exp</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">b_val</span><span class="p">)</span>
        
        <span class="c1"># Adjust chunk size based on available memory</span>
        <span class="c1"># Estimate memory usage: chunk_size * (k + n_neg) * D * 4 bytes</span>
        <span class="n">n_neg_samples</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">neg_ratio</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_neighbors</span><span class="p">),</span> <span class="n">n_samples</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">n_dims</span> <span class="o">=</span> <span class="n">positions</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        
        <span class="c1"># Memory estimate per point (in bytes):</span>
        <span class="c1"># k*D*4 for attraction + n_neg*D*4 for repulsion</span>
        <span class="n">bytes_per_float</span> <span class="o">=</span> <span class="mi">4</span>
        <span class="n">memory_per_point</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_neighbors</span> <span class="o">+</span> <span class="n">n_neg_samples</span><span class="p">)</span> <span class="o">*</span> <span class="n">n_dims</span> <span class="o">*</span> <span class="n">bytes_per_float</span> <span class="o">*</span> <span class="mi">2</span>  <span class="c1"># x2 for safety</span>
        
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="s1">&#39;cuda&#39;</span><span class="p">:</span>
            <span class="c1"># Get available GPU memory and use 20% for force computation (more conservative)</span>
            <span class="n">gpu_mem_free</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">mem_get_info</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">max_chunk_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">gpu_mem_free</span> <span class="o">*</span> <span class="mf">0.2</span> <span class="o">/</span> <span class="n">memory_per_point</span><span class="p">)</span>
            <span class="n">chunk_size</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">chunk_size</span><span class="p">,</span> <span class="n">max_chunk_size</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">)</span>
            <span class="c1"># For very large datasets, be extra conservative</span>
            <span class="k">if</span> <span class="n">n_samples</span> <span class="o">&gt;</span> <span class="mi">500000</span><span class="p">:</span>
                <span class="n">chunk_size</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">chunk_size</span><span class="p">,</span> <span class="mi">2000</span><span class="p">)</span>
            <span class="c1"># Ensure reasonable chunk size</span>
            <span class="n">chunk_size</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="nb">min</span><span class="p">(</span><span class="n">chunk_size</span><span class="p">,</span> <span class="mi">5000</span><span class="p">))</span>  <span class="c1"># Between 100 and 5000</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Using chunk size: </span><span class="si">{</span><span class="n">chunk_size</span><span class="si">}</span><span class="s2"> (available memory: </span><span class="si">{</span><span class="n">gpu_mem_free</span><span class="o">/</span><span class="mf">1e9</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2"> GB)&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">chunk_size</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">)</span>  <span class="c1"># Smaller chunks for CPU</span>

        <span class="c1"># Process in chunks to manage memory</span>
        <span class="n">knn_indices_torch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_knn_indices</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        
        <span class="k">for</span> <span class="n">start_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">,</span> <span class="n">chunk_size</span><span class="p">):</span>
            <span class="n">end_idx</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">start_idx</span> <span class="o">+</span> <span class="n">chunk_size</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">)</span>
            <span class="n">chunk_indices</span> <span class="o">=</span> <span class="nb">slice</span><span class="p">(</span><span class="n">start_idx</span><span class="p">,</span> <span class="n">end_idx</span><span class="p">)</span>
            <span class="n">chunk_size_actual</span> <span class="o">=</span> <span class="n">end_idx</span> <span class="o">-</span> <span class="n">start_idx</span>
            
            <span class="c1"># ============ ATTRACTION FORCES (k-NN only) ============</span>
            <span class="c1"># Get chunk data</span>
            <span class="n">chunk_positions</span> <span class="o">=</span> <span class="n">positions</span><span class="p">[</span><span class="n">chunk_indices</span><span class="p">]</span>  <span class="c1"># (chunk, D)</span>
            <span class="n">chunk_knn_indices</span> <span class="o">=</span> <span class="n">knn_indices_torch</span><span class="p">[</span><span class="n">chunk_indices</span><span class="p">]</span>  <span class="c1"># (chunk, k)</span>
            
            <span class="c1"># Check if we have enough memory for vectorized computation</span>
            <span class="n">attraction_memory</span> <span class="o">=</span> <span class="n">chunk_size_actual</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_neighbors</span> <span class="o">*</span> <span class="n">n_dims</span> <span class="o">*</span> <span class="n">bytes_per_float</span>
            
            <span class="k">try</span><span class="p">:</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="s1">&#39;cuda&#39;</span><span class="p">:</span>
                    <span class="n">gpu_mem_free</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">mem_get_info</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
                    <span class="k">if</span> <span class="n">attraction_memory</span> <span class="o">&gt;</span> <span class="n">gpu_mem_free</span> <span class="o">*</span> <span class="mf">0.4</span><span class="p">:</span>
                        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Not enough memory for vectorized attraction&quot;</span><span class="p">)</span>
                
                <span class="c1"># Try vectorized version (faster)</span>
                <span class="n">neighbor_positions</span> <span class="o">=</span> <span class="n">positions</span><span class="p">[</span><span class="n">chunk_knn_indices</span><span class="p">]</span>  <span class="c1"># (chunk, k, D)</span>
                <span class="n">current_positions</span> <span class="o">=</span> <span class="n">chunk_positions</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># (chunk, 1, D)</span>
                
                <span class="c1"># Compute differences and distances</span>
                <span class="n">diff</span> <span class="o">=</span> <span class="n">neighbor_positions</span> <span class="o">-</span> <span class="n">current_positions</span>  <span class="c1"># (chunk, k, D)</span>
                <span class="n">dist</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">diff</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="o">+</span> <span class="mf">1e-10</span>  <span class="c1"># (chunk, k, 1)</span>
                
                <span class="c1"># Attraction kernel</span>
                <span class="n">att_coeff</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">+</span> <span class="n">a_val</span> <span class="o">*</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">/</span> <span class="n">dist</span><span class="p">)</span> <span class="o">**</span> <span class="n">b_exp</span><span class="p">)</span>  <span class="c1"># (chunk, k, 1)</span>
                
                <span class="c1"># Compute attraction forces and sum over neighbors</span>
                <span class="n">att_forces</span> <span class="o">=</span> <span class="p">(</span><span class="n">att_coeff</span> <span class="o">*</span> <span class="n">diff</span> <span class="o">/</span> <span class="n">dist</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># (chunk, D)</span>
                <span class="n">forces</span><span class="p">[</span><span class="n">chunk_indices</span><span class="p">]</span> <span class="o">+=</span> <span class="n">att_forces</span>
                
            <span class="k">except</span> <span class="p">(</span><span class="ne">RuntimeError</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">OutOfMemoryError</span><span class="p">):</span>
                <span class="c1"># Fall back to point-by-point if memory is tight</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="s1">&#39;cuda&#39;</span><span class="p">:</span>
                    <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;Falling back to point-by-point attraction due to memory constraints&quot;</span><span class="p">)</span>
                
                <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">start_idx</span><span class="p">,</span> <span class="n">end_idx</span><span class="p">):</span>
                    <span class="n">neighbor_ids</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_knn_indices</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
                    <span class="n">pos_i</span> <span class="o">=</span> <span class="n">positions</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span>
                    <span class="n">pos_neighbors</span> <span class="o">=</span> <span class="n">positions</span><span class="p">[</span><span class="n">neighbor_ids</span><span class="p">]</span>
                    
                    <span class="n">diff</span> <span class="o">=</span> <span class="n">pos_neighbors</span> <span class="o">-</span> <span class="n">pos_i</span>
                    <span class="n">dist</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">diff</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="o">+</span> <span class="mf">1e-10</span>
                    <span class="n">att_coeff</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">+</span> <span class="n">a_val</span> <span class="o">*</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">/</span> <span class="n">dist</span><span class="p">)</span> <span class="o">**</span> <span class="n">b_exp</span><span class="p">)</span>
                    <span class="n">forces</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+=</span> <span class="p">(</span><span class="n">att_coeff</span> <span class="o">*</span> <span class="n">diff</span> <span class="o">/</span> <span class="n">dist</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

            <span class="c1"># ============ REPULSION FORCES (Random Sampling) ============</span>
            <span class="k">if</span> <span class="n">n_neg_samples</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="c1"># Check memory for repulsion</span>
                <span class="n">repulsion_memory</span> <span class="o">=</span> <span class="n">chunk_size_actual</span> <span class="o">*</span> <span class="n">n_neg_samples</span> <span class="o">*</span> <span class="n">n_dims</span> <span class="o">*</span> <span class="n">bytes_per_float</span>
                
                <span class="k">try</span><span class="p">:</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="s1">&#39;cuda&#39;</span><span class="p">:</span>
                        <span class="n">gpu_mem_free</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">mem_get_info</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
                        <span class="k">if</span> <span class="n">repulsion_memory</span> <span class="o">&gt;</span> <span class="n">gpu_mem_free</span> <span class="o">*</span> <span class="mf">0.4</span><span class="p">:</span>
                            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Not enough memory for vectorized repulsion&quot;</span><span class="p">)</span>
                    
                    <span class="c1"># Try vectorized version</span>
                    <span class="c1"># Generate random samples for this chunk</span>
                    <span class="n">neg_indices</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">,</span> <span class="p">(</span><span class="n">chunk_size_actual</span><span class="p">,</span> <span class="n">n_neg_samples</span> <span class="o">+</span> <span class="mi">5</span><span class="p">),</span> 
                                              <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
                    
                    <span class="c1"># Create mask to exclude points from the current chunk</span>
                    <span class="n">chunk_range</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">start_idx</span><span class="p">,</span> <span class="n">end_idx</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
                    <span class="n">self_mask</span> <span class="o">=</span> <span class="n">neg_indices</span> <span class="o">==</span> <span class="n">chunk_range</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
                    
                    <span class="c1"># Replace self indices with valid random ones</span>
                    <span class="n">replacement_indices</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">,</span> <span class="p">(</span><span class="n">chunk_size_actual</span><span class="p">,</span> <span class="n">n_neg_samples</span> <span class="o">+</span> <span class="mi">5</span><span class="p">),</span> 
                                                      <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
                    <span class="n">neg_indices</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">self_mask</span><span class="p">,</span> <span class="n">replacement_indices</span><span class="p">,</span> <span class="n">neg_indices</span><span class="p">)</span>
                    
                    <span class="c1"># Take first n_neg_samples</span>
                    <span class="n">neg_indices</span> <span class="o">=</span> <span class="n">neg_indices</span><span class="p">[:,</span> <span class="p">:</span><span class="n">n_neg_samples</span><span class="p">]</span>
                    
                    <span class="c1"># Get negative sample positions</span>
                    <span class="n">neg_positions</span> <span class="o">=</span> <span class="n">positions</span><span class="p">[</span><span class="n">neg_indices</span><span class="p">]</span>  <span class="c1"># (chunk, n_neg, D)</span>
                    <span class="n">current_positions</span> <span class="o">=</span> <span class="n">chunk_positions</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># (chunk, 1, D)</span>
                    
                    <span class="c1"># Compute differences and distances</span>
                    <span class="n">diff</span> <span class="o">=</span> <span class="n">neg_positions</span> <span class="o">-</span> <span class="n">current_positions</span>  <span class="c1"># (chunk, n_neg, D)</span>
                    <span class="n">dist</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">diff</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="o">+</span> <span class="mf">1e-10</span>  <span class="c1"># (chunk, n_neg, 1)</span>
                    
                    <span class="c1"># Repulsion kernel</span>
                    <span class="n">rep_coeff</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.0</span> <span class="o">/</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">+</span> <span class="n">a_val</span> <span class="o">*</span> <span class="p">(</span><span class="n">dist</span> <span class="o">**</span> <span class="n">b_exp</span><span class="p">))</span>  <span class="c1"># (chunk, n_neg, 1)</span>
                    
                    <span class="c1"># Apply distance cutoff</span>
                    <span class="n">cutoff_scale</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">dist</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">cutoff</span><span class="p">)</span>
                    <span class="n">rep_coeff</span> <span class="o">=</span> <span class="n">rep_coeff</span> <span class="o">*</span> <span class="n">cutoff_scale</span>
                    
                    <span class="c1"># Compute repulsion forces and sum over negative samples</span>
                    <span class="n">rep_forces</span> <span class="o">=</span> <span class="p">(</span><span class="n">rep_coeff</span> <span class="o">*</span> <span class="n">diff</span> <span class="o">/</span> <span class="n">dist</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># (chunk, D)</span>
                    <span class="n">forces</span><span class="p">[</span><span class="n">chunk_indices</span><span class="p">]</span> <span class="o">+=</span> <span class="n">rep_forces</span>
                    
                <span class="k">except</span> <span class="p">(</span><span class="ne">RuntimeError</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">OutOfMemoryError</span><span class="p">):</span>
                    <span class="c1"># Fall back to point-by-point</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="s1">&#39;cuda&#39;</span><span class="p">:</span>
                        <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;Falling back to point-by-point repulsion due to memory constraints&quot;</span><span class="p">)</span>
                    
                    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">start_idx</span><span class="p">,</span> <span class="n">end_idx</span><span class="p">):</span>
                        <span class="c1"># Random sample for repulsion</span>
                        <span class="n">neg_samples</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="nb">min</span><span class="p">(</span><span class="n">n_neg_samples</span><span class="p">,</span> <span class="n">n_samples</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
                        <span class="n">neg_samples</span> <span class="o">=</span> <span class="n">neg_samples</span><span class="p">[</span><span class="n">neg_samples</span> <span class="o">!=</span> <span class="n">i</span><span class="p">][:</span><span class="n">n_neg_samples</span><span class="p">]</span>  <span class="c1"># Exclude self</span>
                        
                        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">neg_samples</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                            <span class="n">pos_i</span> <span class="o">=</span> <span class="n">positions</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span>
                            <span class="n">pos_neg</span> <span class="o">=</span> <span class="n">positions</span><span class="p">[</span><span class="n">neg_samples</span><span class="p">]</span>
                            
                            <span class="c1"># Compute differences and distances</span>
                            <span class="n">diff</span> <span class="o">=</span> <span class="n">pos_neg</span> <span class="o">-</span> <span class="n">pos_i</span>
                            <span class="n">dist</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">diff</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="o">+</span> <span class="mf">1e-10</span>
                            
                            <span class="c1"># Repulsion kernel</span>
                            <span class="n">rep_coeff</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.0</span> <span class="o">/</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">+</span> <span class="n">a_val</span> <span class="o">*</span> <span class="p">(</span><span class="n">dist</span> <span class="o">**</span> <span class="n">b_exp</span><span class="p">))</span>
                            
                            <span class="c1"># Apply distance cutoff</span>
                            <span class="n">cutoff_scale</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">dist</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">cutoff</span><span class="p">)</span>
                            <span class="n">rep_coeff</span> <span class="o">=</span> <span class="n">rep_coeff</span> <span class="o">*</span> <span class="n">cutoff_scale</span>
                            
                            <span class="c1"># Apply force</span>
                            <span class="n">forces</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+=</span> <span class="p">(</span><span class="n">rep_coeff</span> <span class="o">*</span> <span class="n">diff</span> <span class="o">/</span> <span class="n">dist</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

        <span class="c1"># Apply cooling and clipping</span>
        <span class="n">forces</span> <span class="o">=</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">forces</span>
        <span class="n">forces</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">forces</span><span class="p">,</span> <span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">cutoff</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">cutoff</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">forces</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_optimize_layout</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">initial_positions</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Optimize the embedding layout using iterative force computation.</span>
<span class="sd">        </span>
<span class="sd">        This private method performs the main optimization loop, iteratively</span>
<span class="sd">        computing and applying forces to refine the embedding layout.</span>
<span class="sd">        </span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        initial_positions : torch.Tensor</span>
<span class="sd">            Initial embedding positions of shape (n_samples, n_components).</span>
<span class="sd">            </span>
<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        torch.Tensor</span>
<span class="sd">            Optimized final positions of shape (n_samples, n_components),</span>
<span class="sd">            normalized to zero mean and unit standard deviation.</span>
<span class="sd">            </span>
<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        Private method, should not be called directly. Used by fit_transform().</span>
<span class="sd">        </span>
<span class="sd">        The optimization uses a simple force-directed layout algorithm with</span>
<span class="sd">        linear cooling schedule.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">positions</span> <span class="o">=</span> <span class="n">initial_positions</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Optimizing layout for </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_n_samples</span><span class="si">}</span><span class="s2"> points...&quot;</span><span class="p">)</span>

        <span class="c1"># Optimization loop</span>
        <span class="k">for</span> <span class="n">iteration</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">max_iter_layout</span><span class="p">):</span>
            <span class="c1"># Compute forces correctly</span>
            <span class="n">forces</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_forces</span><span class="p">(</span><span class="n">positions</span><span class="p">,</span> <span class="n">iteration</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_iter_layout</span><span class="p">)</span>

            <span class="c1"># Update positions</span>
            <span class="n">positions</span> <span class="o">+=</span> <span class="n">forces</span>

            <span class="c1"># Log progress every 20th iteration</span>
            <span class="k">if</span> <span class="n">iteration</span> <span class="o">%</span> <span class="mi">20</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Iteration </span><span class="si">{</span><span class="n">iteration</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">max_iter_layout</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Final normalization</span>
        <span class="n">positions</span> <span class="o">-=</span> <span class="n">positions</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">positions</span> <span class="o">/=</span> <span class="n">positions</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">positions</span>

<div class="viewcode-block" id="DiRePyTorch.fit_transform">
<a class="viewcode-back" href="../../api/modules.html#dire_rapids.dire_pytorch.DiRePyTorch.fit_transform">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">fit_transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>  <span class="c1"># pylint: disable=unused-argument,arguments-differ</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Fit the DiRe model and transform data to low-dimensional embedding.</span>
<span class="sd">        </span>
<span class="sd">        This method performs the complete dimensionality reduction pipeline:</span>
<span class="sd">        1. Computes k-nearest neighbors graph</span>
<span class="sd">        2. Fits kernel parameters</span>
<span class="sd">        3. Initializes embedding with PCA or random projection</span>
<span class="sd">        4. Optimizes layout using force-directed algorithm</span>
<span class="sd">        </span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array-like of shape (n_samples, n_features)</span>
<span class="sd">            High-dimensional input data to transform.</span>
<span class="sd">        y : array-like of shape (n_samples,), optional</span>
<span class="sd">            Ignored. Present for scikit-learn API compatibility.</span>
<span class="sd">            </span>
<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        numpy.ndarray of shape (n_samples, n_components)</span>
<span class="sd">            Low-dimensional embedding of the input data.</span>
<span class="sd">            </span>
<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        Transform high-dimensional data::</span>
<span class="sd">        </span>
<span class="sd">            import numpy as np</span>
<span class="sd">            from dire_rapids import DiRePyTorch</span>
<span class="sd">            </span>
<span class="sd">            X = np.random.randn(1000, 100)</span>
<span class="sd">            reducer = DiRePyTorch(n_neighbors=16)</span>
<span class="sd">            embedding = reducer.fit_transform(X)</span>
<span class="sd">            print(embedding.shape)  # (1000, 2)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Store data</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_n_samples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Processing </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_n_samples</span><span class="si">}</span><span class="s2"> samples with </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2"> features&quot;</span><span class="p">)</span>

        <span class="c1"># Find distribution kernel parameters</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_find_ab_params</span><span class="p">()</span>

        <span class="c1"># Compute k-NN graph</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_compute_knn</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_data</span><span class="p">)</span>

        <span class="c1"># Initialize embedding</span>
        <span class="n">initial_embedding</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_initialize_embedding</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_data</span><span class="p">)</span>

        <span class="c1"># Optimize layout</span>
        <span class="n">final_embedding</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_optimize_layout</span><span class="p">(</span><span class="n">initial_embedding</span><span class="p">)</span>

        <span class="c1"># Convert back to numpy and store</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_layout</span> <span class="o">=</span> <span class="n">final_embedding</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

        <span class="c1"># Clear GPU memory</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="s1">&#39;cuda&#39;</span><span class="p">:</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>
        <span class="n">gc</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_layout</span></div>


<div class="viewcode-block" id="DiRePyTorch.fit">
<a class="viewcode-back" href="../../api/modules.html#dire_rapids.dire_pytorch.DiRePyTorch.fit">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>  <span class="c1"># pylint: disable=unused-argument,arguments-differ</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Fit the DiRe model to data without transforming.</span>
<span class="sd">        </span>
<span class="sd">        This method fits the model by computing the k-NN graph, kernel parameters,</span>
<span class="sd">        and optimized embedding, but primarily serves for scikit-learn compatibility.</span>
<span class="sd">        For practical use, fit_transform() is recommended.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : numpy.ndarray of shape (n_samples, n_features)</span>
<span class="sd">            High-dimensional data to fit the model to.</span>
<span class="sd">        y : array-like of shape (n_samples,), optional</span>
<span class="sd">            Ignored. Present for scikit-learn API compatibility.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        self : DiRePyTorch</span>
<span class="sd">            The fitted DiRe instance.</span>
<span class="sd">            </span>
<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        This method calls fit_transform() internally. The embedding result</span>
<span class="sd">        is stored in self._layout and can be accessed after fitting.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span></div>


<div class="viewcode-block" id="DiRePyTorch.visualize">
<a class="viewcode-back" href="../../api/modules.html#dire_rapids.dire_pytorch.DiRePyTorch.visualize">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">visualize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">point_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Create an interactive visualization of the embedding.</span>
<span class="sd">        </span>
<span class="sd">        This method creates a 2D or 3D scatter plot of the embedding using Plotly,</span>
<span class="sd">        with optional color coding by labels.</span>
<span class="sd">        </span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        labels : array-like of shape (n_samples,), optional</span>
<span class="sd">            Labels for coloring points in the visualization.</span>
<span class="sd">        point_size : int, default=2</span>
<span class="sd">            Size of points in the scatter plot.</span>
<span class="sd">        title : str, optional</span>
<span class="sd">            Title for the plot. If None, a default title is generated.</span>
<span class="sd">        **kwargs : dict</span>
<span class="sd">            Additional keyword arguments passed to plotly.express plotting functions.</span>
<span class="sd">            </span>
<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        plotly.graph_objects.Figure or None</span>
<span class="sd">            Interactive Plotly figure, or None if no embedding is available.</span>
<span class="sd">            </span>
<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        Basic visualization::</span>
<span class="sd">        </span>
<span class="sd">            fig = reducer.visualize()</span>
<span class="sd">            fig.show()</span>
<span class="sd">            </span>
<span class="sd">        With labels and custom styling::</span>
<span class="sd">        </span>
<span class="sd">            fig = reducer.visualize(</span>
<span class="sd">                labels=y, </span>
<span class="sd">                point_size=3, </span>
<span class="sd">                title=&quot;My Embedding&quot;,</span>
<span class="sd">                width=800, </span>
<span class="sd">                height=600</span>
<span class="sd">            )</span>
<span class="sd">            fig.show()</span>
<span class="sd">            </span>
<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        Requires a fitted model with available embedding (self._layout).</span>
<span class="sd">        Only supports 2D and 3D visualizations.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_layout</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;No layout available for visualization&quot;</span><span class="p">)</span>
            <span class="k">return</span> <span class="kc">None</span>

        <span class="k">if</span> <span class="n">title</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">title</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;PyTorch </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">n_components</span><span class="si">}</span><span class="s2">D Embedding&quot;</span>

        <span class="c1"># Create dataframe</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_components</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
            <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_layout</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="s1">&#39;y&#39;</span><span class="p">])</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_components</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
            <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_layout</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="s1">&#39;z&#39;</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Cannot visualize </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">n_components</span><span class="si">}</span><span class="s2">D embedding&quot;</span><span class="p">)</span>
            <span class="k">return</span> <span class="kc">None</span>

        <span class="c1"># Add labels if provided</span>
        <span class="k">if</span> <span class="n">labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">df</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">labels</span>

        <span class="c1"># Create plot</span>
        <span class="n">vis_params</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s1">&#39;color&#39;</span><span class="p">:</span> <span class="s1">&#39;label&#39;</span> <span class="k">if</span> <span class="n">labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
            <span class="s1">&#39;title&#39;</span><span class="p">:</span> <span class="n">title</span><span class="p">,</span>
        <span class="p">}</span>
        <span class="n">vis_params</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_components</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
            <span class="n">fig</span> <span class="o">=</span> <span class="n">px</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="o">**</span><span class="n">vis_params</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">fig</span> <span class="o">=</span> <span class="n">px</span><span class="o">.</span><span class="n">scatter_3d</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="n">z</span><span class="o">=</span><span class="s1">&#39;z&#39;</span><span class="p">,</span> <span class="o">**</span><span class="n">vis_params</span><span class="p">)</span>

        <span class="n">fig</span><span class="o">.</span><span class="n">update_traces</span><span class="p">(</span><span class="n">marker</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;size&#39;</span><span class="p">:</span> <span class="n">point_size</span><span class="p">})</span>

        <span class="k">return</span> <span class="n">fig</span></div>
</div>



<div class="viewcode-block" id="create_dire">
<a class="viewcode-back" href="../../api/modules.html#dire_rapids.dire_pytorch.create_dire">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">create_dire</span><span class="p">(</span><span class="n">backend</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span> <span class="n">memory_efficient</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create DiRe instance with automatic backend selection.</span>
<span class="sd">    </span>
<span class="sd">    This factory function automatically selects the optimal DiRe implementation</span>
<span class="sd">    based on available hardware and software, or allows manual backend selection.</span>
<span class="sd">    It provides a convenient interface for creating DiRe instances without</span>
<span class="sd">    importing specific backend classes.</span>
<span class="sd">    </span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    backend : {&#39;auto&#39;, &#39;cuvs&#39;, &#39;pytorch&#39;, &#39;pytorch_gpu&#39;, &#39;pytorch_cpu&#39;}, default=&#39;auto&#39;</span>
<span class="sd">        Backend selection strategy:</span>
<span class="sd">        </span>
<span class="sd">        - &#39;auto&#39;: Automatically select best available backend based on hardware</span>
<span class="sd">        - &#39;cuvs&#39;: Force RAPIDS cuVS backend (requires RAPIDS installation)</span>
<span class="sd">        - &#39;pytorch&#39;: Force PyTorch backend with automatic device selection</span>
<span class="sd">        - &#39;pytorch_gpu&#39;: Force PyTorch backend on GPU (requires CUDA)</span>
<span class="sd">        - &#39;pytorch_cpu&#39;: Force PyTorch backend on CPU only</span>
<span class="sd">        </span>
<span class="sd">    memory_efficient : bool, default=False</span>
<span class="sd">        If True, use memory-efficient PyTorch implementation which provides:</span>
<span class="sd">        </span>
<span class="sd">        - Reduced memory usage for large datasets</span>
<span class="sd">        - FP16 support for additional memory savings</span>
<span class="sd">        - Enhanced chunking strategies</span>
<span class="sd">        - More aggressive memory cleanup</span>
<span class="sd">        </span>
<span class="sd">    **kwargs : dict</span>
<span class="sd">        Additional keyword arguments passed to the DiRe constructor.</span>
<span class="sd">        See individual backend documentation for available parameters.</span>
<span class="sd">        Common parameters include: n_components, n_neighbors, metric,</span>
<span class="sd">        max_iter_layout, min_dist, spread, verbose, random_state.</span>
<span class="sd">    </span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    DiRe instance</span>
<span class="sd">        An instance of the selected DiRe backend (DiRePyTorch, DiRePyTorchMemoryEfficient,</span>
<span class="sd">        or DiReCuVS) configured with the specified parameters.</span>
<span class="sd">        </span>
<span class="sd">    Raises</span>
<span class="sd">    ------</span>
<span class="sd">    RuntimeError</span>
<span class="sd">        If a specific backend is requested but requirements are not met</span>
<span class="sd">        (e.g., requesting cuVS without RAPIDS, or GPU without CUDA).</span>
<span class="sd">    ValueError</span>
<span class="sd">        If an unknown backend name is specified.</span>
<span class="sd">        </span>
<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    Auto-select optimal backend::\n    </span>
<span class="sd">        from dire_rapids import create_dire</span>
<span class="sd">        </span>
<span class="sd">        # Will use cuVS if available, otherwise PyTorch with GPU if available</span>
<span class="sd">        reducer = create_dire(n_neighbors=32, verbose=True)</span>
<span class="sd">        embedding = reducer.fit_transform(X)</span>
<span class="sd">        </span>
<span class="sd">    Force memory-efficient mode for large datasets::\n    </span>
<span class="sd">        reducer = create_dire(</span>
<span class="sd">            memory_efficient=True,</span>
<span class="sd">            n_neighbors=50,</span>
<span class="sd">            max_iter_layout=200</span>
<span class="sd">        )</span>
<span class="sd">        </span>
<span class="sd">    Force specific backend::\n    </span>
<span class="sd">        # CPU-only processing</span>
<span class="sd">        reducer = create_dire(backend=&#39;pytorch_cpu&#39;)</span>
<span class="sd">        </span>
<span class="sd">        # GPU processing with cuVS acceleration</span>
<span class="sd">        reducer = create_dire(backend=&#39;cuvs&#39;, use_cuvs=True)</span>

<span class="sd">        # With custom distance metric</span>
<span class="sd">        reducer = create_dire(</span>
<span class="sd">            metric=&#39;(x - y).abs().sum(-1)&#39;,  # L1 distance</span>
<span class="sd">            n_neighbors=32,</span>
<span class="sd">            verbose=True</span>
<span class="sd">        )</span>
<span class="sd">        </span>
<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    Backend Selection Priority (when backend=&#39;auto&#39;):</span>
<span class="sd">    1. RAPIDS cuVS (if available and CUDA GPU present)</span>
<span class="sd">    2. PyTorch with CUDA (if CUDA GPU available)  </span>
<span class="sd">    3. PyTorch with CPU (fallback)</span>
<span class="sd">    </span>
<span class="sd">    The function automatically handles import errors and missing dependencies,</span>
<span class="sd">    falling back to available alternatives when possible.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Handle verbose parameter early to disable logging if needed</span>
    <span class="n">verbose</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;verbose&#39;</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
    
    <span class="c1"># Import here to avoid circular imports</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">.dire_cuvs</span><span class="w"> </span><span class="kn">import</span> <span class="n">DiReCuVS</span>
        <span class="n">CUVS_AVAILABLE</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
        <span class="n">CUVS_AVAILABLE</span> <span class="o">=</span> <span class="kc">False</span>
    
    <span class="kn">from</span><span class="w"> </span><span class="nn">.dire_pytorch_memory_efficient</span><span class="w"> </span><span class="kn">import</span> <span class="n">DiRePyTorchMemoryEfficient</span>
    
    <span class="k">if</span> <span class="n">backend</span> <span class="o">==</span> <span class="s1">&#39;auto&#39;</span><span class="p">:</span>
        <span class="c1"># Auto-select best backend based on availability</span>
        <span class="k">if</span> <span class="n">CUVS_AVAILABLE</span> <span class="ow">and</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Auto-selected RAPIDS cuVS backend (GPU acceleration)&quot;</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">DiReCuVS</span><span class="p">(</span><span class="n">use_cuvs</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">memory_efficient</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Auto-selected memory-efficient PyTorch backend (GPU)&quot;</span><span class="p">)</span>
                <span class="k">return</span> <span class="n">DiRePyTorchMemoryEfficient</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Auto-selected PyTorch backend (GPU)&quot;</span><span class="p">)</span>
                <span class="k">return</span> <span class="n">DiRePyTorch</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        
        <span class="c1"># CPU fallback</span>
        <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Auto-selected PyTorch backend (CPU)&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">memory_efficient</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;Memory-efficient mode has limited benefits on CPU&quot;</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">DiRePyTorchMemoryEfficient</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">DiRePyTorch</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    
    <span class="k">elif</span> <span class="n">backend</span> <span class="o">==</span> <span class="s1">&#39;cuvs&#39;</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">CUVS_AVAILABLE</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="s2">&quot;cuVS backend requested but RAPIDS not installed. &quot;</span>
                <span class="s2">&quot;Follow the installation instructions at https://docs.rapids.ai/install/&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;cuVS backend requires CUDA GPU&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Using RAPIDS cuVS backend&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">DiReCuVS</span><span class="p">(</span><span class="n">use_cuvs</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    
    <span class="k">elif</span> <span class="n">backend</span> <span class="o">==</span> <span class="s1">&#39;pytorch&#39;</span><span class="p">:</span>
        <span class="c1"># Use PyTorch with auto device selection</span>
        <span class="k">if</span> <span class="n">memory_efficient</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Using memory-efficient PyTorch backend&quot;</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">DiRePyTorchMemoryEfficient</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Using PyTorch backend&quot;</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">DiRePyTorch</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    
    <span class="k">elif</span> <span class="n">backend</span> <span class="o">==</span> <span class="s1">&#39;pytorch_gpu&#39;</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;GPU requested but CUDA not available&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">memory_efficient</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Using memory-efficient PyTorch backend (GPU)&quot;</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">DiRePyTorchMemoryEfficient</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Using PyTorch backend (GPU)&quot;</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">DiRePyTorch</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    
    <span class="k">elif</span> <span class="n">backend</span> <span class="o">==</span> <span class="s1">&#39;pytorch_cpu&#39;</span><span class="p">:</span>
        <span class="c1"># Force CPU even if GPU is available</span>
        <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Using PyTorch backend (forced CPU)&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">memory_efficient</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;Memory-efficient mode has limited benefits on CPU&quot;</span><span class="p">)</span>
            <span class="c1"># Create instance and force CPU</span>
            <span class="n">reducer</span> <span class="o">=</span> <span class="n">DiRePyTorchMemoryEfficient</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">reducer</span> <span class="o">=</span> <span class="n">DiRePyTorch</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="n">reducer</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">reducer</span>
    
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Unknown backend: </span><span class="si">{</span><span class="n">backend</span><span class="si">}</span><span class="s2">. &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;Choose from: &#39;auto&#39;, &#39;cuvs&#39;, &#39;pytorch&#39;, &#39;pytorch_gpu&#39;, &#39;pytorch_cpu&#39;&quot;</span>
        <span class="p">)</span></div>

</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2024, Alexander Kolpakov (UATX), Igor Rivin (Temple University).</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>