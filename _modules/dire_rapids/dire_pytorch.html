

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>dire_rapids.dire_pytorch &mdash; dire-rapids 0.2.0 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../../_static/css/theme.css?v=9edc463e" />

  
      <script src="../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../_static/documentation_options.js?v=938c9ccc"></script>
      <script src="../../_static/doctools.js?v=9a2dae69"></script>
      <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search"  style="background: white" >

          
          
          <a href="../../index.html" class="icon icon-home">
            dire-rapids
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../api/modules.html">dire_rapids</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu"  style="background: white" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">dire-rapids</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../index.html">Module code</a></li>
      <li class="breadcrumb-item active">dire_rapids.dire_pytorch</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for dire_rapids.dire_pytorch</h1><div class="highlight"><pre>
<span></span><span class="c1"># dire_pytorch.py</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">PyTorch/PyKeOps backend for DiRe dimensionality reduction.</span>

<span class="sd">This implementation features:</span>
<span class="sd">- Memory-efficient chunked k-NN computation for large datasets (&gt;100K points)</span>
<span class="sd">- Attraction forces applied only between k-NN neighbors  </span>
<span class="sd">- Repulsion forces computed from random samples</span>
<span class="sd">- Automatic GPU memory management with adaptive chunk sizing</span>
<span class="sd">- Designed for high-performance processing on CUDA GPUs</span>

<span class="sd">Performance characteristics:</span>
<span class="sd">- Best for datasets &gt;50K points on CUDA GPUs</span>
<span class="sd">- Memory-aware processing up to millions of points</span>
<span class="sd">- Chunked computation prevents GPU out-of-memory errors</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">gc</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">sys</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">plotly.express</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">px</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">loguru</span><span class="w"> </span><span class="kn">import</span> <span class="n">logger</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">scipy.optimize</span><span class="w"> </span><span class="kn">import</span> <span class="n">curve_fit</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.base</span><span class="w"> </span><span class="kn">import</span> <span class="n">TransformerMixin</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.decomposition</span><span class="w"> </span><span class="kn">import</span> <span class="n">PCA</span>

<span class="c1"># PyKeOps for efficient force computations</span>
<span class="k">try</span><span class="p">:</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">pykeops.torch</span><span class="w"> </span><span class="kn">import</span> <span class="n">LazyTensor</span>

    <span class="n">PYKEOPS_AVAILABLE</span> <span class="o">=</span> <span class="kc">True</span>
<span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
    <span class="n">PYKEOPS_AVAILABLE</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;PyKeOps not available. Install with: pip install pykeops&quot;</span><span class="p">)</span>

<span class="c1"># cuVS for fast approximate k-NN at scale (optional RAPIDS dependency)</span>
<span class="k">try</span><span class="p">:</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">cupy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">cp</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">cuvs.neighbors</span><span class="w"> </span><span class="kn">import</span> <span class="n">ivf_flat</span> <span class="k">as</span> <span class="n">cuvs_ivf_flat</span>
    <span class="n">CUVS_AVAILABLE</span> <span class="o">=</span> <span class="kc">True</span>
<span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
    <span class="n">CUVS_AVAILABLE</span> <span class="o">=</span> <span class="kc">False</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_compute_forces_kernel</span><span class="p">(</span><span class="n">positions</span><span class="p">,</span> <span class="n">knn_indices</span><span class="p">,</span> <span class="n">neg_indices</span><span class="p">,</span> <span class="n">a_val</span><span class="p">,</span> <span class="n">b_exp</span><span class="p">,</span> <span class="n">cutoff</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Compute attraction + repulsion forces for all points in one shot.</span>

<span class="sd">    This is the hot loop kernel — torch.compile fuses it into a small number</span>
<span class="sd">    of CUDA kernels, eliminating the per-chunk launch overhead that dominates</span>
<span class="sd">    when the dataset fits comfortably in GPU memory (true for any modern GPU</span>
<span class="sd">    up to ~1M+ points).</span>

<span class="sd">    All arithmetic runs in bf16 for ~2x memory bandwidth savings on the</span>
<span class="sd">    gather/scatter-dominated workload.  The caller accumulates positions</span>
<span class="sd">    in fp32, so numerical drift stays bounded.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    positions : (N, D)  — bf16 on CUDA, fp32 on CPU</span>
<span class="sd">    knn_indices : (N, k) long</span>
<span class="sd">    neg_indices : (N, n_neg) long</span>
<span class="sd">    a_val, b_exp, cutoff : float</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    (N, D) forces in same dtype as positions</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Attraction: toward k-NN neighbors</span>
    <span class="n">neighbor_pos</span> <span class="o">=</span> <span class="n">positions</span><span class="p">[</span><span class="n">knn_indices</span><span class="p">]</span>                    <span class="c1"># (N, k, D)</span>
    <span class="n">diff</span> <span class="o">=</span> <span class="n">neighbor_pos</span> <span class="o">-</span> <span class="n">positions</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>             <span class="c1"># (N, k, D)</span>
    <span class="n">dist</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">diff</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="o">+</span> <span class="mf">1e-10</span>    <span class="c1"># (N, k, 1)</span>
    <span class="n">att_coeff</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">+</span> <span class="n">a_val</span> <span class="o">*</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">/</span> <span class="n">dist</span><span class="p">)</span> <span class="o">**</span> <span class="n">b_exp</span><span class="p">)</span>
    <span class="n">forces</span> <span class="o">=</span> <span class="p">(</span><span class="n">att_coeff</span> <span class="o">*</span> <span class="n">diff</span> <span class="o">/</span> <span class="n">dist</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>            <span class="c1"># (N, D)</span>

    <span class="c1"># Repulsion: against random negative samples</span>
    <span class="n">neg_pos</span> <span class="o">=</span> <span class="n">positions</span><span class="p">[</span><span class="n">neg_indices</span><span class="p">]</span>                          <span class="c1"># (N, n_neg, D)</span>
    <span class="n">diff_n</span> <span class="o">=</span> <span class="n">neg_pos</span> <span class="o">-</span> <span class="n">positions</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>                 <span class="c1"># (N, n_neg, D)</span>
    <span class="n">dist_n</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">diff_n</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="o">+</span> <span class="mf">1e-10</span>
    <span class="n">rep_coeff</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.0</span> <span class="o">/</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">+</span> <span class="n">a_val</span> <span class="o">*</span> <span class="p">(</span><span class="n">dist_n</span> <span class="o">**</span> <span class="n">b_exp</span><span class="p">))</span>
    <span class="n">rep_coeff</span> <span class="o">=</span> <span class="n">rep_coeff</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">dist_n</span> <span class="o">/</span> <span class="n">cutoff</span><span class="p">)</span>
    <span class="n">forces</span> <span class="o">=</span> <span class="n">forces</span> <span class="o">+</span> <span class="p">(</span><span class="n">rep_coeff</span> <span class="o">*</span> <span class="n">diff_n</span> <span class="o">/</span> <span class="n">dist_n</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">forces</span>


<span class="c1"># torch.compile fuses the above into efficient CUDA kernels, eliminating</span>
<span class="c1"># intermediate tensor allocations.  We lazily compile on first CUDA call</span>
<span class="c1"># and fall back to eager mode if compilation fails.</span>
<span class="n">_forces_compiled_cuda</span> <span class="o">=</span> <span class="kc">None</span>
<span class="n">_torch_compile_failed</span> <span class="o">=</span> <span class="kc">False</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_compute_forces_compiled</span><span class="p">(</span><span class="n">positions</span><span class="p">,</span> <span class="n">knn_indices</span><span class="p">,</span> <span class="n">neg_indices</span><span class="p">,</span> <span class="n">a_val</span><span class="p">,</span> <span class="n">b_exp</span><span class="p">,</span> <span class="n">cutoff</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Dispatch to compiled or eager kernel.&quot;&quot;&quot;</span>
    <span class="k">global</span> <span class="n">_forces_compiled_cuda</span><span class="p">,</span> <span class="n">_torch_compile_failed</span>
    <span class="k">if</span> <span class="n">positions</span><span class="o">.</span><span class="n">is_cuda</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">_torch_compile_failed</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">_forces_compiled_cuda</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">_forces_compiled_cuda</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span>
                    <span class="n">_compute_forces_kernel</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;reduce-overhead&quot;</span>
                <span class="p">)</span>
            <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
                <span class="n">_torch_compile_failed</span> <span class="o">=</span> <span class="kc">True</span>
                <span class="k">return</span> <span class="n">_compute_forces_kernel</span><span class="p">(</span><span class="n">positions</span><span class="p">,</span> <span class="n">knn_indices</span><span class="p">,</span> <span class="n">neg_indices</span><span class="p">,</span> <span class="n">a_val</span><span class="p">,</span> <span class="n">b_exp</span><span class="p">,</span> <span class="n">cutoff</span><span class="p">)</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">_forces_compiled_cuda</span><span class="p">(</span><span class="n">positions</span><span class="p">,</span> <span class="n">knn_indices</span><span class="p">,</span> <span class="n">neg_indices</span><span class="p">,</span> <span class="n">a_val</span><span class="p">,</span> <span class="n">b_exp</span><span class="p">,</span> <span class="n">cutoff</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
            <span class="n">_torch_compile_failed</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="k">return</span> <span class="n">_compute_forces_kernel</span><span class="p">(</span><span class="n">positions</span><span class="p">,</span> <span class="n">knn_indices</span><span class="p">,</span> <span class="n">neg_indices</span><span class="p">,</span> <span class="n">a_val</span><span class="p">,</span> <span class="n">b_exp</span><span class="p">,</span> <span class="n">cutoff</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_compile_metric</span><span class="p">(</span><span class="n">spec</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Turn a metric spec into a callable metric(x, y) that returns a distance-like</span>
<span class="sd">    matrix with broadcasting:</span>
<span class="sd">      - Torch path:  x: (A, 1, D), y: (1, B, D)  -&gt; (A, B) torch.Tensor</span>
<span class="sd">      - KeOps path:  x: LazyTensor(A,1,D), y: LazyTensor(1,B,D) -&gt; LazyTensor(A,B)</span>

<span class="sd">    If spec is None or &#39;euclidean&#39;/&#39;l2&#39;, return None (fast-path Euclidean stays in backend).</span>
<span class="sd">    Named metrics like &#39;euclidean&#39;, &#39;l2&#39;, &#39;inner_product&#39; return None (handled by backend).</span>
<span class="sd">    If spec is str expression, it&#39;s eval&#39;ed with {&#39;x&#39;: x, &#39;y&#39;: y} and no builtins.</span>
<span class="sd">    If spec is callable, it&#39;s returned unchanged.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    callable or None</span>
<span class="sd">        None for backend-native metrics, callable for custom metrics</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">spec</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">spec</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
        <span class="n">expr</span> <span class="o">=</span> <span class="n">spec</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
        <span class="c1"># These named metrics can be handled by backends (cuVS, PyTorch)</span>
        <span class="k">if</span> <span class="n">expr</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;euclidean&quot;</span><span class="p">,</span> <span class="s2">&quot;l2&quot;</span><span class="p">,</span> <span class="s2">&quot;sqeuclidean&quot;</span><span class="p">,</span> <span class="s2">&quot;inner_product&quot;</span><span class="p">,</span> <span class="s2">&quot;cosine&quot;</span><span class="p">):</span>
            <span class="k">return</span> <span class="kc">None</span>  <span class="c1"># use built-in backend metric</span>
        <span class="c1"># Custom expression - compile to callable</span>
        <span class="k">def</span><span class="w"> </span><span class="nf">_expr_metric</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">_expr</span><span class="o">=</span><span class="n">spec</span><span class="p">):</span>
            <span class="c1"># Use ONLY tensor methods like .sum(-1), .sqrt(), .abs(), etc.</span>
            <span class="c1"># Works for both torch.Tensor and KeOps LazyTensor.</span>
            <span class="k">return</span> <span class="nb">eval</span><span class="p">(</span><span class="n">_expr</span><span class="p">,</span> <span class="p">{</span><span class="s2">&quot;__builtins__&quot;</span><span class="p">:</span> <span class="p">{}},</span> <span class="p">{</span><span class="s2">&quot;x&quot;</span><span class="p">:</span> <span class="n">x</span><span class="p">,</span> <span class="s2">&quot;y&quot;</span><span class="p">:</span> <span class="n">y</span><span class="p">})</span>  <span class="c1"># pylint: disable=eval-used # Sandboxed eval for custom metrics</span>
        <span class="k">return</span> <span class="n">_expr_metric</span>
    <span class="k">if</span> <span class="nb">callable</span><span class="p">(</span><span class="n">spec</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">spec</span>
    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;metric must be None, a string expression, or a callable&quot;</span><span class="p">)</span>


<div class="viewcode-block" id="DiRePyTorch">
<a class="viewcode-back" href="../../api/modules.html#dire_rapids.dire_pytorch.DiRePyTorch">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">DiRePyTorch</span><span class="p">(</span><span class="n">TransformerMixin</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Memory-efficient PyTorch/PyKeOps implementation of DiRe dimensionality reduction.</span>
<span class="sd">    </span>
<span class="sd">    This class provides a high-performance implementation of the DiRe algorithm using PyTorch</span>
<span class="sd">    as the computational backend. It features adaptive memory management for large datasets</span>
<span class="sd">    and automatic GPU optimization.</span>
<span class="sd">    </span>
<span class="sd">    Features</span>
<span class="sd">    --------</span>
<span class="sd">    - Chunked k-NN computation prevents GPU out-of-memory errors</span>
<span class="sd">    - Memory-aware force computation with automatic chunk sizing</span>
<span class="sd">    - Attraction forces between k-NN neighbors only</span>
<span class="sd">    - Repulsion forces from random sampling for efficiency</span>
<span class="sd">    - Automatic FP16 optimization for memory and speed</span>
<span class="sd">    - Optional PyKeOps integration for low-dimensional data</span>
<span class="sd">    </span>
<span class="sd">    Best suited for</span>
<span class="sd">    ---------------</span>
<span class="sd">    - Large datasets (&gt;50K points) on CUDA GPUs</span>
<span class="sd">    - Production environments requiring reliable memory usage</span>
<span class="sd">    - High-performance dimensionality reduction workflows</span>
<span class="sd">    </span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    n_components : int, default=2</span>
<span class="sd">        Number of dimensions in the target embedding space.</span>
<span class="sd">    n_neighbors : int, default=16</span>
<span class="sd">        Number of nearest neighbors to use for attraction forces.</span>
<span class="sd">    init : {&#39;pca&#39;, &#39;random&#39;}, default=&#39;pca&#39;</span>
<span class="sd">        Method for initializing the embedding. &#39;pca&#39; uses PCA initialization,</span>
<span class="sd">        &#39;random&#39; uses random projection.</span>
<span class="sd">    max_iter_layout : int, default=128</span>
<span class="sd">        Maximum number of optimization iterations.</span>
<span class="sd">    min_dist : float, default=1e-2</span>
<span class="sd">        Minimum distance between points in the embedding.</span>
<span class="sd">    spread : float, default=1.0</span>
<span class="sd">        Controls how tightly points are packed in the embedding.</span>
<span class="sd">    cutoff : float, default=42.0</span>
<span class="sd">        Distance cutoff for repulsion forces.</span>
<span class="sd">    n_sample_dirs : int, default=8</span>
<span class="sd">        Number of sampling directions (used by derived classes).</span>
<span class="sd">    sample_size : int, default=16</span>
<span class="sd">        Size of samples for force computation (used by derived classes).</span>
<span class="sd">    neg_ratio : int, default=8</span>
<span class="sd">        Ratio of negative samples to positive samples for repulsion.</span>
<span class="sd">    verbose : bool, default=True</span>
<span class="sd">        Whether to print progress information.</span>
<span class="sd">    random_state : int or None, default=None</span>
<span class="sd">        Random seed for reproducible results.</span>
<span class="sd">    use_exact_repulsion : bool, default=False</span>
<span class="sd">        If True, use exact all-pairs repulsion (memory intensive, for testing only).</span>
<span class="sd">    metric : str, callable, or None, default=None</span>
<span class="sd">        Custom distance metric for k-NN computation only (layout forces remain Euclidean):</span>

<span class="sd">        - None or &#39;euclidean&#39;/&#39;l2&#39;: Use fast built-in Euclidean distance</span>
<span class="sd">        - str: String expression evaluated with x and y tensors (e.g., &#39;(x - y).abs().sum(-1)&#39; for L1)</span>
<span class="sd">        - callable: Custom function taking (x, y) tensors and returning distance matrix</span>

<span class="sd">        Examples: &#39;(x - y).abs().sum(-1)&#39; (L1), &#39;1 - (x*y).sum(-1)/(x.norm()*y.norm() + 1e-8)&#39; (cosine).</span>
<span class="sd">        </span>
<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    device : torch.device</span>
<span class="sd">        The PyTorch device being used (CPU or CUDA).</span>
<span class="sd">    logger : loguru.Logger</span>
<span class="sd">        Instance-specific logger for this reducer.</span>
<span class="sd">        </span>
<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    Basic usage::</span>
<span class="sd">    </span>
<span class="sd">        from dire_rapids import DiRePyTorch</span>
<span class="sd">        import numpy as np</span>
<span class="sd">        </span>
<span class="sd">        # Create sample data</span>
<span class="sd">        X = np.random.randn(10000, 100)</span>
<span class="sd">        </span>
<span class="sd">        # Create and fit reducer</span>
<span class="sd">        reducer = DiRePyTorch(n_neighbors=32, verbose=True)</span>
<span class="sd">        embedding = reducer.fit_transform(X)</span>
<span class="sd">        </span>
<span class="sd">        # Visualize results</span>
<span class="sd">        fig = reducer.visualize()</span>
<span class="sd">        fig.show()</span>
<span class="sd">    </span>
<span class="sd">    With custom parameters::</span>

<span class="sd">        reducer = DiRePyTorch(</span>
<span class="sd">            n_components=3,</span>
<span class="sd">            n_neighbors=50,</span>
<span class="sd">            max_iter_layout=200,</span>
<span class="sd">            min_dist=0.1,</span>
<span class="sd">            random_state=42</span>
<span class="sd">        )</span>
<span class="sd">        embedding = reducer.fit_transform(X)</span>

<span class="sd">    With custom distance metric::</span>

<span class="sd">        # Using L1 (Manhattan) distance for k-NN</span>
<span class="sd">        reducer = DiRePyTorch(</span>
<span class="sd">            metric=&#39;(x - y).abs().sum(-1)&#39;,</span>
<span class="sd">            n_neighbors=32</span>
<span class="sd">        )</span>
<span class="sd">        embedding = reducer.fit_transform(X)</span>

<span class="sd">        # Using custom callable metric</span>
<span class="sd">        def cosine_distance(x, y):</span>
<span class="sd">            return 1 - (x * y).sum(-1) / (x.norm(dim=-1, keepdim=True) * y.norm(dim=-1, keepdim=True) + 1e-8)</span>

<span class="sd">        reducer = DiRePyTorch(metric=cosine_distance)</span>
<span class="sd">        embedding = reducer.fit_transform(X)</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="DiRePyTorch.__init__">
<a class="viewcode-back" href="../../api/modules.html#dire_rapids.dire_pytorch.DiRePyTorch.__init__">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span>
            <span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
            <span class="n">n_neighbors</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
            <span class="n">init</span><span class="o">=</span><span class="s2">&quot;pca&quot;</span><span class="p">,</span>
            <span class="n">max_iter_layout</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
            <span class="n">min_dist</span><span class="o">=</span><span class="mf">1e-2</span><span class="p">,</span>
            <span class="n">spread</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
            <span class="n">cutoff</span><span class="o">=</span><span class="mf">42.0</span><span class="p">,</span>
            <span class="n">n_sample_dirs</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
            <span class="n">sample_size</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
            <span class="n">neg_ratio</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
            <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
            <span class="n">use_exact_repulsion</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>  <span class="c1"># If True, use all-pairs repulsion (for testing)</span>
            <span class="n">metric</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initialize DiRePyTorch reducer with specified parameters.</span>
<span class="sd">        </span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        n_components : int, default=2</span>
<span class="sd">            Number of dimensions in the target embedding space.</span>
<span class="sd">        n_neighbors : int, default=16</span>
<span class="sd">            Number of nearest neighbors to use for attraction forces.</span>
<span class="sd">        init : {&#39;pca&#39;, &#39;random&#39;}, default=&#39;pca&#39;</span>
<span class="sd">            Method for initializing the embedding.</span>
<span class="sd">        max_iter_layout : int, default=128</span>
<span class="sd">            Maximum number of optimization iterations.</span>
<span class="sd">        min_dist : float, default=1e-2</span>
<span class="sd">            Minimum distance between points in the embedding.</span>
<span class="sd">        spread : float, default=1.0</span>
<span class="sd">            Controls how tightly points are packed in the embedding.</span>
<span class="sd">        cutoff : float, default=42.0</span>
<span class="sd">            Distance cutoff for repulsion forces.</span>
<span class="sd">        n_sample_dirs : int, default=8</span>
<span class="sd">            Number of sampling directions (reserved for future use).</span>
<span class="sd">        sample_size : int, default=16</span>
<span class="sd">            Size of samples for force computation (reserved for future use).</span>
<span class="sd">        neg_ratio : int, default=8</span>
<span class="sd">            Ratio of negative samples to positive samples for repulsion.</span>
<span class="sd">        verbose : bool, default=True</span>
<span class="sd">            Whether to print progress information.</span>
<span class="sd">        random_state : int or None, default=None</span>
<span class="sd">            Random seed for reproducible results.</span>
<span class="sd">        use_exact_repulsion : bool, default=False</span>
<span class="sd">            If True, use exact all-pairs repulsion (memory intensive, testing only).</span>
<span class="sd">        metric : str, callable, or None, default=None</span>
<span class="sd">            Custom distance metric for k-NN computation. See class docstring for details.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">n_components</span> <span class="o">=</span> <span class="n">n_components</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_neighbors</span> <span class="o">=</span> <span class="n">n_neighbors</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">init</span> <span class="o">=</span> <span class="n">init</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_iter_layout</span> <span class="o">=</span> <span class="n">max_iter_layout</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">min_dist</span> <span class="o">=</span> <span class="n">min_dist</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">spread</span> <span class="o">=</span> <span class="n">spread</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cutoff</span> <span class="o">=</span> <span class="n">cutoff</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_sample_dirs</span> <span class="o">=</span> <span class="n">n_sample_dirs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sample_size</span> <span class="o">=</span> <span class="n">sample_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">neg_ratio</span> <span class="o">=</span> <span class="n">neg_ratio</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="n">verbose</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random_state</span> <span class="o">=</span> <span class="n">random_state</span> <span class="k">if</span> <span class="n">random_state</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span> <span class="o">**</span> <span class="mi">32</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">use_exact_repulsion</span> <span class="o">=</span> <span class="n">use_exact_repulsion</span>

        <span class="c1"># Store RNG state -- defer torch/cuda seeding to fit_transform</span>
        <span class="c1"># to avoid mutating global state from a library constructor.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">random_state</span><span class="p">)</span>

        <span class="c1"># Custom metric for k-NN only (layout forces remain Euclidean):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">metric_spec</span> <span class="o">=</span> <span class="n">metric</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_metric_fn</span> <span class="o">=</span> <span class="n">_compile_metric</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">metric_spec</span><span class="p">)</span>

        <span class="c1"># Setup instance-specific logger</span>
        <span class="c1"># Use logger.bind() for context but track handler IDs to avoid</span>
        <span class="c1"># corrupting the global loguru logger for other users.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">logger</span> <span class="o">=</span> <span class="n">logger</span><span class="o">.</span><span class="n">bind</span><span class="p">(</span><span class="n">dire_instance</span><span class="o">=</span><span class="nb">id</span><span class="p">(</span><span class="bp">self</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_logger_handler_ids</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
            <span class="c1"># Add handler that outputs to stderr with formatting</span>
            <span class="n">handler_id</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">add</span><span class="p">(</span>
                <span class="n">sys</span><span class="o">.</span><span class="n">stderr</span><span class="p">,</span>
                <span class="n">level</span><span class="o">=</span><span class="s2">&quot;INFO&quot;</span><span class="p">,</span>
                <span class="nb">filter</span><span class="o">=</span><span class="k">lambda</span> <span class="n">record</span><span class="p">:</span> <span class="n">record</span><span class="p">[</span><span class="s2">&quot;extra&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;dire_instance&quot;</span><span class="p">)</span> <span class="o">==</span> <span class="nb">id</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_logger_handler_ids</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">handler_id</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Add null handler that discards all messages</span>
            <span class="n">handler_id</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">add</span><span class="p">(</span>
                <span class="k">lambda</span> <span class="n">msg</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>
                <span class="n">level</span><span class="o">=</span><span class="s2">&quot;TRACE&quot;</span><span class="p">,</span>
                <span class="nb">filter</span><span class="o">=</span><span class="k">lambda</span> <span class="n">record</span><span class="p">:</span> <span class="n">record</span><span class="p">[</span><span class="s2">&quot;extra&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;dire_instance&quot;</span><span class="p">)</span> <span class="o">==</span> <span class="nb">id</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_logger_handler_ids</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">handler_id</span><span class="p">)</span>

        <span class="c1"># Internal state</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_data</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_layout</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_n_samples</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_a</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_b</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_knn_indices</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_knn_distances</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="c1"># Device management</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cuda&#39;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s1">&#39;cpu&#39;</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="s1">&#39;cuda&#39;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Using CUDA device: </span><span class="si">{</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">get_device_name</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;CUDA not available, using CPU&quot;</span><span class="p">)</span></div>


    <span class="k">def</span><span class="w"> </span><span class="nf">_find_ab_params</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Find optimal a and b parameters for the distribution kernel.</span>
<span class="sd">        </span>
<span class="sd">        This private method fits a curve to determine the optimal parameters for the</span>
<span class="sd">        probability kernel used in force calculations. The parameters control the</span>
<span class="sd">        shape of the attraction/repulsion curve.</span>
<span class="sd">        </span>
<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        Private method, should not be called directly. Used by fit_transform().</span>
<span class="sd">        The kernel function is: 1 / (1 + a * x^(2*b))</span>
<span class="sd">        </span>
<span class="sd">        Side Effects</span>
<span class="sd">        ------------</span>
<span class="sd">        Sets self._a and self._b attributes with the fitted parameters.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">def</span><span class="w"> </span><span class="nf">curve</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
            <span class="k">return</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">+</span> <span class="n">a</span> <span class="o">*</span> <span class="n">x</span> <span class="o">**</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">b</span><span class="p">))</span>

        <span class="n">xv</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">spread</span><span class="p">,</span> <span class="mi">300</span><span class="p">)</span>
        <span class="n">yv</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">xv</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
        <span class="n">yv</span><span class="p">[</span><span class="n">xv</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_dist</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.0</span>
        <span class="n">yv</span><span class="p">[</span><span class="n">xv</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_dist</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="p">(</span><span class="n">xv</span><span class="p">[</span><span class="n">xv</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_dist</span><span class="p">]</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_dist</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">spread</span><span class="p">)</span>

        <span class="n">params</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">curve_fit</span><span class="p">(</span><span class="n">curve</span><span class="p">,</span> <span class="n">xv</span><span class="p">,</span> <span class="n">yv</span><span class="p">)[:</span><span class="mi">2</span><span class="p">]</span>  <span class="c1"># Extract only params and covariance</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_a</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_b</span> <span class="o">=</span> <span class="n">params</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Found kernel params: a=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_a</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, b=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_b</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_compute_knn</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">chunk_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">use_fp16</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>  <span class="c1"># pylint: disable=too-many-branches</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute k-nearest neighbors with memory-efficient chunking.</span>
<span class="sd">        </span>
<span class="sd">        This private method computes the k-nearest neighbors graph using either PyTorch</span>
<span class="sd">        or PyKeOps backends. It intelligently selects the optimal backend based on</span>
<span class="sd">        data dimensionality and automatically manages memory through chunking.</span>
<span class="sd">        </span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : numpy.ndarray</span>
<span class="sd">            Input data of shape (n_samples, n_features).</span>
<span class="sd">        chunk_size : int, optional</span>
<span class="sd">            Size of chunks for processing. If None, automatically determined based</span>
<span class="sd">            on available memory.</span>
<span class="sd">        use_fp16 : bool, optional</span>
<span class="sd">            Use FP16 precision for computation. If None, automatically determined</span>
<span class="sd">            based on data size and GPU capabilities. FP16 provides 2x memory savings</span>
<span class="sd">            and 2-14x speedup on modern GPUs.</span>
<span class="sd">            </span>
<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        Private method, should not be called directly. Used by fit_transform().</span>
<span class="sd">        </span>
<span class="sd">        Backend Selection:</span>
<span class="sd">        - PyTorch: Used for high-dimensional data (&gt;= 200D) or when PyKeOps unavailable</span>
<span class="sd">        - PyKeOps: Used for low-dimensional data (&lt; 200D) on GPU for better performance</span>
<span class="sd">        </span>
<span class="sd">        Side Effects</span>
<span class="sd">        ------------</span>
<span class="sd">        Sets self._knn_indices and self._knn_distances with computed k-NN graph.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">n_samples</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">n_dims</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Computing </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">n_neighbors</span><span class="si">}</span><span class="s2">-NN graph for </span><span class="si">{</span><span class="n">n_samples</span><span class="si">}</span><span class="s2"> points in </span><span class="si">{</span><span class="n">n_dims</span><span class="si">}</span><span class="s2">D...&quot;</span><span class="p">)</span>

        <span class="c1"># ── cuVS fast path: use GPU-accelerated kNN for large datasets ──</span>
        <span class="c1"># cuVS IVF-Flat is much faster than brute-force when N is large</span>
        <span class="c1"># relative to D.  For high-D data (D&gt;200) the index build cost is</span>
        <span class="c1"># higher, so we raise the threshold.  Empirically:</span>
        <span class="c1">#   D&lt;200:  cuVS wins at N &gt;= 100K  (covertype 54D: 7s→2.5s at 200K)</span>
        <span class="c1">#   D&gt;=200: cuVS wins at N &gt;= 200K  (mnist 784D: slower at 50K)</span>
        <span class="n">cuvs_threshold</span> <span class="o">=</span> <span class="mi">200000</span> <span class="k">if</span> <span class="n">n_dims</span> <span class="o">&gt;=</span> <span class="mi">200</span> <span class="k">else</span> <span class="mi">100000</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">CUVS_AVAILABLE</span>
                <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="s1">&#39;cuda&#39;</span>
                <span class="ow">and</span> <span class="n">n_samples</span> <span class="o">&gt;=</span> <span class="n">cuvs_threshold</span>
                <span class="ow">and</span> <span class="n">n_dims</span> <span class="o">&lt;=</span> <span class="mi">2048</span>
                <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_metric_fn</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">):</span>  <span class="c1"># cuVS only supports built-in metrics</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_knn_cuvs</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
            <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;cuVS kNN failed (</span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">), falling back to PyTorch&quot;</span><span class="p">)</span>

        <span class="c1"># Auto-detect FP16 usage based on data size and GPU</span>
        <span class="k">if</span> <span class="n">use_fp16</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="s1">&#39;cuda&#39;</span><span class="p">:</span>
            <span class="c1"># Use FP16 for high-dimensional data or large datasets</span>
            <span class="n">use_fp16</span> <span class="o">=</span> <span class="n">n_dims</span> <span class="o">&gt;=</span> <span class="mi">500</span> <span class="ow">or</span> <span class="n">n_samples</span> <span class="o">&gt;=</span> <span class="mi">100000</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="s1">&#39;cpu&#39;</span><span class="p">:</span>
            <span class="n">use_fp16</span> <span class="o">=</span> <span class="kc">False</span>  <span class="c1"># CPU doesn&#39;t benefit from FP16</span>
        
        <span class="c1"># Choose precision</span>
        <span class="k">if</span> <span class="n">use_fp16</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="s1">&#39;cuda&#39;</span><span class="p">:</span>
            <span class="n">dtype</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">float16</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Using FP16 for k-NN (2x memory, faster on H100/A100)&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">dtype</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">float32</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Using FP32 for k-NN&quot;</span><span class="p">)</span>
        
        <span class="n">X_torch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

        <span class="c1"># CRITICAL: PyKeOps is slower than PyTorch for high dimensions!</span>
        <span class="c1"># Use PyTorch for high-D, PyKeOps for low-D</span>
        <span class="n">use_pykeops</span> <span class="o">=</span> <span class="n">PYKEOPS_AVAILABLE</span> <span class="ow">and</span> <span class="n">n_dims</span> <span class="o">&lt;</span> <span class="mi">200</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="s1">&#39;cuda&#39;</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">use_fp16</span>

        <span class="k">if</span> <span class="n">n_dims</span> <span class="o">&gt;=</span> <span class="mi">200</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Using PyTorch for k-NN (high dimension: </span><span class="si">{</span><span class="n">n_dims</span><span class="si">}</span><span class="s2">D)&quot;</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">use_pykeops</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Using PyKeOps for k-NN (low dimension, GPU available)&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Using PyTorch for k-NN&quot;</span><span class="p">)</span>

        <span class="c1"># Set default chunk size if not provided</span>
        <span class="k">if</span> <span class="n">chunk_size</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">chunk_size</span> <span class="o">=</span> <span class="mi">50000</span>

        <span class="c1"># Adaptive chunk sizing based on available GPU memory</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="s1">&#39;cuda&#39;</span><span class="p">:</span>
            <span class="c1"># Check available memory AFTER allocating X_torch</span>
            <span class="n">gpu_mem_free</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">mem_get_info</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
            <span class="c1"># Estimate memory for k-NN: chunk_size * n_samples * bytes_per_element</span>
            <span class="n">bytes_per_element</span> <span class="o">=</span> <span class="mi">2</span> <span class="k">if</span> <span class="n">use_fp16</span> <span class="k">else</span> <span class="mi">4</span>  <span class="c1"># FP16 uses 2 bytes, FP32 uses 4</span>
            <span class="n">memory_per_chunk</span> <span class="o">=</span> <span class="n">chunk_size</span> <span class="o">*</span> <span class="n">n_samples</span> <span class="o">*</span> <span class="n">bytes_per_element</span>

            <span class="c1"># Only auto-adjust if using default chunk size</span>
            <span class="k">if</span> <span class="n">chunk_size</span> <span class="o">==</span> <span class="mi">50000</span><span class="p">:</span>
                <span class="c1"># Use conservative memory fraction: 20-25% of available memory</span>
                <span class="c1"># This accounts for PyTorch overhead, temp buffers, and fragmentation</span>
                <span class="n">memory_fraction</span> <span class="o">=</span> <span class="mf">0.25</span> <span class="k">if</span> <span class="n">use_fp16</span> <span class="k">else</span> <span class="mf">0.20</span>
                <span class="n">max_memory</span> <span class="o">=</span> <span class="n">gpu_mem_free</span> <span class="o">*</span> <span class="n">memory_fraction</span>
                <span class="k">if</span> <span class="n">memory_per_chunk</span> <span class="o">&gt;</span> <span class="n">max_memory</span><span class="p">:</span>
                    <span class="n">chunk_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">max_memory</span> <span class="o">/</span> <span class="p">(</span><span class="n">n_samples</span> <span class="o">*</span> <span class="n">bytes_per_element</span><span class="p">))</span>
                    <span class="n">chunk_size</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="n">chunk_size</span><span class="p">)</span>  <span class="c1"># Minimum chunk size</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Using chunk size: </span><span class="si">{</span><span class="n">chunk_size</span><span class="si">}</span><span class="s2"> (GPU memory: </span><span class="si">{</span><span class="n">gpu_mem_free</span><span class="o">/</span><span class="mi">1024</span><span class="o">**</span><span class="mi">3</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2">GB, dtype: </span><span class="si">{</span><span class="n">dtype</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>
        
        <span class="c1"># Initialize arrays for results</span>
        <span class="n">all_knn_indices</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">all_knn_distances</span> <span class="o">=</span> <span class="p">[]</span>
        
        <span class="c1"># Process in chunks to avoid memory issues</span>
        <span class="k">for</span> <span class="n">start_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">,</span> <span class="n">chunk_size</span><span class="p">):</span>
            <span class="n">end_idx</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">start_idx</span> <span class="o">+</span> <span class="n">chunk_size</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">n_samples</span> <span class="o">&gt;</span> <span class="mi">50000</span><span class="p">:</span>  <span class="c1"># Only log for large datasets</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Processing chunk </span><span class="si">{</span><span class="n">start_idx</span><span class="o">//</span><span class="n">chunk_size</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="p">(</span><span class="n">n_samples</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">chunk_size</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="o">//</span><span class="n">chunk_size</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

            <span class="c1"># Get chunk data</span>
            <span class="n">X_chunk</span> <span class="o">=</span> <span class="n">X_torch</span><span class="p">[</span><span class="n">start_idx</span><span class="p">:</span><span class="n">end_idx</span><span class="p">]</span>  <span class="c1"># (chunk_size, D)</span>
            <span class="n">distances</span> <span class="o">=</span> <span class="kc">None</span>

            <span class="k">if</span> <span class="n">use_pykeops</span><span class="p">:</span>
                <span class="c1"># Use PyKeOps for LOW dimensional data</span>
                <span class="c1"># Ensure contiguity for PyKeOps</span>
                <span class="n">X_i</span> <span class="o">=</span> <span class="n">LazyTensor</span><span class="p">(</span><span class="n">X_chunk</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">contiguous</span><span class="p">())</span>  <span class="c1"># (chunk_size, 1, D)</span>
                <span class="n">X_j</span> <span class="o">=</span> <span class="n">LazyTensor</span><span class="p">(</span><span class="n">X_torch</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]</span><span class="o">.</span><span class="n">contiguous</span><span class="p">())</span>   <span class="c1"># (1, N, D)</span>

                <span class="c1"># Compute distances using custom metric or default Euclidean</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_metric_fn</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="c1"># Custom metric - works with LazyTensor</span>
                    <span class="n">D_ij</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_metric_fn</span><span class="p">(</span><span class="n">X_i</span><span class="p">,</span> <span class="n">X_j</span><span class="p">)</span>  <span class="c1"># (chunk_size, N) LazyTensor</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="c1"># Fast built-in Euclidean (squared distances)</span>
                    <span class="n">D_ij</span> <span class="o">=</span> <span class="p">((</span><span class="n">X_i</span> <span class="o">-</span> <span class="n">X_j</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># (chunk_size, N) LazyTensor</span>

                <span class="c1"># Find k+1 nearest neighbors (including self)</span>
                <span class="n">knn_dists</span><span class="p">,</span> <span class="n">knn_indices</span> <span class="o">=</span> <span class="n">D_ij</span><span class="o">.</span><span class="n">Kmin_argKmin</span><span class="p">(</span><span class="n">K</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_neighbors</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

                <span class="c1"># Remove self</span>
                <span class="n">chunk_indices</span> <span class="o">=</span> <span class="n">knn_indices</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:]</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
                <span class="c1"># For custom metrics, distances are already in metric space</span>
                <span class="c1"># For Euclidean, convert from squared to actual distances</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_metric_fn</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">chunk_distances</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">knn_dists</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:])</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">chunk_distances</span> <span class="o">=</span> <span class="n">knn_dists</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:]</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># Use PyTorch for HIGH dimensional data (MUCH faster!)</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_metric_fn</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="c1"># Custom metric - compute pairwise distances manually</span>
                    <span class="c1"># Broadcast: X_chunk: (chunk, 1, D), X_torch: (1, N, D) -&gt; (chunk, N)</span>
                    <span class="n">X_i</span> <span class="o">=</span> <span class="n">X_chunk</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># (chunk, 1, D)</span>
                    <span class="n">X_j</span> <span class="o">=</span> <span class="n">X_torch</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># (1, N, D)</span>
                    <span class="n">distances</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_metric_fn</span><span class="p">(</span><span class="n">X_i</span><span class="p">,</span> <span class="n">X_j</span><span class="p">)</span>  <span class="c1"># (chunk, N)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="c1"># Fast built-in Euclidean distance</span>
                    <span class="n">distances</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cdist</span><span class="p">(</span><span class="n">X_chunk</span><span class="p">,</span> <span class="n">X_torch</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

                <span class="n">knn_dists</span><span class="p">,</span> <span class="n">knn_indices</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">topk</span><span class="p">(</span><span class="n">distances</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_neighbors</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span>
                                                   <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">largest</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

                <span class="c1"># Remove self</span>
                <span class="n">chunk_indices</span> <span class="o">=</span> <span class="n">knn_indices</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:]</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
                <span class="n">chunk_distances</span> <span class="o">=</span> <span class="n">knn_dists</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:]</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

            <span class="n">all_knn_indices</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">chunk_indices</span><span class="p">)</span>
            <span class="n">all_knn_distances</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">chunk_distances</span><span class="p">)</span>

            <span class="c1"># Clear GPU memory after each chunk to avoid fragmentation</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="s1">&#39;cuda&#39;</span><span class="p">:</span>
                <span class="k">del</span> <span class="n">knn_dists</span><span class="p">,</span> <span class="n">knn_indices</span>
                <span class="k">if</span> <span class="n">distances</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="k">del</span> <span class="n">distances</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>
        
        <span class="c1"># Concatenate results</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_knn_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">(</span><span class="n">all_knn_indices</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_knn_distances</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">(</span><span class="n">all_knn_distances</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;k-NN graph computed: shape </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_knn_indices</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_compute_knn_cuvs</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Use cuVS IVF-Flat for fast GPU-accelerated kNN.</span>

<span class="sd">        IVF-Flat partitions the dataset into Voronoi cells (n_lists clusters)</span>
<span class="sd">        and searches only the closest nprobe cells.  With nprobe high enough</span>
<span class="sd">        relative to n_lists the results are effectively exact.</span>

<span class="sd">        Sets self._knn_indices, self._knn_distances (same contract as _compute_knn).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">n_samples</span><span class="p">,</span> <span class="n">n_dims</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">k</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_neighbors</span> <span class="o">+</span> <span class="mi">1</span>  <span class="c1"># +1 because cuVS returns self as first neighbor</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Using cuVS IVF-Flat for </span><span class="si">{</span><span class="n">n_samples</span><span class="si">}</span><span class="s2"> points in </span><span class="si">{</span><span class="n">n_dims</span><span class="si">}</span><span class="s2">D&quot;</span><span class="p">)</span>

        <span class="n">X_gpu</span> <span class="o">=</span> <span class="n">cp</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">cp</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="s1">&#39;C&#39;</span><span class="p">)</span>

        <span class="c1"># Scale n_lists with dataset size; search enough cells for high recall</span>
        <span class="n">n_lists</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">n_samples</span><span class="p">)),</span> <span class="mi">1024</span><span class="p">)</span>
        <span class="n">nprobe</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">n_lists</span><span class="p">,</span> <span class="mi">64</span><span class="p">)</span>

        <span class="n">build_params</span> <span class="o">=</span> <span class="n">cuvs_ivf_flat</span><span class="o">.</span><span class="n">IndexParams</span><span class="p">(</span><span class="n">n_lists</span><span class="o">=</span><span class="n">n_lists</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="s2">&quot;sqeuclidean&quot;</span><span class="p">)</span>
        <span class="n">index</span> <span class="o">=</span> <span class="n">cuvs_ivf_flat</span><span class="o">.</span><span class="n">build</span><span class="p">(</span><span class="n">build_params</span><span class="p">,</span> <span class="n">X_gpu</span><span class="p">)</span>

        <span class="n">search_params</span> <span class="o">=</span> <span class="n">cuvs_ivf_flat</span><span class="o">.</span><span class="n">SearchParams</span><span class="p">(</span><span class="n">n_probes</span><span class="o">=</span><span class="n">nprobe</span><span class="p">)</span>
        <span class="n">distances</span><span class="p">,</span> <span class="n">indices</span> <span class="o">=</span> <span class="n">cuvs_ivf_flat</span><span class="o">.</span><span class="n">search</span><span class="p">(</span><span class="n">search_params</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">X_gpu</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span>

        <span class="n">indices_np</span> <span class="o">=</span> <span class="n">cp</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">(</span><span class="n">cp</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">indices</span><span class="p">))</span>
        <span class="n">distances_np</span> <span class="o">=</span> <span class="n">cp</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">(</span><span class="n">cp</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">distances</span><span class="p">))</span>

        <span class="c1"># Remove self (first neighbor) and convert squared distances to distances</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_knn_indices</span> <span class="o">=</span> <span class="n">indices_np</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_knn_distances</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="n">distances_np</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:],</span> <span class="mf">0.0</span><span class="p">))</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;k-NN graph computed via cuVS: shape </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_knn_indices</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Clean up</span>
        <span class="k">del</span> <span class="n">X_gpu</span><span class="p">,</span> <span class="n">index</span>
        <span class="n">cp</span><span class="o">.</span><span class="n">get_default_memory_pool</span><span class="p">()</span><span class="o">.</span><span class="n">free_all_blocks</span><span class="p">()</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_initialize_embedding</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initialize the low-dimensional embedding.</span>
<span class="sd">        </span>
<span class="sd">        This private method creates the initial embedding using either PCA or random</span>
<span class="sd">        projection, then normalizes the result.</span>
<span class="sd">        </span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : numpy.ndarray</span>
<span class="sd">            Input high-dimensional data of shape (n_samples, n_features).</span>
<span class="sd">            </span>
<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        torch.Tensor</span>
<span class="sd">            Initial embedding of shape (n_samples, n_components) on the target device.</span>
<span class="sd">            </span>
<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        Private method, should not be called directly. Used by fit_transform().</span>
<span class="sd">        </span>
<span class="sd">        The embedding is normalized to have zero mean and unit standard deviation</span>
<span class="sd">        along each dimension.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">init</span> <span class="o">==</span> <span class="s1">&#39;pca&#39;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Initializing with PCA&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="s1">&#39;cuda&#39;</span> <span class="ow">and</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">32</span><span class="p">:</span>
                <span class="c1"># GPU-accelerated PCA via truncated SVD</span>
                <span class="n">X_t</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
                <span class="n">X_t</span> <span class="o">=</span> <span class="n">X_t</span> <span class="o">-</span> <span class="n">X_t</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
                <span class="c1"># Use randomized SVD (pca_lowrank) — O(N*D*q) instead of full SVD,</span>
                <span class="c1"># and avoids cusolver limits on very wide matrices (D &gt;&gt; N).</span>
                <span class="n">U</span><span class="p">,</span> <span class="n">S</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">pca_lowrank</span><span class="p">(</span><span class="n">X_t</span><span class="p">,</span> <span class="n">q</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_components</span><span class="p">)</span>
                <span class="n">embedding</span> <span class="o">=</span> <span class="p">(</span><span class="n">U</span> <span class="o">*</span> <span class="n">S</span><span class="p">)</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
                <span class="k">del</span> <span class="n">X_t</span><span class="p">,</span> <span class="n">U</span><span class="p">,</span> <span class="n">S</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="s1">&#39;cuda&#39;</span><span class="p">:</span>
                    <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_components</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">random_state</span><span class="p">)</span>
                <span class="n">embedding</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">init</span> <span class="o">==</span> <span class="s1">&#39;random&#39;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Initializing with random projection&quot;</span><span class="p">)</span>
            <span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">random_state</span><span class="p">)</span>
            <span class="n">projection</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">standard_normal</span><span class="p">((</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_components</span><span class="p">))</span>
            <span class="n">projection</span> <span class="o">/=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">projection</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">embedding</span> <span class="o">=</span> <span class="n">X</span> <span class="o">@</span> <span class="n">projection</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unknown init method: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">init</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Normalize</span>
        <span class="n">embedding</span> <span class="o">-=</span> <span class="n">embedding</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">embedding</span> <span class="o">/=</span> <span class="n">embedding</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">embedding</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_compute_forces</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">positions</span><span class="p">,</span> <span class="n">iteration</span><span class="p">,</span> <span class="n">max_iterations</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute attraction and repulsion forces for layout optimization.</span>

<span class="sd">        Uses a single vectorized pass over all points (no chunking). On any</span>
<span class="sd">        GPU with &gt;= 2 GB free VRAM this handles &gt; 500K points comfortably.</span>
<span class="sd">        Falls back to a chunked path only on true out-of-memory.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        positions : torch.Tensor</span>
<span class="sd">            Current positions, shape (n_samples, n_components).</span>
<span class="sd">        iteration : int</span>
<span class="sd">            Current iteration number (0-indexed).</span>
<span class="sd">        max_iterations : int</span>
<span class="sd">            Total number of iterations planned.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        torch.Tensor</span>
<span class="sd">            Forces of shape (n_samples, n_components).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">n_samples</span> <span class="o">=</span> <span class="n">positions</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">a_val</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_a</span><span class="p">)</span>
        <span class="n">b_exp</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">_b</span><span class="p">)</span>
        <span class="n">n_neg</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">neg_ratio</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_neighbors</span><span class="p">),</span> <span class="n">n_samples</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>

        <span class="n">knn_indices_torch</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;_knn_indices_torch&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">knn_indices_torch</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">knn_indices_torch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_knn_indices</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span>
            <span class="p">)</span>

        <span class="c1"># Generate negative samples (randint is cheap on GPU)</span>
        <span class="n">neg_indices</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span>
            <span class="mi">0</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">,</span> <span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">n_neg</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span>
        <span class="p">)</span>

        <span class="c1"># Run force kernel in bf16 for ~2x bandwidth savings on gather-heavy ops;</span>
        <span class="c1"># positions stay fp32 in the caller, so accumulated drift is bounded.</span>
        <span class="n">use_bf16</span> <span class="o">=</span> <span class="n">positions</span><span class="o">.</span><span class="n">is_cuda</span> <span class="ow">and</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_bf16_supported</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">use_bf16</span><span class="p">:</span>
            <span class="n">pos_lo</span> <span class="o">=</span> <span class="n">positions</span><span class="o">.</span><span class="n">bfloat16</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">pos_lo</span> <span class="o">=</span> <span class="n">positions</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="n">forces</span> <span class="o">=</span> <span class="n">_compute_forces_compiled</span><span class="p">(</span>
                <span class="n">pos_lo</span><span class="p">,</span> <span class="n">knn_indices_torch</span><span class="p">,</span> <span class="n">neg_indices</span><span class="p">,</span>
                <span class="n">a_val</span><span class="p">,</span> <span class="n">b_exp</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">cutoff</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">except</span> <span class="p">(</span><span class="ne">RuntimeError</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">OutOfMemoryError</span><span class="p">):</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="s1">&#39;cuda&#39;</span><span class="p">:</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                <span class="s2">&quot;Vectorized force computation OOM — falling back to chunked path&quot;</span>
            <span class="p">)</span>
            <span class="n">forces</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_forces_chunked</span><span class="p">(</span>
                <span class="n">pos_lo</span><span class="p">,</span> <span class="n">knn_indices_torch</span><span class="p">,</span> <span class="n">neg_indices</span><span class="p">,</span>
                <span class="n">a_val</span><span class="p">,</span> <span class="n">b_exp</span><span class="p">,</span> <span class="n">n_neg</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="n">use_bf16</span><span class="p">:</span>
            <span class="n">forces</span> <span class="o">=</span> <span class="n">forces</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>

        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">forces</span><span class="p">,</span> <span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">cutoff</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">cutoff</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_compute_forces_chunked</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">positions</span><span class="p">,</span> <span class="n">knn_indices_torch</span><span class="p">,</span> <span class="n">neg_indices</span><span class="p">,</span>
                                <span class="n">a_val</span><span class="p">,</span> <span class="n">b_exp</span><span class="p">,</span> <span class="n">n_neg</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Chunked fallback for GPUs that cannot fit the full computation.&quot;&quot;&quot;</span>
        <span class="n">n_samples</span> <span class="o">=</span> <span class="n">positions</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">forces</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">positions</span><span class="p">)</span>
        <span class="n">chunk_size</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">n_samples</span> <span class="o">//</span> <span class="mi">10</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">start</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">,</span> <span class="n">chunk_size</span><span class="p">):</span>
            <span class="n">end</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">start</span> <span class="o">+</span> <span class="n">chunk_size</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">)</span>
            <span class="n">s</span> <span class="o">=</span> <span class="nb">slice</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">end</span><span class="p">)</span>
            <span class="n">chunk_pos</span> <span class="o">=</span> <span class="n">positions</span><span class="p">[</span><span class="n">s</span><span class="p">]</span>

            <span class="c1"># Attraction</span>
            <span class="n">neighbor_pos</span> <span class="o">=</span> <span class="n">positions</span><span class="p">[</span><span class="n">knn_indices_torch</span><span class="p">[</span><span class="n">s</span><span class="p">]]</span>
            <span class="n">diff</span> <span class="o">=</span> <span class="n">neighbor_pos</span> <span class="o">-</span> <span class="n">chunk_pos</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">dist</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">diff</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="o">+</span> <span class="mf">1e-10</span>
            <span class="n">att</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">+</span> <span class="n">a_val</span> <span class="o">*</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">/</span> <span class="n">dist</span><span class="p">)</span> <span class="o">**</span> <span class="n">b_exp</span><span class="p">)</span>
            <span class="n">forces</span><span class="p">[</span><span class="n">s</span><span class="p">]</span> <span class="o">+=</span> <span class="p">(</span><span class="n">att</span> <span class="o">*</span> <span class="n">diff</span> <span class="o">/</span> <span class="n">dist</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

            <span class="c1"># Repulsion</span>
            <span class="n">neg_pos</span> <span class="o">=</span> <span class="n">positions</span><span class="p">[</span><span class="n">neg_indices</span><span class="p">[</span><span class="n">s</span><span class="p">]]</span>
            <span class="n">diff_n</span> <span class="o">=</span> <span class="n">neg_pos</span> <span class="o">-</span> <span class="n">chunk_pos</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">dist_n</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">diff_n</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="o">+</span> <span class="mf">1e-10</span>
            <span class="n">rep</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.0</span> <span class="o">/</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">+</span> <span class="n">a_val</span> <span class="o">*</span> <span class="p">(</span><span class="n">dist_n</span> <span class="o">**</span> <span class="n">b_exp</span><span class="p">))</span>
            <span class="n">rep</span> <span class="o">=</span> <span class="n">rep</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">dist_n</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">cutoff</span><span class="p">)</span>
            <span class="n">forces</span><span class="p">[</span><span class="n">s</span><span class="p">]</span> <span class="o">+=</span> <span class="p">(</span><span class="n">rep</span> <span class="o">*</span> <span class="n">diff_n</span> <span class="o">/</span> <span class="n">dist_n</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">forces</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_optimize_layout</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">initial_positions</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Optimize the embedding layout using iterative force computation.</span>

<span class="sd">        This private method performs the main optimization loop, iteratively</span>
<span class="sd">        computing and applying forces to refine the embedding layout.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        initial_positions : torch.Tensor</span>
<span class="sd">            Initial embedding positions of shape (n_samples, n_components).</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        torch.Tensor</span>
<span class="sd">            Optimized final positions of shape (n_samples, n_components),</span>
<span class="sd">            normalized to zero mean and unit standard deviation.</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        Private method, should not be called directly. Used by fit_transform().</span>

<span class="sd">        Forces are computed in bf16 for bandwidth efficiency, accumulated</span>
<span class="sd">        into fp32 positions via linear cooling: alpha = 1 - iter/max_iter.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">positions</span> <span class="o">=</span> <span class="n">initial_positions</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Optimizing layout for </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_n_samples</span><span class="si">}</span><span class="s2"> points...&quot;</span><span class="p">)</span>

        <span class="c1"># Pre-convert kNN indices to GPU tensor once (avoid re-creating every iteration)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_knn_indices_torch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_knn_indices</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span>
        <span class="p">)</span>

        <span class="c1"># Optimization loop with linear cooling</span>
        <span class="k">for</span> <span class="n">iteration</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">max_iter_layout</span><span class="p">):</span>
            <span class="n">forces</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_forces</span><span class="p">(</span><span class="n">positions</span><span class="p">,</span> <span class="n">iteration</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_iter_layout</span><span class="p">)</span>

            <span class="n">alpha</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">iteration</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_iter_layout</span>
            <span class="n">positions</span><span class="o">.</span><span class="n">add_</span><span class="p">(</span><span class="n">forces</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">iteration</span> <span class="o">%</span> <span class="mi">20</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Iteration </span><span class="si">{</span><span class="n">iteration</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">max_iter_layout</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Final normalization</span>
        <span class="n">positions</span> <span class="o">-=</span> <span class="n">positions</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">positions</span> <span class="o">/=</span> <span class="n">positions</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">positions</span>

<div class="viewcode-block" id="DiRePyTorch.fit_transform">
<a class="viewcode-back" href="../../api/modules.html#dire_rapids.dire_pytorch.DiRePyTorch.fit_transform">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">fit_transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>  <span class="c1"># pylint: disable=unused-argument,arguments-differ</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Fit the DiRe model and transform data to low-dimensional embedding.</span>
<span class="sd">        </span>
<span class="sd">        This method performs the complete dimensionality reduction pipeline:</span>
<span class="sd">        1. Computes k-nearest neighbors graph</span>
<span class="sd">        2. Fits kernel parameters</span>
<span class="sd">        3. Initializes embedding with PCA or random projection</span>
<span class="sd">        4. Optimizes layout using force-directed algorithm</span>
<span class="sd">        </span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array-like of shape (n_samples, n_features)</span>
<span class="sd">            High-dimensional input data to transform.</span>
<span class="sd">        y : array-like of shape (n_samples,), optional</span>
<span class="sd">            Ignored. Present for scikit-learn API compatibility.</span>
<span class="sd">            </span>
<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        numpy.ndarray of shape (n_samples, n_components)</span>
<span class="sd">            Low-dimensional embedding of the input data.</span>
<span class="sd">            </span>
<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        Transform high-dimensional data::</span>
<span class="sd">        </span>
<span class="sd">            import numpy as np</span>
<span class="sd">            from dire_rapids import DiRePyTorch</span>
<span class="sd">            </span>
<span class="sd">            X = np.random.randn(1000, 100)</span>
<span class="sd">            reducer = DiRePyTorch(n_neighbors=16)</span>
<span class="sd">            embedding = reducer.fit_transform(X)</span>
<span class="sd">            print(embedding.shape)  # (1000, 2)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Seed torch RNGs for reproducibility (deferred from __init__</span>
        <span class="c1"># to avoid mutating global state at construction time).</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">random_state</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">manual_seed_all</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">random_state</span><span class="p">)</span>

        <span class="c1"># Store data</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_n_samples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Processing </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_n_samples</span><span class="si">}</span><span class="s2"> samples with </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2"> features&quot;</span><span class="p">)</span>

        <span class="c1"># Validate n_components</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_components</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;n_components must be positive, got </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">n_components</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Validate n_neighbors</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_neighbors</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;n_neighbors must be positive, got </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">n_neighbors</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Validate and adjust n_neighbors if necessary</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_neighbors</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_n_samples</span><span class="p">:</span>
            <span class="n">old_n_neighbors</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_neighbors</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">n_neighbors</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_n_samples</span> <span class="o">-</span> <span class="mi">1</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;n_neighbors=</span><span class="si">{</span><span class="n">old_n_neighbors</span><span class="si">}</span><span class="s2"> is &gt;= n_samples=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_n_samples</span><span class="si">}</span><span class="s2">. &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;Adjusting n_neighbors to </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">n_neighbors</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>

        <span class="c1"># Find distribution kernel parameters</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_find_ab_params</span><span class="p">()</span>

        <span class="c1"># Compute k-NN graph</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_compute_knn</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_data</span><span class="p">)</span>

        <span class="c1"># Initialize embedding</span>
        <span class="n">initial_embedding</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_initialize_embedding</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_data</span><span class="p">)</span>

        <span class="c1"># Optimize layout</span>
        <span class="n">final_embedding</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_optimize_layout</span><span class="p">(</span><span class="n">initial_embedding</span><span class="p">)</span>

        <span class="c1"># Convert back to numpy and store</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_layout</span> <span class="o">=</span> <span class="n">final_embedding</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

        <span class="c1"># Clear GPU memory</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="s1">&#39;cuda&#39;</span><span class="p">:</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>
        <span class="n">gc</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_layout</span></div>


<div class="viewcode-block" id="DiRePyTorch.fit">
<a class="viewcode-back" href="../../api/modules.html#dire_rapids.dire_pytorch.DiRePyTorch.fit">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>  <span class="c1"># pylint: disable=unused-argument,arguments-differ</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Fit the DiRe model to data without transforming.</span>
<span class="sd">        </span>
<span class="sd">        This method fits the model by computing the k-NN graph, kernel parameters,</span>
<span class="sd">        and optimized embedding, but primarily serves for scikit-learn compatibility.</span>
<span class="sd">        For practical use, fit_transform() is recommended.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : numpy.ndarray of shape (n_samples, n_features)</span>
<span class="sd">            High-dimensional data to fit the model to.</span>
<span class="sd">        y : array-like of shape (n_samples,), optional</span>
<span class="sd">            Ignored. Present for scikit-learn API compatibility.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        self : DiRePyTorch</span>
<span class="sd">            The fitted DiRe instance.</span>
<span class="sd">            </span>
<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        This method calls fit_transform() internally. The embedding result</span>
<span class="sd">        is stored in self._layout and can be accessed after fitting.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span></div>


<div class="viewcode-block" id="DiRePyTorch.visualize">
<a class="viewcode-back" href="../../api/modules.html#dire_rapids.dire_pytorch.DiRePyTorch.visualize">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">visualize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">point_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">max_points</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Create an interactive visualization of the embedding.</span>

<span class="sd">        Uses WebGL rendering (Scattergl) for performance and automatically</span>
<span class="sd">        subsamples to max_points if dataset is larger.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        labels : array-like of shape (n_samples,), optional</span>
<span class="sd">            Labels for coloring points in the visualization.</span>
<span class="sd">        point_size : int, default=2</span>
<span class="sd">            Size of points in the scatter plot.</span>
<span class="sd">        title : str, optional</span>
<span class="sd">            Title for the plot. If None, a default title is generated.</span>
<span class="sd">        max_points : int, default=10000</span>
<span class="sd">            Maximum number of points to display. Subsamples if larger.</span>
<span class="sd">        **kwargs : dict</span>
<span class="sd">            Additional keyword arguments passed to plotly.express plotting functions.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        plotly.graph_objects.Figure or None</span>
<span class="sd">            Interactive Plotly figure, or None if no embedding is available.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        Basic visualization::</span>

<span class="sd">            fig = reducer.visualize()</span>
<span class="sd">            fig.show()</span>

<span class="sd">        With labels and custom styling::</span>

<span class="sd">            fig = reducer.visualize(</span>
<span class="sd">                labels=y,</span>
<span class="sd">                point_size=3,</span>
<span class="sd">                title=&quot;My Embedding&quot;,</span>
<span class="sd">                max_points=20000,</span>
<span class="sd">                width=800,</span>
<span class="sd">                height=600</span>
<span class="sd">            )</span>
<span class="sd">            fig.show()</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        Requires a fitted model with available embedding (self._layout).</span>
<span class="sd">        Only supports 2D and 3D visualizations.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_layout</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;No layout available for visualization&quot;</span><span class="p">)</span>
            <span class="k">return</span> <span class="kc">None</span>

        <span class="k">if</span> <span class="n">title</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">title</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;PyTorch </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">n_components</span><span class="si">}</span><span class="s2">D Embedding&quot;</span>

        <span class="c1"># Subsample if needed</span>
        <span class="n">n_points</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_layout</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">n_points</span> <span class="o">&gt;</span> <span class="n">max_points</span><span class="p">:</span>
            <span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
            <span class="n">subsample_idx</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">n_points</span><span class="p">,</span> <span class="n">max_points</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="n">layout_vis</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_layout</span><span class="p">[</span><span class="n">subsample_idx</span><span class="p">]</span>
            <span class="n">labels_vis</span> <span class="o">=</span> <span class="n">labels</span><span class="p">[</span><span class="n">subsample_idx</span><span class="p">]</span> <span class="k">if</span> <span class="n">labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">layout_vis</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_layout</span>
            <span class="n">labels_vis</span> <span class="o">=</span> <span class="n">labels</span>

        <span class="c1"># Create dataframe</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_components</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
            <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">layout_vis</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="s1">&#39;y&#39;</span><span class="p">])</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_components</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
            <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">layout_vis</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="s1">&#39;z&#39;</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Cannot visualize </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">n_components</span><span class="si">}</span><span class="s2">D embedding&quot;</span><span class="p">)</span>
            <span class="k">return</span> <span class="kc">None</span>

        <span class="c1"># Add labels if provided</span>
        <span class="k">if</span> <span class="n">labels_vis</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">df</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">labels_vis</span>

        <span class="c1"># Create plot</span>
        <span class="n">vis_params</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s1">&#39;color&#39;</span><span class="p">:</span> <span class="s1">&#39;label&#39;</span> <span class="k">if</span> <span class="n">labels_vis</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
            <span class="s1">&#39;title&#39;</span><span class="p">:</span> <span class="n">title</span><span class="p">,</span>
        <span class="p">}</span>
        <span class="n">vis_params</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_components</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
            <span class="n">fig</span> <span class="o">=</span> <span class="n">px</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="o">**</span><span class="n">vis_params</span><span class="p">)</span>
            <span class="c1"># Convert to WebGL for performance</span>
            <span class="k">for</span> <span class="n">trace</span> <span class="ow">in</span> <span class="n">fig</span><span class="o">.</span><span class="n">data</span><span class="p">:</span>
                <span class="n">trace</span><span class="o">.</span><span class="n">type</span> <span class="o">=</span> <span class="s1">&#39;scattergl&#39;</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">fig</span> <span class="o">=</span> <span class="n">px</span><span class="o">.</span><span class="n">scatter_3d</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="n">z</span><span class="o">=</span><span class="s1">&#39;z&#39;</span><span class="p">,</span> <span class="o">**</span><span class="n">vis_params</span><span class="p">)</span>

        <span class="n">fig</span><span class="o">.</span><span class="n">update_traces</span><span class="p">(</span><span class="n">marker</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;size&#39;</span><span class="p">:</span> <span class="n">point_size</span><span class="p">,</span> <span class="s1">&#39;opacity&#39;</span><span class="p">:</span> <span class="mf">0.7</span><span class="p">})</span>

        <span class="k">return</span> <span class="n">fig</span></div>
</div>



<div class="viewcode-block" id="create_dire">
<a class="viewcode-back" href="../../api/modules.html#dire_rapids.dire_pytorch.create_dire">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">create_dire</span><span class="p">(</span><span class="n">backend</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span> <span class="n">memory_efficient</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create DiRe instance with automatic backend selection.</span>

<span class="sd">    This factory function automatically selects the optimal DiRe implementation</span>
<span class="sd">    based on available hardware and software, or allows manual backend selection.</span>
<span class="sd">    It provides a convenient interface for creating DiRe instances without</span>
<span class="sd">    importing specific backend classes.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    backend : {&#39;auto&#39;, &#39;cuvs&#39;, &#39;pytorch&#39;, &#39;pytorch_gpu&#39;, &#39;pytorch_cpu&#39;}, default=&#39;auto&#39;</span>
<span class="sd">        Backend selection strategy:</span>

<span class="sd">        - &#39;auto&#39;: Automatically select best available backend based on hardware</span>
<span class="sd">        - &#39;cuvs&#39;: Force RAPIDS cuVS backend (requires RAPIDS installation)</span>
<span class="sd">        - &#39;pytorch&#39;: Force PyTorch backend with automatic device selection</span>
<span class="sd">        - &#39;pytorch_gpu&#39;: Force PyTorch backend on GPU (requires CUDA)</span>
<span class="sd">        - &#39;pytorch_cpu&#39;: Force PyTorch backend on CPU only</span>

<span class="sd">    memory_efficient : bool, default=False</span>
<span class="sd">        If True, use memory-efficient PyTorch implementation which provides:</span>

<span class="sd">        - Reduced memory usage for large datasets</span>
<span class="sd">        - FP16 support for additional memory savings</span>
<span class="sd">        - Enhanced chunking strategies</span>
<span class="sd">        - More aggressive memory cleanup</span>

<span class="sd">    **kwargs : dict</span>
<span class="sd">        Additional keyword arguments passed to the DiRe constructor.</span>
<span class="sd">        See individual backend documentation for available parameters.</span>
<span class="sd">        Common parameters include: n_components, n_neighbors, metric,</span>
<span class="sd">        max_iter_layout, min_dist, spread, verbose, random_state.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    DiRe instance</span>
<span class="sd">        An instance of the selected DiRe backend (DiRePyTorch, DiRePyTorchMemoryEfficient,</span>
<span class="sd">        or DiReCuVS) configured with the specified parameters.</span>

<span class="sd">    Raises</span>
<span class="sd">    ------</span>
<span class="sd">    RuntimeError</span>
<span class="sd">        If a specific backend is requested but requirements are not met</span>
<span class="sd">        (e.g., requesting cuVS without RAPIDS, or GPU without CUDA).</span>
<span class="sd">    ValueError</span>
<span class="sd">        If an unknown backend name is specified.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    Auto-select optimal backend::\n</span>
<span class="sd">        from dire_rapids import create_dire</span>

<span class="sd">        # Will use cuVS if available, otherwise PyTorch with GPU if available</span>
<span class="sd">        reducer = create_dire(n_neighbors=32, verbose=True)</span>
<span class="sd">        embedding = reducer.fit_transform(X)</span>

<span class="sd">    Force memory-efficient mode for large datasets::\n</span>
<span class="sd">        reducer = create_dire(</span>
<span class="sd">            memory_efficient=True,</span>
<span class="sd">            n_neighbors=50,</span>
<span class="sd">            max_iter_layout=200</span>
<span class="sd">        )</span>

<span class="sd">    Force specific backend::\n</span>
<span class="sd">        # CPU-only processing</span>
<span class="sd">        reducer = create_dire(backend=&#39;pytorch_cpu&#39;)</span>

<span class="sd">        # GPU processing with cuVS acceleration</span>
<span class="sd">        reducer = create_dire(backend=&#39;cuvs&#39;, use_cuvs=True)</span>

<span class="sd">        # With custom distance metric</span>
<span class="sd">        reducer = create_dire(</span>
<span class="sd">            metric=&#39;(x - y).abs().sum(-1)&#39;,  # L1 distance</span>
<span class="sd">            n_neighbors=32,</span>
<span class="sd">            verbose=True</span>
<span class="sd">        )</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    Backend Selection Priority (when backend=&#39;auto&#39;):</span>
<span class="sd">    1. RAPIDS cuVS (if available and CUDA GPU present)</span>
<span class="sd">    2. PyTorch Memory-Efficient with CUDA (if CUDA GPU available, cuVS not available, or memory_efficient=True)</span>
<span class="sd">    3. PyTorch with CUDA (if CUDA GPU available and memory_efficient=False)</span>
<span class="sd">    4. PyTorch with CPU (fallback)</span>

<span class="sd">    When cuVS is not available but GPU is present, the memory-efficient PyTorch backend</span>
<span class="sd">    is automatically selected for better GPU memory management and to handle larger datasets.</span>

<span class="sd">    The function automatically handles import errors and missing dependencies,</span>
<span class="sd">    falling back to available alternatives when possible.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Handle verbose parameter early to disable logging if needed</span>
    <span class="n">verbose</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;verbose&#39;</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>

    <span class="c1"># Import here to avoid circular imports</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">.dire_cuvs</span><span class="w"> </span><span class="kn">import</span> <span class="n">DiReCuVS</span><span class="p">,</span> <span class="n">CUVS_AVAILABLE</span>  <span class="c1"># pylint: disable=import-outside-toplevel</span>
    <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
        <span class="n">CUVS_AVAILABLE</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="kn">from</span><span class="w"> </span><span class="nn">.dire_pytorch_memory_efficient</span><span class="w"> </span><span class="kn">import</span> <span class="n">DiRePyTorchMemoryEfficient</span>  <span class="c1"># pylint: disable=import-outside-toplevel</span>

    <span class="k">if</span> <span class="n">backend</span> <span class="o">==</span> <span class="s1">&#39;auto&#39;</span><span class="p">:</span>
        <span class="c1"># Auto-select best backend based on availability</span>
        <span class="k">if</span> <span class="n">CUVS_AVAILABLE</span> <span class="ow">and</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Auto-selected RAPIDS cuVS backend (GPU acceleration)&quot;</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">DiReCuVS</span><span class="p">(</span><span class="n">use_cuvs</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
            <span class="c1"># When cuVS is not available, prefer memory-efficient backend for better GPU memory management</span>
            <span class="k">if</span> <span class="n">memory_efficient</span> <span class="ow">or</span> <span class="ow">not</span> <span class="n">CUVS_AVAILABLE</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Auto-selected memory-efficient PyTorch backend (GPU)&quot;</span><span class="p">)</span>
                <span class="k">return</span> <span class="n">DiRePyTorchMemoryEfficient</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Auto-selected PyTorch backend (GPU)&quot;</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">DiRePyTorch</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="c1"># CPU fallback</span>
        <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Auto-selected PyTorch backend (CPU)&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">memory_efficient</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;Memory-efficient mode has limited benefits on CPU&quot;</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">DiRePyTorchMemoryEfficient</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">DiRePyTorch</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">backend</span> <span class="o">==</span> <span class="s1">&#39;cuvs&#39;</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">CUVS_AVAILABLE</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="s2">&quot;cuVS backend requested but RAPIDS not installed. &quot;</span>
                <span class="s2">&quot;Follow the installation instructions at https://docs.rapids.ai/install/&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;cuVS backend requires CUDA GPU&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Using RAPIDS cuVS backend&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">DiReCuVS</span><span class="p">(</span><span class="n">use_cuvs</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">backend</span> <span class="o">==</span> <span class="s1">&#39;pytorch&#39;</span><span class="p">:</span>
        <span class="c1"># Use PyTorch with auto device selection</span>
        <span class="k">if</span> <span class="n">memory_efficient</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Using memory-efficient PyTorch backend&quot;</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">DiRePyTorchMemoryEfficient</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Using PyTorch backend&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">DiRePyTorch</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">backend</span> <span class="o">==</span> <span class="s1">&#39;pytorch_gpu&#39;</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;GPU requested but CUDA not available&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">memory_efficient</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Using memory-efficient PyTorch backend (GPU)&quot;</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">DiRePyTorchMemoryEfficient</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Using PyTorch backend (GPU)&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">DiRePyTorch</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">backend</span> <span class="o">==</span> <span class="s1">&#39;pytorch_cpu&#39;</span><span class="p">:</span>
        <span class="c1"># Force CPU even if GPU is available</span>
        <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Using PyTorch backend (forced CPU)&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">memory_efficient</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;Memory-efficient mode has limited benefits on CPU&quot;</span><span class="p">)</span>
            <span class="c1"># Create instance and force CPU</span>
            <span class="n">reducer</span> <span class="o">=</span> <span class="n">DiRePyTorchMemoryEfficient</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">reducer</span> <span class="o">=</span> <span class="n">DiRePyTorch</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="n">reducer</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">reducer</span>

    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
        <span class="sa">f</span><span class="s2">&quot;Unknown backend: </span><span class="si">{</span><span class="n">backend</span><span class="si">}</span><span class="s2">. &quot;</span>
        <span class="sa">f</span><span class="s2">&quot;Choose from: &#39;auto&#39;, &#39;cuvs&#39;, &#39;pytorch&#39;, &#39;pytorch_gpu&#39;, &#39;pytorch_cpu&#39;&quot;</span>
    <span class="p">)</span></div>


</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2025, Alexander Kolpakov (UATX), Igor Rivin (Temple University).</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>